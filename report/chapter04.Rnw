% LaTeX file for Chapter 04
<<'preamble04',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path='figure/ch04_fig', 
    self.contained=FALSE,
    cache=FALSE
) 
@

\chapter{Discussion and Outlook}

\section{Meta Analysis}
There are numerous methods to pool the estimates of multiple studies into one estimate, and two will be introduced here; fixed and random effects meta-analysis.
First the fixed effect meta-analysis will be explained. For convenience, notatotion will be identical whenever possible for both methods. Note that both methods can be used for continuous or dichotomous outcomes. For more details about the methods, see chapter 11 and 12 in \citet{metaanalysis}


\vspace{0mm}
Let $y_{i}$ be the effect size estimate of the study $i$ and $v_{i}$ be the corresponding variance of the effect size estimate. Effect measures have to be identical for all studies. Furthermore, let $w_i$ be the inverse of the variance of the estimate from study $i$, $1/v_{i}$ and $n$ the total number of studies.

\vspace{0mm}
The pooled estimate $\Delta_{f}$ of the fixed effects model is then simply the weighted average with the weights given by the inverses of the variances, $w_{i}$, given in \ref{weighted.mean}. The variance $\nu_{f}$ is the reciprocal of the sum of the weights as in \ref{reciproce.variance}.

\begin{align}
\Delta_{f} &= \frac{\sum_{i = 1}^n w_{i}y_{i}}{\sum_{i = 1}^n w_{i}} \label{weighted.mean} \\
\nu_{f} &= \frac{1}{\sum_{i = 1}^n w_{i}} \label{reciproce.variance}
\end{align}

The computation of random effects meta-analysis is more complicated. Random effects meta-analysis will give smaller studies with larger variance of their estimates more weight in the pooled estimate. The key principle is that the estimates are allowed to vary randomly around the true estimate $\Delta$, and additionally, the estimates are subject to noise or sampling error themselves. Thus a within - and between study variance has to be computed.
Let $Q$ be the heterogeneity of study estimates as given in \ref{Q.heterogeneity}. The degrees of freedom $d$ are equal to $n-1$. $C$ is defined in \ref{C.definition}. The between study variance $\tau^2$ is then defined as in \ref{Tao.definition}. The definition follows \citet{tau.estimator}, but other methods are available such as maximum likelihood or restricted maximum likelihood estimators. 

\begin{align}
Q &= \sum_{i = 1}^n w_{i}(y_{i} - \Delta_{f})^2 \label{Q.heterogeneity} \\
C &= \sum_{i = 1}^n w_{i} - \frac{\sum_{i = 1}^n w_{i}^2}{\sum_{i = 1}^n w_{i}} \label{C.definition} \\
\tau^2 &= \max(0, \frac{Q - d}{C}) \label{Tau.definition}
\end{align}

The variance of a study estimate $y_{i}$ of study $i$, $v_{i}^\star$ is then defined as in \ref{ranef.study.variance}, with $w_{i}^\star$ being the inverse of $v_{i}^\star$. It is used to calculate a new kind of weighted mean to obtain a pooled estimate $\Delta_{r}$ as in \ref{ranef.weighted.mean}. The variance of $\Delta_{r}$, $\nu_{r}$ is then the sum of the reciprocal variances (\ref{ranef.reciproce.variance}).

\begin{align}
v_{i}^\star &= v_{i} + \tau^2 \label{ranef.study.variance} \\
\Delta_{r} &= \frac{\sum_{i = 1}^n w_{i}^\star y_{i}}{\sum_{i = 1}^n w_{i}^\star} \label{ranef.weighted.mean} \\
\nu_{r} &= \frac{1}{\sum_{i = 1}^n w_{i}^\star} \label{ranef.reciproce.variance}
\end{align}

A p-value under the Null-hypothesis of $\Delta = 0$ can be obtained by calculating the $Z$-value (\ref{Z.value}) and the usual computation as in (\ref{p.value.calculation}), $\Phi$ being the cumulative distribution function of a standard normal distribution. 

\begin{align}
Z &= \frac{\Delta}{\sqrt{\nu}} \label{Z-value} \\
p &= 2(1 - \Phi(|{Z}|) \label{p.value.calculation}
\end{align}

\section{Reporting Bias Test}
Essentially, there are two kinds of tests for reporting bias, non-parametrical or rank-based tests or regression based tests. Five of them will be presented.
First, tests for continuous outcome studies are described, and special modifications of those for binary outcomes will be introduced later.

\vspace{0mm}
Again, let $y_{i}$ be the effect size estimate and $v_{i}$ the variance estimate of study $i$. Then, the standardized effect size $y_{i}^\star$ is given in \ref{begg.stand.eff}. $\Delta_{f}$ is the pooled estimate for fixed effect estimate defined in \ref{weighted.mean}. Let $v_{i}^\star$ be the variance of $y_{i} - \Delta_{f}$ as defined in \ref{begg.stand.var}. 

\begin{align}
v_{i}^\star &= v_{i} - 1/\sum_{i = 1}^n v_{i}^-1 \label{begg.stand.var} \\
y_{i}^\star &= (y_{i} - \Delta_{f})/v_{i}^\star \label{begg.stand.eff}
\end{align}

Then, a rank correlation test based on Kendall's tau is used. The pairs of $y_{i}^\star$ and $v_{i}^\star$ that are ranked in the same order are enumerated. Let $u$ be the number of pairs ranked in the same order, and $l$ the number of pairs ranked in the opposite order (e.g. larger standardized effect size and smaller variance). Then the normalized test statistic $Z$ is given in \ref{begg.teststat}. $n$ is the number of studies.

\begin{align}
Z &= (u - l)/\sqrt{n(n-1)(2n + 5)/18} \label{begg.teststat}
\end{align}

The changes in the case of ties are negligible \cite[410]{begg.ties}.

\vspace{0mm}
Alternatively, one can use Eggers test \citep{Egger} that is based on simple linear regression. Let $y_{i}^\star = y_{i}/\sqrt{v_{i}}$, $x_{i} = 1/\sqrt{v_{i}}$. Furthermore, let $\hat{y_{i}} = \beta_{0} + \beta_{1}x_{i}$. Using linear regression, one obtains a least-squares estimate for $\beta_{0}$, and the null hypothesis $\beta_{0} = 0$ can be tested using that $\beta_{0} \sim t_{n-1}$, $n-1$ being the degrees of freedom of the t-distribution. The p-value for $\beta_{0} = 0$ (no reporting bias) is given in \ref{egger.pvalue}.

\begin{align}
p &= 2*(1 - t_{n-1}(\beta_{0}/se(\beta_{0}))) \label{egger.pvalue}
\end{align}

A method proposed in \citet{thompson.sharp} allows for between study heterogeneity. Let $\tau^2$ be equal to \ref{Tau.definition}. The effect size estimates are then assumed to be distributed as in \ref{t.sharp.regression}. Then, a weighted regression is carried out with weigths $1/v_{i}^\star$ as given in \ref{ranef.study.variance}. Analagous to Eggers test, $\beta_{0}$ is then tested with respect to the null hypothesis $\beta{0} = 0$.

\begin{align}
y_{i} \sim N(\beta_{0} + \beta{1}x_{i}, v_{i} + \tau^2) \label{t.sharp.regression}
\end{align}

A rank based alternative to Peters test for binary outcomes is the Harbords test \citep{Harbord}. Let $e_{t}$ be the number of events in a two-armed study $i$ and $n_{t}$ be the total number of patients in the treatment arm and the same for $n_{c}$ and $e_{c}$ for the control arm. Then the score $r_{i}$ (the first derivative of the log-likelihood of a proportion with treatment effect equal 0) and its variance $v_{i}$ can be computed as shown in \ref{harbord.score} and \ref{harbord.variance}.

\begin{align}
r_{i} &= e_{t} - (e_{t} - e_{c})(e_{t} + (n_{t} - e_{t}))/(n_{t} + n_{c}) \label{harbord.score} \\
v_{i} &= \frac{(e_{t} + e_{c})(e_{t} + (n_{t} - e_{t}))(e_{c} + (n_{c} - e_{c}))((n_{t} - e_{t}) + (n_{c} - e_{c}))}{(n_{t} + n_{c})^2(n_{t} + n_{c} - 1)} \label{harbord.variance}
\end{align}

Similarly to Eggers or Peters Test, now a weighted linear regression can be performed on $r_{i}/v_{i}$ depending on the standard error $1/\sqrt{v_{i}}$ with the $1/v_{i}$ used as weigths. $r_{i}/v_{i}$ is also known as peto odds ratio. 


\section{Reporting Bias Adjustment}
One method to account for reporting bias in meta-analysis is to apply the Trim and Fill adjustment method \citep{trimfill}. It is based on a funnel plot, on which the effect size estimates of studies are plotted against their standard error. If reporting bias is present, the estimate will shift in average towards higher or lower efffect sizes compared to the estimates of larger studies. Trim and Fill is a nonparametric approach.

\vspace{0mm}
The algorithm for the method tries to estimate the number of studies that are not available due to reporting bias, $k$. There are different estimators for $k$. First, $\Delta$ is estimated using a fixed or random effects model. Then, the $k$ effect size estimates with the smallest standard errors are trimmed, and $\Delta$ is estimated again. The procedure is repeated until $k$ is 0 and the funnel plot is symmetric. The total number of missing studies is then mirrored with respect to the final effect size estimate $\Delta$, and $\Delta$ and its standard error is then computed to obtain an unbiased estimate.




% \begin{align} \label{cox reg}
% P(Y < y|\mathbf{x}) = 1 - exp(-exp(h(y) - (\mathbf{x})^\top\beta)
% \end{align}
% 
% See \cite{hothorn} for further information. It specifies the instantaneous risk of an event at time t to be
% 
% \begin{align}
% \lambda_{0}(t)exp((\mathbf{x})^\top\beta) \nonumber
% \end{align}
% 
% The model is regarded as a semi parametric model since it includes the covariates in a linear fashion but leaves the baseline hazard $\lambda_{0}(t)$ unspecified. The factor $exp((\mathbf{x})^\top\beta)$ has the interpretation of a hazard ratio between the reference with $\mathbf{x} = 0$. The formal definition of the hazard is
% 
% \begin{align}
% h(t) = \lim_{h \to 0} \frac{P(t < T < t + h| T > t)}{h}
% \end{align}
% 
% 
% \begin{align} \label{generalized linear model}
% \mathbf{Y}{_{ij}}|U{_i},\epsilon{_{ij}} = (1,x{_i}^\top)\beta + U{_i} + \epsilon{_{ij}}
% \end{align}