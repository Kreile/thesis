\documentclass[11pt,a4paper,twoside]{book}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\input{header.sty}   % packages, layout and standard macros


\usepackage{verbatim}
\usepackage{tikz}
\usetikzlibrary{trees}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\input{title}




\graphicspath{{./figure/}}
\DeclareGraphicsExtensions{.pdf,.png}
\setcounter{tocdepth}{1}



\thispagestyle{empty}
\begin{center}
  \vspace*{6cm}{\bfseries\Huge
  $p$-values:\\[5mm] their use, abuse and proper use \\[5mm]
  illustrated with seven facets 
  }
  \vfill
  \rm

  \LARGE
  M\"axli Musterli\\[12mm]
  
  \normalsize
  Version \today
\end{center}
\newpage
\thispagestyle{empty}~
\newpage
\pagenumbering{roman}

\thispagestyle{plain}\markboth{Contents}{Contents}
\tableofcontents
\setkeys{Gin}{width=.8\textwidth}

\chapter*{Preface}
\addtocontents{toc}{\protect \vspace*{13.mm}}
\addcontentsline{toc}{chapter}{\bfseries{Preface}}
\thispagestyle{plain}\markboth{Preface}{Preface}

Howdy!

\bigskip

\begin{flushright}
  Max Muster\\
  June 2018
\end{flushright}

\addtocontents{toc}{\protect \vspace*{10mm}}

\cleardoublepage
\pagenumbering{arabic}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% LaTeX file for Chapter 01



\chapter{Introduction}

Meta-analysis is at the core of evidence based medicine because it allows to summarise evidence over multiple studies and provide a more broad view on success and effectivity of clinical treatments. The necessity of meta-analyses is also increased by the abundance of data and publications. Especially when the findings differ or even contradict between studies, meta-analysis is the only way to go if one wants to keep decisions based on quantitative and scientific criteria.

\vspace{0mm}
For this, meta-analyses do not only benefit research, but also clinical practice, and may lead to better health care and prevention. However, since the amount of empirical research is expanding, meta-analysis can be part in any field where repeated experiments are performed. The usefulness of meta-analysis expands therefore well over clinical science.

\vspace{0mm}
Usually, a meta-analysis is part of a systematic review where researchers decided to summarise all research in a given field or more specifically, that concerns a given question. Systematic reviews may also incorporate results that can not be included in a meta-analysis, such as adverse effects reported in one trial, but a meta-analysis is the central part of a systematic review if results from multiple studies are available. The authors usually take their conclusions largely based on the results of the meta-analysis.

% In science, there is not only a need for accumulation of knowledge, but also for concentration. For the same reason as statistical analysis is performed on single experiments, it can also be used for results of multiple experiments or studies: to simplify and summarize the data at hand to a degree that is understandable. The latter procedure goes usually under the name of meta-analysis. Meta analyses are used to summarize results and evidence over multiple studies when they are considered to be similar enough.
% 
% \vspace{0mm}
% In the face of the large amount of research that is done in some fields of empirical science, meta-analysis becomes increasingly important, for looking at all evidence would simply take very long for one person. Meta-analyses are often part of a systematic review, an effort of experts of a field to provide an overlook over the evidence. In the course of a review, all literature and data with respect to a scientific question is collected and a meta-analysis is operated at the end to summarize the findings.
% 
% \vspace{0mm}
% In the case of clinical science, systematic reviews and meta-analyses do not only benefit scientists but also patients and clinicians, for both are provided with up-to-date summaries of current evidence with respect to a certain treatment. Therefore, meta-analysis is at the core of what is called evidence-based medicine. 
% 

\vspace{0mm}
However, there are problems that potentially limit the validity of meta-analysis; studies at hand can be biased or heterogeneity between study results can be large and the number of studies small. The importance and the issues of meta-analysis are the reasons why they have been chosen as one general topic of the masters thesis. One particular problem will furthermore be investigated in more detail: reporting bias and meta-analysis. Not only will the methods to deal with issues as reporting bias be discussed, but also will they be applied on a dataset of systematic reviews that can be used for meta-analysis. So at the end of the report, the reader will not only have an impression of the technical issues caused by reporting bias, but also of the abundance and extent of it in the dataset. Since the dataset is very large and of good quality, results might also be representative to some extent for reporting bias in clinical science.


\subsection{Cochrane and the Cochrane Database of Systematic Reviews}
The Cochrane Organization has specialized on systematic reviews in clinical science. It publishes and maintains a library with a large number of systematic reviews that are available in some countries to the public.

\vspace{0mm}
The data analyzed in this thesis stems completely from the Cochrane Library of systematic Reviews (cite). 

\vspace{0mm}
The reviews are arguably of good quality, since the authors are following elaborated guidelines, and there are control-mechanisms within the organisation that should prohibit conflicts of interests. This might further improve the validity and precision of findings and conclusions that have been made based on this data. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% LaTeX file for Chapter 02












\chapter{The Cochrane Dataset} 

\subsection{Structure and Content}
The dataset consists of 5016 systematic reviews from the Cochrane Library with 52995 studies.
Each study provides data of (multiple) comparisons of clinical interventions. 
% It can not be ruled out that some comparisons are retrospective, e.g. from observational studies. 
In Table \ref{barbiturate.row}, two comparisons from a systematic review about effects of barbiturates are shown as they are given in the dataset. As can be seen, the comparison is further specified by the variables in the columns. One row of the dataset is one comparison.

% latex table generated in R 3.5.1 by xtable 1.8-3 package
% Sun Apr  7 21:19:44 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lllrrrr}
  \hline
Study & Comparison\_type & Outcome & Events & Total & Events\_c & Total\_c \\ 
  \hline
Bohn 1989 & Barbiturate vs no barbiturate & Death at the end of follow-up & 11.00 & 41.00 & 11.00 & 41.00 \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Death at the end of follow-up & 14.00 & 27.00 & 13.00 & 26.00 \\ 
   \hline
\end{tabular}
\endgroup
\caption{Example of two comparisons as given in the dataset. Events denotes the count of events in the treatment group while Events c the count of events in the group compared to. Further descriptive variables have been ommitted} 
\label{barbiturate.row}
\end{table}


A complete listing of the variables is given in Table \ref{variable}. They can roughly be separated into variables that specify the review in which the comparison is contained and variables that specify the comparison itself (separated by a horizontal line in Table \ref{variable}).

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{l l}
      \textbf{Variable} & \textbf{Description}\\
      \hline
      \textbf{file.nr} & The number of the file from which the review data has been . \\&gathered. This file corresponds to a file available in the. \\& Cochrane library\\
      \textbf{doi} & Digital object identifier. A unique id of the review such that  \\ &the full text of the review can be found on the web.\\
      \textbf{file.index} & Internal index of the file in the Cochrane library.\\
      \textbf{file.version} & Denotes the version of the review, since the reviews are \\ &occasionally updated.\\
      %\multicolumn{2}{c}{textbf{Study level variables}}\\ 
      \hline
      \textbf{comparison.name/.nr} & Specification of the interventions compared in the study  \\ and a unique number for the comparison\\
      \textbf{outcome.name/.nr} & Specification by which outcome the interventions are compared\\ and a unique number for the outcome\\
      \textbf{subgroup.name/.nr} & Potentially indication of affiliation to subgroups and a \\ unique number for the subgroup\\
      \textbf{study.name} & Name of the study to which the comparison belongs\\
      \textbf{study.year} & Year in which the study was published\\
      \textbf{outcome.measure} & Indication of the quantification method of the effect \\ &(of one intervention compared to the other).\\
      \textbf{effect} & Measure of the effect given in the quantity denoted by \\ &``outcome measure''.\\
      \textbf{events1/events2} & The counts of patients with an outcome \textit{if}\\ & measurement/outcome is binary or dichotomous \\ &2 (1 for treatment group and 2 for control group).\\
      \textbf{total1/total2} & Number of patients in groups.\\
      \textbf{mean1/mean2)} & Mean of patient measurements \textit{if} outcome is continuous.\\
      \textbf{sd1/sd2} & Standard deviation of mean \textit{if} \\ &outcome is continuous.
    \end{tabular}
  \caption{Dataset variable names and descriptions  \label{variable}}

  \end{center}
\end{table}

The structure of a review is shown in Figure \ref{review}. 
% Comparisons of a review can consecutively be subdivided into different comparison types, different outcome measures and different subgroups. 
The comparison type variable specifies what is compared, the outcome variable how it is compared, and the subgroup variable indicates if the comparison belongs to a certain subgroup. If desired, Figure \ref{review} can be compared to Table \ref{barbiturates} where an exemplary review is listed.

\begin{figure}
\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=red,fill=red!30]
\tikzstyle{optional}=[dashed,fill=gray!50]
\begin{tikzpicture}
[grow = right, anchor = west, 
  growth parent anchor=east, % added code
  parent anchor=east]
  \node {Review} [edge from parent fork right]
    child { node {Comparison type 2}
      child { node {Outcome 2}}
      child { node {Outcome 1}
        child { node {Subgroup 2}}
        child { node {Subgroup 1}}}
    }
    child [missing] {}		
    child { node {Comparison type 1  }};
\end{tikzpicture}
\caption{Structure of a hypothetical review with two different comparisons\label{review.structure}}
\label{review.structure}
\end{figure}



% \vspace{0mm}
% Lets consider the previously mentioned barbiturate and head injury review. The aim was to ``assess the effects of barbiturates in reducing mortality, disability and raised ICP (intra-cranial pressure) in people with acute traumatic brain injury'' as well as to ``quantify any side effects resulting from the use of barbiturates''. The medical background is that one knew that barbiturates could cause relief in intra-cranial pressure, but also reduce cerebral blood flow. Because one effect is thought to be beneficial for persons with severe head injuries while the other isn't, the authors of the review wanted to find out if there is a net benefit of barbiturates.
% 
% \vspace{0mm}
% The review comprises five studies in total. Three of them compared barbiturate to placebo, one compared barbiturate to Mannitol and one Pentobarbital to Thiopental, which would be the comparison/research subject to speak in the previously introduced notions. 
% 
% \vspace{0mm}
% All the studies convey multiple information to the review. As an example, that could be death or death \textit{and} severe disability at follow up as an outcome. Again, the study can be further split up in different subgroups, here for example in a group with - and without haematoma. 
% 
% \vspace{0mm}
% The complete listing of outcomes is in table \ref{barbiturates}. The table also gives an illustration of the variety of data that can be included in a review. We have for example continuous and binary outcome data, that again is divided into a variety of different things that have been measured. Often, additionally to the main study result, also adverse effects are for example included which are in this case separate outcomes and possibly subgroups.


% latex table generated in R 3.5.1 by xtable 1.8-3 package
% Sun Apr  7 21:19:45 2019
\begin{table}[ht]
\centering
\begingroup\footnotesize
\begin{tabular}{lll}
  \hline
Study & Comparison & Outcome \\ 
  \hline
Bohn 1989 & Barbiturate vs no barbiturate & Death at the end of follow-up \\ 
  Bohn 1989 & Barbiturate vs no barbiturate & Death or severe disability at the end of follow-up \\ 
  Eisenberg 1988 & Barbiturate vs no barbiturate & Death at the end of follow-up \\ 
  Eisenberg 1988 & Barbiturate vs no barbiturate & Uncontrolled ICP during treatment \\ 
  Eisenberg 1988 & Barbiturate vs no barbiturate & Hypotension during treatment \\ 
  Perez-Barcena 2008 & Pentobarbital vs Thiopental & Death at the end of follow-up (6 months) \\ 
  Perez-Barcena 2008 & Pentobarbital vs Thiopental & Death or severe disability at the end of follow-up (6 months) \\ 
  Perez-Barcena 2008 & Pentobarbital vs Thiopental & Uncontrolled ICP during treatment \\ 
  Perez-Barcena 2008 & Pentobarbital vs Thiopental & Hypotension during treatment \\ 
  Schwartz 1984 & Barbiturate vs Mannitol & Death at the end of follow-up (1 year) \\ 
  Schwartz 1984 & Barbiturate vs Mannitol & Death at the end of follow-up (1 year) \\ 
  Schwartz 1984 & Barbiturate vs Mannitol & Uncontrolled ICP during treatment \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Death at the end of follow-up \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Death or severe disability at the end of follow-up \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Mean ICP during treatment \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Mean arterial pressure during treatment \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Hypotension during treatment \\ 
  Ward 1985 & Barbiturate vs no barbiturate & Mean body temperature during treatment \\ 
   \hline
\end{tabular}
\endgroup
\caption{Barbiturate and head injury review. In the columns, study names, comparison types and outcome measure of the comparisons are given} 
\label{barbiturates}
\end{table}


% The research subject or outcome type can possibly already be well defined in the general review question. Conversely, research subject or comparison has to be further specified in outcome and subgroup categories. As may have been implied, the terminology does not rely to a hundred percent on strict functional definitions.


It is important to not confuse comparisons with studies. A study can contribute multiple comparisons to a systematic review. Also, despite a comparison has variables concerning event counts and means, it can only have one of the two, either means (if the outcome measure is continuous) or event counts (for binary outcomes).

\vspace{0mm}
Having provided an overview over the dataset, now, some more specific information is provided. The dataset consists of 463820 comparisons and has 26 variables that specify the comparisons. Information about missing values in the dataset is given in Table \ref{missing}. For variables as research subject, outcome and subgroup name and event counts there are no missing values. The relative amount of missing values is very low except for study years.



% latex table generated in R 3.5.1 by xtable 1.8-3 package
% Sun Apr  7 21:19:45 2019
\begin{table}[ht]
\centering
\begingroup\footnotesize
\begin{tabular}{lr}
  \hline
  \hline
Missing mean values & 1287 \\ 
  Missing standard deviations & 999 \\ 
  Missing effects & 158 \\ 
  Missing study year & 27234 \\ 
   \hline
\end{tabular}
\endgroup
\caption{Number of missing variables and measurements in the dataset} 
\label{missing}
\end{table}



More properties of the reviews, the studies and the comparisons in the dataset will be provided on the following pages. The publication dates of the studies included in the dataset are shown in Figure \ref{study.years}. Most studies were published after 2000.

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-8-1} 

}



\end{knitrout}
\caption{Frequencies of study publication years in the dataset. 44655 were excluded due to likely wrong indications}
\label{study.years}
\end{figure}

Figure \ref{study.outcomes} provides the frequencies of outcome types of the comparisons. Note that the abundance of mean differences and standardized mean differences can also give an impression of the proportion of continuous outcome comparisons vs. binary outcome comparisons in the dataset.

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-9-1} 

}



\end{knitrout}
\caption{Frequencies of some outcome measures for the effects in the dataset. 5593 measures with other outcome measures are excluded}
\label{study.outcomes}
\end{figure}

It is also possible to look at the properties of the reviews. One question could be how many studies or comparisons that a review comprises. The former is shown in Figure \ref{studies.per.review} and the latter in Figure \ref{comparisons.per.review}. It can be seen that while almost 400 reviews consist of one study only, there are more than 150 with equal or more than 30 distinct studies. A similar variance between reviews can also be observed when looking at the number of comparisons.

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-10-1} 

}



\end{knitrout}
\caption{Empirical distribution of number of studies per review}
\label{studies.per.review}
\end{figure}

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-11-1} 

}



\end{knitrout}
\caption{Empirical distribution of number of comparisons per review}
\label{comparisons.per.review}
\end{figure}

A question not to be mistaken with the previous would be how many comparison \textit{types} there are per review. This gives an additional impression of the scope of a review. Analogously to the previous figures, the empirical distribution of comparison types is depicted in Figure \ref{subjects.per.review}.


\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-12-1} 

}



\end{knitrout}
\caption{Empirical distribution of number of different comparison types per review}
\label{subjects.per.review}
\end{figure}

% At the end, a main goal of the thesis is to analyze reviews with respect to reporting bias in meta analyses. 
For comparisons to be suitable for usage in meta-analysis, they have to be somewhat identical (same comparison type, outcome measure and possibly subgroup). For an analysis of reporting bias, again a certain number of studies is required in order for reporting bias to be detectable by the methods. One question would therefore be: How many groups of identical comparisons of a certain size are given in the dataset? This depends on which degree of similarity between comparisons is considered to be sufficient.

\vspace{0mm}
In Table \ref{repr.groups}, two different similarity criteria have been used. One is based on the same comparison type and outcome measure, the other includes additionally subgroup affiliation of comparisons, i.e. only comparisons in the same subgroups are considered to be similar enough.

\vspace{0mm}
Table \ref{repr.groups} shows the cumulative number of \textit{groups} of comparisons with equal or more than $n$ comparisons. Practically, this means that this number of meta analyses can be performed with each having at least $n$ comparisons.

% latex table generated in R 3.5.1 by xtable 1.8-3 package
% Sun Apr  7 21:19:51 2019
\begin{table}[ht]
\centering
\begingroup\footnotesize
\begin{tabular}{lll}
  \hline
n & Cumulative sum (without subgroups) & Cumulative sum (with subgroups) \\ 
  \hline
1 & 109191 & 186300 \\ 
  2 & 67699 & 83956 \\ 
  3 & 47800 & 52270 \\ 
  4 & 36169 & 36198 \\ 
  5 & 28090 & 26570 \\ 
  6 & 22702 & 20126 \\ 
  7 & 18547 & 15896 \\ 
  8 & 15475 & 12935 \\ 
  9 & 13008 & 10821 \\ 
  10 & 11008 & 9229 \\ 
  11 & 9362 & 7991 \\ 
  12 & 8057 & 7070 \\ 
  13 & 6988 & 6368 \\ 
  14 & 6044 & 5783 \\ 
  15 & 5328 & 5328 \\ 
   \hline
\end{tabular}
\endgroup
\caption{Cumulative number of groups with number of reproduction trials >= n} 
\label{repr.groups}
\end{table}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% LaTeX file for Chapter 03










\chapter{Results}

One crucial assumption in meta analysis is that the availability and publication of studies does not depend on their effect and the variance of the effect. If this is not given, one often speaks of publication bias. In fact, there can also be other reasons for this (see discussion section). A more appropriate term for the phenomenon is small study effect. If small study effects are present in a meta-analysis, the classical approaches to merge single study results in to an overall intervention effect fails to provide an appropriate estimate of the treatment effect. 

\vspace{0mm}
To provide an overview over the issue, first it is shown how mean effect size decreases with increasing sample size of the comparisons in Figure \ref{effect.samplesize}. All effects are normalized by subtracting the mean effect size of the dataset and dividng through the standard deviation. Then, the mean of the absolute value for a given sample size is plotted against its sample size. Note that various types of outcome measures are included, such as mean difference and risk ratios, and are normalized with respect to all sample sizes.

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-17-1} 

}



\end{knitrout}
\caption{Mean of the absolute of the normalized effect size plotted against the total sample size.}
\label{effect.samplesize}
\end{figure}

\vspace{0mm}
There are tests that can be applied to find out if reporting bias is present in the meta analysis. For the precise description, see the methods section. Application of the tests is only recommended if there are ten or more studies that can be used, so all meta-analyses with less than ten studies have been excluded.

\vspace{0mm}
There are modifications to make tests more appropriate in case of binary outcomes, therefore, the results of the tests are separated in continuous outcome test results and dichotomoized outcome results. In Figure \ref{bias.results.bin} the proportion of test results that led to rejection of the null hypothesis of no small study effect based on the 5 \% level are shown for dichotomous outcomes. The same is shown in Figure \ref{bias.results.cont} for continuous outcome measures.



% # <<results = 'asis', Echo = FALSE>>=
% # rejection.bin <- data.bin.ext %>% summarize(egger.rejection = mean(egger.test),
% #                                             schwarzer.rejection = mean(schwarzer.test),
% #                                             rucker.rejection = mean(rucker.test),
% #                                             harbord.rejection = mean(harbord.test),
% #                                             peter.rejection = mean(peter.test))
% # print(xtable(rejection.bin), label = "bias.results", caption = "Cumulative number of groups with number of reproduction trials >= n", align = "llll", digits = 0), include.rownames = F, size = "footnotesize")
% # @

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-18-1} 

}



\end{knitrout}
\caption{Proportion where the null hypothesis of no small study effect is rejected based on the 5\% significance level for different tests (dichotomous outcomes).}
\label{bias.results.bin}
\end{figure}

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-19-1} 

}



\end{knitrout}
\caption{Proportion where the null hypothesis of no small study effect is rejected based on the 5\% significance level for different tests (continuous outcomes).}
\label{bias.results.cont}
\end{figure}

Furthermore, one can investigate how well the tests give the same results, i.e. classify the same study collections as having publication bias. This is shown in Table \ref{agreement.bin} and Table \ref{agreement.cont}, again separated for outcome types.

\begin{kframe}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning: Setting row names on a tibble is deprecated.}}\end{kframe}% latex table generated in R 3.5.1 by xtable 1.8-3 package
% Sun Apr  7 21:20:02 2019
\begin{table}[ht]
\centering
\begingroup\footnotesize
\begin{tabular}{lll}
  \hline
 & Test Agreement & P-value Correlation \\ 
  \hline
egger.schwarzer & 0.84 & 0.38 \\ 
  egger.peter & 0.84 & 0.44 \\ 
  egger.rucker & 0.83 & 0.39 \\ 
  egger.harbord & 0.91 & 0.75 \\ 
  schwarzer.peter & 0.85 & 0.24 \\ 
  schwarzer.rucker & 0.83 & 0.30 \\ 
  schwarzer.harbord & 0.88 & 0.52 \\ 
  rucker.peter & 0.89 & 0.67 \\ 
  harbord.peter & 0.86 & 0.45 \\ 
   \hline
\end{tabular}
\endgroup
\caption{Proportion of tests that agree in rejection ar acceptance of the null hypothesis that there is no small study effect (dichotomous outcomes)} 
\label{agreement.bin}
\end{table}



\begin{kframe}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning: Setting row names on a tibble is deprecated.}}\end{kframe}% latex table generated in R 3.5.1 by xtable 1.8-3 package
% Sun Apr  7 21:20:02 2019
\begin{table}[ht]
\centering
\begingroup\footnotesize
\begin{tabular}{lll}
  \hline
 & Test Agreement & P-value Correlation \\ 
  \hline
thomson.egger & 0.85 & 0.67 \\ 
  thomson.begg & 0.75 & 0.45 \\ 
  egger.begg & 0.75 & 0.38 \\ 
   \hline
\end{tabular}
\endgroup
\caption{Proportion of tests that agree in rejection ar acceptance of the null hypothesis that there is no small study effect (continuous outcomes)} 
\label{agreement.cont}
\end{table}


\vspace{0mm}
Test performance depends on the sample size, despite having restricted sample size to a minimum of 10 studies. The p-values of two tests are shown with respect to the sample size of the studies in Figure \ref{pvalues.samplesize.bin} for peters test based on dichotomous outcomes and in Figure \ref{pvalues.samplesize.cont} for thomson and sharp's test based on continuous outcomes. %(Suggests that 10 is likely too small)

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-22-1} 

}



\end{knitrout}
\caption{P-values of peters test for small study effects and their corresponding sample size (dichotomous outcomes)}
\label{pvalues.samplesize.bin}
\end{figure}

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-23-1} 

}



\end{knitrout}
\caption{P-values of thomson and sharp's test for small study effects and their corresponding sample size (continuous outcomes)}
\label{pvalues.samplesize.cont}
\end{figure}




\vspace{0mm}
One can use the proportion of added studies by the trim-and-fill method from the overall number of studies to further investigate the extent of small study effects. A histogram with those fractions is shown in Figure \ref{trimfill.cont} for continuous outcomes and \ref{trimfill.bin} for dichotomous outcomes. The mean fraction of trimmed comparisons for binary outcomes is 0.19 and the median 0.17. In Figure \ref{trimfill.pvalues.bin} and Figure \ref{trimfill.pvalues.cont}, the relationship between fraction of added studies by trim-and-fill and the hypothesis test decisions of the small study effects tests is shown for continuous and dichotomous outcomes.

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-25-1} 

}



\end{knitrout}
\caption{Histogram of fractions of trimmed comparisons from meta analyses with continuous outcomes.}
\label{trimfill.cont}
\end{figure}

The mean fraction of trimmed comparisons for continuous outcomes is 0.22 and the median 0.2.

The same is repeated for binary outcomes in figure \ref{trimfill.bin}. 
\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-26-1} 

}



\end{knitrout}
\caption{Histogram of fractions of trimmed comparisons from meta analyses with binary outcomes.}
\label{trimfill.bin}
\end{figure}


\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-27-1} 

}



\end{knitrout}
\caption{Fraction of added studies for small study effect correction by trim and fill and the corresponding small study effect test decision (based on 5\% significance level) of peters test and dichotomous outcomes}
\label{trimfill.pvalues.bin}
\end{figure}

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.98, 0.98, 0.98}\color{fgcolor}

{\centering \includegraphics[width=\textwidth-3cm]{figure/ch02_figunnamed-chunk-28-1} 

}



\end{knitrout}
\caption{Fraction of added studies for small study effect correction by trim and fill and the corresponding small study effect test decision (based on 5\% significance level) of thomson and sharp's test and continuous outcomes}
\label{trimfill.pvalues.cont}
\end{figure}




























% 
% For continuous outcomes, three tests are available: Eggers (based on linear regression), Thompson and Sharp (weighted linear regression) and Begg and Mazumdar (rank based) test. The following three figures show the distribution of p-values of the corresponding tests. Note that only meta analyses with more than 10 comparisons have been included. 
% 
% \vspace{0mm}
% Since each histogram of p-values has 20 bins, the content of the bin with the smallest p-values is equal to the number of meta-analyses whose reporting bias test reports a p-value < 0.05. The fraction of those analyses in which we would reject the null-hypothesis based on the 5 \% threshold can therefore be assessed by eye, and would be for example for Eggers test somewhat less than one third of all analyses. 
% 
% \begin{figure}
% <<echo=FALSE>>=
% data %>% filter(outcome.measure == "Mean Difference" | outcome.measure == "Std. Mean Difference") %>% #filter(file.nr < 503) %>% 
%   filter(sd1 > 0 & sd2 > 0 ) %>% filter(!is.na(sd1) & !is.na(sd2)) %>% 
%   filter(mean1 != 0 | mean2 != 0 ) %>% filter(!is.na(mean1) & !is.na(mean2)) %>% 
%   group_by(file.nr, outcome.nr, subgroup.nr) %>% 
%   mutate(n = n()) %>% filter(n > 9) %>% 
%   summarize(pval = metabias(metacont(n.e = total1, mean.e = mean1, sd.e = sd1, n.c = total2, mean.c = mean2, sd.c = sd2), 
%                             method = "linreg")$p.val) %>% 
%   ggplot(aes(x = pval)) + geom_histogram(col = "gray15", fill = "dodgerblue", bins = 20) +
%   theme_bw() + labs(title = "Eggers Reporting Bias Test P-values for Continuous Outcome Meta-Analyses") + xlab("P-value") + ylab("Frequency")
% @
% \caption{Histogram of p-values for Eggers reporting bias test (linear regression based) for continuous outcome meta analysis.}
% \label{egger.cont}
% \end{figure}
% 
% 
% \begin{figure}
% <<echo=FALSE>>=
% data %>% filter(outcome.measure == "Mean Difference" | outcome.measure == "Std. Mean Difference") %>% #filter(file.nr < 503) %>% 
%   filter(sd1 > 0 & sd2 > 0 ) %>% filter(!is.na(sd1) & !is.na(sd2)) %>% 
%   filter(mean1 != 0 | mean2 != 0 ) %>% filter(!is.na(mean1) & !is.na(mean2)) %>% 
%   group_by(file.nr, outcome.nr, subgroup.nr) %>% 
%   mutate(n = n()) %>% filter(n > 9) %>% 
%   summarize(pval = metabias(metacont(n.e = total1, mean.e = mean1, sd.e = sd1, n.c = total2, mean.c = mean2, sd.c = sd2), 
%                             method = "mm")$p.val) %>% 
%   ggplot(aes(x = pval)) + geom_histogram(col = "gray15", fill = "dodgerblue", bins = 20) +
%   theme_bw() + labs(title = "Thomson Sharp Reporting Bias Test P-values for Continuous Outcome Meta-Analyses") + xlab("P-value") + ylab("Frequency")
% @
% \caption{Histogram of p-values for Thompsom and Sharp reporting bias test (weighted linear regression based) for continuous outcome meta analysis.}
% \label{thomson.cont}
% \end{figure}
% 
% \begin{figure}
% <<echo=FALSE>>=
% data %>% filter(outcome.measure == "Mean Difference" | outcome.measure == "Std. Mean Difference") %>% #filter(file.nr < 503) %>% 
%   filter(sd1 > 0 & sd2 > 0 ) %>% filter(!is.na(sd1) & !is.na(sd2)) %>% 
%   filter(mean1 != 0 | mean2 != 0 ) %>% filter(!is.na(mean1) & !is.na(mean2)) %>% 
%   group_by(file.nr, outcome.nr, subgroup.nr) %>% 
%   mutate(n = n()) %>% filter(n > 9) %>% 
%   summarize(pval = metabias(metacont(n.e = total1, mean.e = mean1, sd.e = sd1, n.c = total2, mean.c = mean2, sd.c = sd2), 
%                             method = "rank")$p.val) %>% 
%   ggplot(aes(x = pval)) + geom_histogram(col = "gray15", fill = "dodgerblue", bins = 20) +
%   theme_bw() + labs(title = "Begg and Mazumdar Reporting Bias Test P-values for Continuous Outcome Meta-Analyses") + xlab("P-value") + ylab("Frequency")
% @
% \caption{Histogram of p-values for Begg and Mazumdar reporting bias test (rank based) for continuous outcome meta analysis.}
% \label{begg.cont}
% \end{figure}
% 
% 
% For binary outcomes, Peters and Harbords reporting bias test have been chosen. Also here, only meta-analyses with more than 10 comparisons are included.
% 
% \begin{figure}
% <<echo=FALSE>>=
% data %>% filter(outcome.measure == "Risk Ratio" | outcome.measure == "Odds Ratio") %>% filter(file.nr != 3014) %>% 
%   filter(events1 > 0 | events2 > 0) %>% 
%   filter(total1 - events1 > 0 | total2 - events2 > 0) %>%
%   group_by(file.nr, outcome.nr, subgroup.nr) %>% 
%   mutate(n = n()) %>% filter(n > 9) %>% 
%   summarize(pval = metabias(metabin(event.e = events1, n.e = total1, event.c = events2, n.c = total2, sm = "OR"), method = "peters")$p.val) %>% 
%   ggplot(aes(x = pval)) + geom_histogram(col = "gray15", fill = "dodgerblue", bins = 20) +
%   theme_bw() + labs(title = "Peters Reporting Bias Test P-values for Binary Outcome Meta-Analyses") + xlab("P-value") + ylab("Frequency")
% @
% \caption{Histogram of p-values for Peters reporting bias test (rank based) for continuous outcome meta analysis.}
% \label{peters.bin}
% \end{figure}
% 
% 
% \begin{figure}
% <<echo=FALSE>>=
% data %>% filter(outcome.measure == "Risk Ratio" | outcome.measure == "Odds Ratio") %>% filter(file.nr != 3014) %>% 
%   filter(events1 > 0 | events2 > 0) %>% 
%   filter(total1 - events1 > 0 | total2 - events2 > 0) %>%
%   group_by(file.nr, outcome.nr, subgroup.nr) %>% 
%   mutate(n = n()) %>% filter(n > 9) %>% 
%   summarize(pval = metabias(metabin(event.e = events1, n.e = total1, event.c = events2, n.c = total2, sm = "OR"), method = "score")$p.val) %>% 
%   ggplot(aes(x = pval)) + geom_histogram(col = "gray15", fill = "dodgerblue", bins = 20) +
%   theme_bw() + labs(title = "Harbord Reporting Bias Test P-values for Binary Outcome Meta-Analyses") + xlab("P-value") + ylab("Frequency")
% @
% \caption{Histogram of p-values for Harbord reporting bias test (rank based) for continuous outcome meta analysis.}
% \label{harbord.bin}
% \end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% LaTeX file for Chapter 04


\chapter{Discussion and Outlook}

\section{Meta Analysis}
There are numerous methods to pool the estimates of multiple studies into one estimate, and two will be introduced here; fixed and random effects meta-analysis.
First the fixed effect meta-analysis will be explained. For convenience, notatotion will be identical whenever possible for both methods. Note that both methods can be used for continuous or dichotomous outcomes. For more details about the methods, see chapter 11 and 12 in \citet{metaanalysis}


\vspace{0mm}
Let $y_{i}$ be the effect size estimate of the study $i$ and $v_{i}$ be the corresponding variance of the effect size estimate. Effect measures have to be identical for all studies. Furthermore, let $w_i$ be the inverse of the variance of the estimate from study $i$, $1/v_{i}$ and $n$ the total number of studies.

\vspace{0mm}
The pooled estimate $\Delta_{f}$ of the fixed effects model is then simply the weighted average with the weights given by the inverses of the variances, $w_{i}$, given in \ref{weighted.mean}. The variance $\nu_{f}$ is the reciprocal of the sum of the weights as in \ref{reciproce.variance}.

\begin{align}
\Delta_{f} &= \frac{\sum_{i = 1}^n w_{i}y_{i}}{\sum_{i = 1}^n w_{i}} \label{weighted.mean} \\
\nu_{f} &= \frac{1}{\sum_{i = 1}^n w_{i}} \label{reciproce.variance}
\end{align}

The computation of random effects meta-analysis is more complicated. Random effects meta-analysis will give smaller studies with larger variance of their estimates more weight in the pooled estimate. The key principle is that the estimates are allowed to vary randomly around the true estimate $\Delta$, and additionally, the estimates are subject to noise or sampling error themselves. Thus a within - and between study variance has to be computed.
Let $Q$ be the heterogeneity of study estimates as given in \ref{Q.heterogeneity}. The degrees of freedom $d$ are equal to $n-1$. $C$ is defined in \ref{C.definition}. The between study variance $\tau^2$ is then defined as in \ref{Tao.definition}. The definition follows \citet{tau.estimator}, but other methods are available such as maximum likelihood or restricted maximum likelihood estimators. 

\begin{align}
Q &= \sum_{i = 1}^n w_{i}(y_{i} - \Delta_{f})^2 \label{Q.heterogeneity} \\
C &= \sum_{i = 1}^n w_{i} - \frac{\sum_{i = 1}^n w_{i}^2}{\sum_{i = 1}^n w_{i}} \label{C.definition} \\
\tau^2 &= \max(0, \frac{Q - d}{C}) \label{Tau.definition}
\end{align}

The variance of a study estimate $y_{i}$ of study $i$, $v_{i}^\star$ is then defined as in \ref{ranef.study.variance}, with $w_{i}^\star$ being the inverse of $v_{i}^\star$. It is used to calculate a new kind of weighted mean to obtain a pooled estimate $\Delta_{r}$ as in \ref{ranef.weighted.mean}. The variance of $\Delta_{r}$, $\nu_{r}$ is then the sum of the reciprocal variances (\ref{ranef.reciproce.variance}).

\begin{align}
v_{i}^\star &= v_{i} + \tau^2 \label{ranef.study.variance} \\
\Delta_{r} &= \frac{\sum_{i = 1}^n w_{i}^\star y_{i}}{\sum_{i = 1}^n w_{i}^\star} \label{ranef.weighted.mean} \\
\nu_{r} &= \frac{1}{\sum_{i = 1}^n w_{i}^\star} \label{ranef.reciproce.variance}
\end{align}

A p-value under the Null-hypothesis of $\Delta = 0$ can be obtained by calculating the $Z$-value (\ref{Z.value}) and the usual computation as in (\ref{p.value.calculation}), $\Phi$ being the cumulative distribution function of a standard normal distribution. 

\begin{align}
Z &= \frac{\Delta}{\sqrt{\nu}} \label{Z-value} \\
p &= 2(1 - \Phi(|{Z}|) \label{p.value.calculation}
\end{align}

\section{Reporting Bias Test}
Essentially, there are two kinds of tests for reporting bias, non-parametrical or rank-based tests or regression based tests. Five of them will be presented.
First, tests for continuous outcome studies are described, and special modifications of those for binary outcomes will be introduced later.

\vspace{0mm}
Again, let $y_{i}$ be the effect size estimate and $v_{i}$ the variance estimate of study $i$. Then, the standardized effect size $y_{i}^\star$ is given in \ref{begg.stand.eff}. $\Delta_{f}$ is the pooled estimate for fixed effect estimate defined in \ref{weighted.mean}. Let $v_{i}^\star$ be the variance of $y_{i} - \Delta_{f}$ as defined in \ref{begg.stand.var}. 

\begin{align}
v_{i}^\star &= v_{i} - 1/\sum_{i = 1}^n v_{i}^-1 \label{begg.stand.var} \\
y_{i}^\star &= (y_{i} - \Delta_{f})/v_{i}^\star \label{begg.stand.eff}
\end{align}

Then, a rank correlation test based on Kendall's tau is used. The pairs of $y_{i}^\star$ and $v_{i}^\star$ that are ranked in the same order are enumerated. Let $u$ be the number of pairs ranked in the same order, and $l$ the number of pairs ranked in the opposite order (e.g. larger standardized effect size and smaller variance). Then the normalized test statistic $Z$ is given in \ref{begg.teststat}. $n$ is the number of studies.

\begin{align}
Z &= (u - l)/\sqrt{n(n-1)(2n + 5)/18} \label{begg.teststat}
\end{align}

The changes in the case of ties are negligible \cite[410]{begg.ties}.

\vspace{0mm}
Alternatively, one can use Eggers test \citep{Egger} that is based on simple linear regression. Let $y_{i}^\star = y_{i}/\sqrt{v_{i}}$, $x_{i} = 1/\sqrt{v_{i}}$. Furthermore, let $\hat{y_{i}} = \beta_{0} + \beta_{1}x_{i}$. Using linear regression, one obtains a least-squares estimate for $\beta_{0}$, and the null hypothesis $\beta_{0} = 0$ can be tested using that $\beta_{0} \sim t_{n-1}$, $n-1$ being the degrees of freedom of the t-distribution. The p-value for $\beta_{0} = 0$ (no reporting bias) is given in \ref{egger.pvalue}.

\begin{align}
p &= 2*(1 - t_{n-1}(\beta_{0}/se(\beta_{0}))) \label{egger.pvalue}
\end{align}

A method proposed in \citet{thompson.sharp} allows for between study heterogeneity. Let $\tau^2$ be equal to \ref{Tau.definition}. The effect size estimates are then assumed to be distributed as in \ref{t.sharp.regression}. Then, a weighted regression is carried out with weigths $1/v_{i}^\star$ as given in \ref{ranef.study.variance}. Analagous to Eggers test, $\beta_{0}$ is then tested with respect to the null hypothesis $\beta{0} = 0$.

\begin{align}
y_{i} \sim N(\beta_{0} + \beta{1}x_{i}, v_{i} + \tau^2) \label{t.sharp.regression}
\end{align}

A rank based alternative to Peters test for binary outcomes is the Harbords test \citep{Harbord}. Let $e_{t}$ be the number of events in a two-armed study $i$ and $n_{t}$ be the total number of patients in the treatment arm and the same for $n_{c}$ and $e_{c}$ for the control arm. Then the score $r_{i}$ (the first derivative of the log-likelihood of a proportion with treatment effect equal 0) and its variance $v_{i}$ can be computed as shown in \ref{harbord.score} and \ref{harbord.variance}.

\begin{align}
r_{i} &= e_{t} - (e_{t} - e_{c})(e_{t} + (n_{t} - e_{t}))/(n_{t} + n_{c}) \label{harbord.score} \\
v_{i} &= \frac{(e_{t} + e_{c})(e_{t} + (n_{t} - e_{t}))(e_{c} + (n_{c} - e_{c}))((n_{t} - e_{t}) + (n_{c} - e_{c}))}{(n_{t} + n_{c})^2(n_{t} + n_{c} - 1)} \label{harbord.variance}
\end{align}

Similarly to Eggers or Peters Test, now a weighted linear regression can be performed on $r_{i}/v_{i}$ depending on the standard error $1/\sqrt{v_{i}}$ with the $1/v_{i}$ used as weigths. $r_{i}/v_{i}$ is also known as peto odds ratio. 


\section{Reporting Bias Adjustment}
One method to account for reporting bias in meta-analysis is to apply the Trim and Fill adjustment method \citep{trimfill}. It is based on a funnel plot, on which the effect size estimates of studies are plotted against their standard error. If reporting bias is present, the estimate will shift in average towards higher or lower efffect sizes compared to the estimates of larger studies. Trim and Fill is a nonparametric approach.

\vspace{0mm}
The algorithm for the method tries to estimate the number of studies that are not available due to reporting bias, $k$. There are different estimators for $k$. First, $\Delta$ is estimated using a fixed or random effects model. Then, the $k$ effect size estimates with the smallest standard errors are trimmed, and $\Delta$ is estimated again. The procedure is repeated until $k$ is 0 and the funnel plot is symmetric. The total number of missing studies is then mirrored with respect to the final effect size estimate $\Delta$, and $\Delta$ and its standard error is then computed to obtain an unbiased estimate.




% \begin{align} \label{cox reg}
% P(Y < y|\mathbf{x}) = 1 - exp(-exp(h(y) - (\mathbf{x})^\top\beta)
% \end{align}
% 
% See \cite{hothorn} for further information. It specifies the instantaneous risk of an event at time t to be
% 
% \begin{align}
% \lambda_{0}(t)exp((\mathbf{x})^\top\beta) \nonumber
% \end{align}
% 
% The model is regarded as a semi parametric model since it includes the covariates in a linear fashion but leaves the baseline hazard $\lambda_{0}(t)$ unspecified. The factor $exp((\mathbf{x})^\top\beta)$ has the interpretation of a hazard ratio between the reference with $\mathbf{x} = 0$. The formal definition of the hazard is
% 
% \begin{align}
% h(t) = \lim_{h \to 0} \frac{P(t < T < t + h| T > t)}{h}
% \end{align}
% 
% 
% \begin{align} \label{generalized linear model}
% \mathbf{Y}{_{ij}}|U{_i},\epsilon{_{ij}} = (1,x{_i}^\top)\beta + U{_i} + \epsilon{_{ij}}
% \end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% LaTeX file for Chapter 05


\chapter{Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

% LaTeX file for Chapter 01



\chapter{Appendix}

Maybe some R code here, probably a \rr{sessionInfo()}




\cleardoublepage
\phantomsection
\addtocontents{toc}{\protect \vspace*{10mm}}
\addcontentsline{toc}{chapter}{\bfseries Bibliography}


\bibliographystyle{mywiley} 
\bibliography{biblio}

\cleardoublepage

\end{document}

