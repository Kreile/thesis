% LaTeX file for Chapter 03

<<echo=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path='figure/ch02_fig',
    self.contained=FALSE,
    cache=TRUE
)
@

<<echo=FALSE>>=
library(knitr)
opts_chunk$set(fig.path='figure/ch02_fig',
               echo=TRUE, message=FALSE,
               fig.width=8.1, fig.height=3,
               out.width='\\textwidth-3cm',
               message=FALSE, fig.align='center',
               background="gray98", tidy=FALSE, #tidy.opts=list(width.cutoff=60),
               cache=TRUE
)
options(width=74)
@

<<echo = FALSE, warning=FALSE, message=FALSE>>=
rm(list = ls())
PATH_HOME = path.expand("~") # user home
PATH = file.path(PATH_HOME, 'Data/PubBias')
PATH2 = file.path(PATH_HOME, 'PubBias')
FILE = 'cochrane_2018-06-09.csv'
PATH_DATA = file.path(PATH, 'data')
PATH_CODE = file.path(PATH2, 'code')
PATH_RESULTS = file.path(PATH2, 'results')
PATH_FIGURES = file.path(PATH_RESULTS, 'figures')

file_results = "pb.RData"

source(file.path(PATH_CODE, 'PubBias_functions.R'))

file.dat <- "data.RData"
if (file.exists(file.path(PATH_RESULTS, file.dat))) {
	load(file.path(PATH_RESULTS, file.dat))
} else {
	data = pb.readData(path = PATH_DATA, file = FILE)
	tmp = pb.clean(data)
	data = tmp[[1]]
	aliases = tmp[[2]]
	save(data, file =  file.path(PATH_RESULTS, file.dat))
}

load(file.path(PATH_RESULTS, "meta_analyses_summary_bin_cont_surv.RData"))
load(file.path(PATH_RESULTS, "meta_analyses_summary_complete.RData"))
load(file.path(PATH_RESULTS, "meta.bin.RData"))
load(file.path(PATH_RESULTS, "meta.cont.RData"))
load(file.path(PATH_RESULTS, "meta.surv.RData"))
load(file.path(PATH_RESULTS, "data_used_for_analysis.RData"))

###################################################################################################################
###################################################################################################################

#Barbiturate Examples
barbi1 <- arrange(filter(data, file.nr == 21) %>% 
          select(Study = study.name, Comparison = comparison.name, Outcome = outcome.name, 
                 Events = events1, Total = total1, Events_c = events2, Total_c = total2) %>% 
            slice(c(1,3)), Study) 
barbi2 <- arrange(filter(data, file.nr == 21) %>% 
          select(Study = study.name, Comparison = comparison.name,Outcome = outcome.name), Study)
barbi2[barbi2$Study == "P\303\251rez-B\303\241rcena 2008", 1] = "Perez-Barcena 2008"

#Missing values
cont.out <- data %>% filter(outcome.measure.new == "Mean Difference" | outcome.measure.new == "Std. Mean Difference" | 
                                 outcome.measure.new == "Hedges' G") 

missing.mean <- which(is.na(cont.out$mean1) | is.na(cont.out$mean2))
missing.effect <- which(is.na(cont.out$effect))
missing.means <- intersect(missing.mean, missing.effect) #Cont. results that have neither complete means nor an effect
wrong.effect <- which(cont.out$mean1 == 0 & cont.out$mean2 == 0 & cont.out$effect == 0) #Cont.results that have only zeros
missing.effects <- length(c(missing.means, wrong.effect))

missing.sd <- which(is.na(cont.out$sd1) | is.na(cont.out$sd2))
missing.se <- which(is.na(cont.out$se))
missing.sds <- intersect(missing.se, missing.sd) #Cont. results that have neither complete means nor an effect
wrong.sds <- which(cont.out$sd1 == 0 & cont.out$sd2 == 0 & cont.out$se == 0) #Cont.results that have only zeros
missing.sds <- length(c(missing.sds, wrong.sds))

missing.ss <- which(is.na(data$total1) | is.na(data$total2))
wrong.ss <- which(data$total1 <= 0 | data$total2 <= 0)
missing.ssize <- length(c(missing.ss, wrong.ss))

missing.year <- sum(is.na(data$study.year)) + length(c(which(data$study.year < 1920), which(data$study.year > 2019)))

missing.table <- rbind("Missing mean values and mean differences" = missing.effects,
                         "Missing standard deviations and standard errors" = missing.sds,
                         "Missing sample sizes" = missing.ssize,
                         "Missing study year" = missing.year)

#Mean and median number of different outcome types of reviews
mean.diff.out <- data %>% group_by(file.nr, comparison.nr) %>% distinct(outcome.name) %>%
  ungroup() %>% group_by(file.nr) %>%
  count() %>% ungroup %>% summarise(mean = mean(n))

median.diff.out <- data %>% group_by(file.nr, comparison.nr) %>% distinct(outcome.name) %>%
  ungroup() %>% group_by(file.nr) %>%
  count() %>% ungroup %>% summarise(mean = median(n))

#Study.year quantiles:
#data.ext2 <- data.ext %>% mutate(study.year = ifelse(study.year > 1920, study.year, NA))
publication.year.range <- c(quantile(data.ext2$study.year, 0.05, na.rm = T), quantile(data.ext2$study.year, 0.25, na.rm = T), 
                            quantile(data.ext2$study.year, 0.5, na.rm = T), quantile(data.ext2$study.year, 0.75, na.rm = T),
                            round(mean(data.ext2$study.year, na.rm = T), 2), quantile(data.ext2$study.year, 0.95, na.rm = T))

#Outcome.measure frequency table:
outcome.measure.frequencies <- rbind(data %>% group_by(outcome.measure.new) %>% count() %>% 
                                       arrange(desc(n)) %>% ungroup() %>% filter(row_number() < 9),
                                     data %>% group_by(outcome.measure.new) %>% count() %>% arrange(desc(n)) %>% 
                                       ungroup() %>% filter(row_number() > 8) %>% 
                                       summarise(outcome.measure.new = "other", n = sum(n)))

outcome.measure.frequencies <- outcome.measure.frequencies %>% mutate(percentage = round(n/sum(n),3)*100)
names(outcome.measure.frequencies) <- c("Outcome measure", "n", "Percentage")
outcome.measure.frequencies$Percentage <- paste(outcome.measure.frequencies$Percentage, "%", sep = "")

#Total and group size quantiles:
data.ext2 <- data.ext2 %>% ungroup() %>%  mutate(total.n = total1 + total2)
samplesize.range <- c(quantile(data.ext2$total.n, 0.05, na.rm = T), quantile(data.ext2$total.n, 0.25, na.rm = T), 
                            quantile(data.ext2$total.n, 0.5, na.rm = T), quantile(data.ext2$total.n, 0.75, na.rm = T),
                            round(mean(data.ext2$total.n, na.rm = T), 2), quantile(data.ext2$total.n, 0.95, na.rm = T))
treatment.group.size.range <- c(quantile(data.ext2$total1, 0.05, na.rm = T), quantile(data.ext2$total1, 0.25, na.rm = T), 
                      quantile(data.ext2$total1, 0.5, na.rm = T), quantile(data.ext2$total1, 0.75, na.rm = T),
                      round(mean(data.ext2$total1, na.rm = T), 2), quantile(data.ext2$total1, 0.95, na.rm = T))

#Frequencies of results:
comp.freq <- data %>% group_by(file.nr) %>% summarise(n = n())
comp.range <- c(length(which(comp.freq$n < 6)), quantile(comp.freq$n, 0.25, na.rm = T), 
                      quantile(comp.freq$n, 0.5, na.rm = T), quantile(comp.freq$n, 0.75, na.rm = T),
                      round(mean(comp.freq$n, na.rm = T), 2), quantile(comp.freq$n, 0.95, na.rm = T))

#Frequencies of studies:
study.freq <- data %>% group_by(file.nr) %>% distinct(study.name) %>% count()
study.range <- c(length(which(study.freq$n < 3)), quantile(study.freq$n, 0.25, na.rm = T), 
                      quantile(study.freq$n, 0.5, na.rm = T), quantile(study.freq$n, 0.75, na.rm = T),
                      round(mean(study.freq$n, na.rm = T), 2), quantile(study.freq$n, 0.95, na.rm = T))

#Pooling studies
cum.repr.trials.subg <- data %>% group_by(file.nr, comparison.nr, outcome.nr, subgroup.nr) %>% count %>% group_by(n) %>% count %>%
  filter(n < 15) %>%
  full_join( data %>% group_by(file.nr, comparison.nr, outcome.nr) %>% count %>% group_by(n) %>% count %>%
               filter(n > 14) %>% ungroup %>% summarise(n = 15, nn = sum(nn))) %>% 
  ungroup() %>% arrange(desc(n)) %>% mutate(csum  = cumsum(nn)) %>% arrange(n)
# cum.repr.trials.nosub <- data %>% group_by(file.nr, comparison.nr, outcome.nr) %>% count %>% group_by(n) %>% count %>%
#   filter(n < 15) %>%
#   full_join( data %>% group_by(file.nr, comparison.nr, outcome.nr) %>% count %>% group_by(n) %>% count %>%
#                filter(n > 14) %>% ungroup %>% summarise(n = 15, nn = sum(nn))) %>% 
#   ungroup() %>% arrange(desc(n)) %>% mutate(csum  = cumsum(nn)) %>% arrange(n)

# cum.repr.trials <- cbind(cum.repr.trials.nosub, cum.repr.trials.subg)[,c(1,3,6)]

colnames(cum.repr.trials.subg)  <- c("n","Number of groups", "Cumulative sum of groups")













	data <- data %>% mutate(
		outcome.type = ifelse(outcome.measure.new == "Hazard Ratio", "surv", 
													ifelse(outcome.measure.new == "Odds Ratio" | outcome.measure.new == "Risk Ratio" |
																 	outcome.measure.new == "Peto Odds Ratio" | outcome.measure.new == "Risk Difference", "bin", "cont")),
		outcome.type = ifelse(outcome.measure.new == "Rate Ratio" | outcome.measure.new == "Rate difference", "rate", outcome.type),
		lrr = NA,
		var.lrr = NA,
		smd = NA,
		var.smd = NA,
		smd.pbit = NA,
		var.smd.pbit = NA,
		smd.ordl = NA,
		var.smd.ordl = NA,
		cor.phi = NA,
		var.cor.phi = NA,
		pval.single = NA, 
		cor.pearson = NA,
		var.cor.pearson = NA,
		z = NA,
		var.z = NA,
		events1c = NA,
		events2c = NA,
		sig.single = NA)
	cont.ind <- which(data$outcome.type == "cont" & !is.na(data$outcome.type))
	
	data[cont.ind, "outcome.type"] <- data[cont.ind, ] %>% 
		mutate(outcome.type = ifelse(outcome.measure.new == "Std. Mean Difference"  | outcome.measure.new == "Mean Difference", 
																 outcome.type, NA)) %>% select(outcome.type)
	
	cont.ind <- which(data$outcome.type == "cont" & !is.na(data$outcome.type))
	
	
	nomean1.ind <- which(data$outcome.type == "cont" & is.na(data$mean1))
	nomean2.ind <- which(data$outcome.type == "cont" & is.na(data$mean2))
	noeffects.ind <- which(data$outcome.type == "cont" & !is.na(data$effect))
	nomeans.ind <- intersect(nomean1.ind, nomean2.ind)
	nomeans.ind <- intersect(noeffects.ind, nomeans.ind) #no means, but a (std.) mean difference is provided.
	
	data[nomeans.ind,"mean1"] <- data[nomeans.ind,"effect"]
	data[nomeans.ind,"mean2"] <- 0
	
	data[cont.ind,] <- escalc(data = data[cont.ind,], m1i = mean1, m2i = mean2, 
														sd1i = sd1, sd2i = sd2, n1i = total1, n2i = total2,
														measure = "SMD" , append = T, var.names = c("smd", "var.smd"))
	
	inpute.given.ind <- which(is.na(data[cont.ind, "smd"]) & data[cont.ind, "outcome.measure.new"] == "Std. Mean Difference")
	
	
	#Counts of meta-analyses with only zeros:
all.zero.events.number <- data.ext2 %>% filter(outcome.type == "bin") %>% 
  group_by(meta.id) %>% 
    mutate(n = n()) %>% filter(n >= 10) %>% 
  filter(all(events1 == 0) & all(events2 == 0)) %>% 
  distinct(meta.id) %>% ungroup() %>%  count()

#Counts of meta-analyses with means and sds only zeros:
all.zero.means.number <- data.ext2 %>% filter(outcome.type == "cont") %>% group_by(meta.id) %>% 
    mutate(n = n()) %>% filter(n >= 10) %>% filter(all(mean1 == 0) & all(mean2 == 0)) %>% 
    filter(all(sd1 == 0) | all(sd2 == 0)) %>% distinct(meta.id) %>% ungroup() %>% count()

#Counts of meta-analyses with n larger ten:
m.a.largerten.number <- meta %>% filter(k > 9) %>% ungroup %>% count()
#smaller I2 than 0.5:
m.a.smaller.5.number <- meta %>% filter(k > 9 & I2 < 0.5) %>% ungroup %>% count()
#variance ratio > 4:
m.a.variance4.number <- meta %>% filter(k > 9 & I2 < 0.5) %>% filter((se.max^2)/(se.min^2) > 4) %>% ungroup %>% count()
#At least on sig. estimate:
m.a.one.sig.number <- meta %>% filter(k > 9 & I2 < 0.5) %>% filter((se.max^2)/(se.min^2) > 4) %>% filter(n.sig.single > 0) %>% ungroup %>% count()
#Single patient meta-analyses:
tmp <- data.ext2 %>% filter(outcome.type == "cont") %>% group_by(meta.id) %>% 
	mutate(n = n()) %>% filter(n >= 10) %>% filter(!all(mean1 == 0) & !all(mean2 == 0)) %>% 
	filter(!all(sd1 == 0) | !all(sd2 == 0)) 

meta.id.vector <- unique(tmp$meta.id)
m.a.singlepatient.number <- length(meta.id.vector[c(which(meta.id.vector > 42716 & meta.id.vector < 42725))] )
#How many z-score meta-analyses are excluded due to total <= 3, and how many m.a. have then n < 10:
tmp <- data.ext2 %>% group_by(meta.id) %>% mutate(n = n()) %>% filter(n > 9) %>%
	filter(outcome.type != "rate" & !is.na(outcome.type))

metac <- meta %>% filter(k > 9) %>% filter(n.sig.single > 0) %>% filter((se.max^2)/(se.min^2) > 4) %>% filter(I2 < 0.5)

meta.id.vector <- metac$meta.id[-which(metac$outcome.type == "surv")]
meta.id.vector <- meta.id.vector[-c(which(meta.id.vector == 157083),
																which(meta.id.vector == 159329),
																# which(meta.id.vector == 12459),
																# which(meta.id.vector == 12465),
																# which(meta.id.vector == 22087),
																which(meta.id.vector == 182298))] 

meta.data.zscore <- tmp[which(tmp$meta.id %in% meta.id.vector),]
total.seq3.number <- meta.data.zscore %>% filter(total1 + total2 < 4) %>% select(var.z) %>% ungroup() %>% count() 
m.a.seq3.seq10.number <- meta.data.zscore %>% filter(total1 + total2 > 3) %>% count() %>% filter(nn < 10) %>% ungroup %>% count()

meta.id.vector <- metac$meta.id
meta.data <- data.ext2[which(data.ext2$meta.id %in% meta.id.vector),]


@




\chapter{The Cochrane Dataset} \label{ch:dataset}


\section{Cochrane Systematic Reviews}
The Cochrane Group has specialized on systematic reviews in clinical science. Certain knowledge of standards and principles of the Cochrane Group may help to assess the quality and the properties of the dataset. The following information stems from the Cochrane Handbook for Systematic Reviews \citep{cochrane.handbook}. \\
The definition of a systematic review is that it ``attempts to collate all empirical evidence that fits pre-specified eligibility criteria in order to answer a specific research question.'' Thus, the ``key properties of a review are'':

\begin{itemize}
\item``a clearly stated set of objectives with pre-defined eligibility criteria for studies''
\item ``an explicit, reproducible methodology''
\item ``a systematic search that attempts to identify all studies that would meet the eligibility criteria''
\item ``an assessment of the validity of the findings of the included studies, for example through the assessment of risk of bias''
\end{itemize}

At the end of a systematic review, ``a systematic presentation, and synthesis, of the characteristics and findings of the included studies'' is done. \\
53 Cochrane Review Groups prepare and maintain the reviews within specific areas of health care. A group consists of ``researchers, healthcare professionals and people using healthcare services (consumers)''. \\
The groups are supported by Method Groups, Centers and Fields. The Cochrane Method Groups aim to discuss and consult the groups in methodological questions concerning review preparation. The Centers play a main role in training and support of the Groups. The Fields are responsible for broad medical research areas and follow priorities in those areas by advice and control of the groups. \\
The first step in a review is writing a protocol, specifying the research question, the methods to be used in literature search and analysis and the eligibility criteria of the study. Changes in protocols are possible but have to be documented and the protocol is published in advance of the publication of the full review. The choices of methodology as well as the changes should not be made ``on the basis of how they affect the outcome of the research study''. \\
In order to avoid potential conflicts of interests, there is a code of conduct that all entities of the Cochrane Organization have to agree on: conflicts of interest must be disclosed and possibly be forwarded to the Cochrane Center, and participation of review authors in the studies used have to be acknowledged. Additionally, a Steering Group publishes a report of potential conflicts of interests based on information about external funding of Cochrane Groups. \\
In order for keeping the reviews up-to-date, they are revised in a two-year circle with exceptions. In addition to inclusion of new evidence in a field, the revision and maintenance process may as well includes change in analysis methods. This can reflect some advance in clinical science as for example new information about important subgroups, as well as new methods for conducting a Cochrane Review. However, there are no clear guidelines and the Cochrane Groups are free in the rate and extent of up-dating their reviews.

\subsection{Methods for Cochrane Reviews}
A research question defines the following points: ``the types of population (participants), types of interventions (and comparisons), and the types of outcomes that are of interest''. From the research question, usually the eligibility criteria follow. Usually, outcomes are not part of eligibility criteria, except for special cases such as adverse effect reviews. \\
The type of study is an important eligibility criterium. The Cochrane Collaboration focuses ``primarily on randomized controlled trials'', and also, the methods of study identification in literature search are focused on randomized trials. Furthermore, study characteristics such as blinding of study operators with respect to treatment and cluster-randomizing might be additional eligibility criteria which have to be chosen by the review authors. \\
After having specified the eligibility criteria, studies have to be collected. The central idea of systematic reviews, and also meta-analyses, is that the collected studies are a random sample of a population of studies, i.e. that they are representative and can be used to assess population properties. Therefore, the search process is crucial, as a selective search result may impose bias on the sample of studies available, making it a non-random sample. For this purpose, the Cochrane Groups are advised to go beyond MEDLINE !!cite!!, because a search restricted to it has been shown to deliver only 30\% to 80\% of available studies. ``Time and budget restraints require the review author to balance the thoroughness of the search with efficiency in use of time and funds and the best way of achieving this balance is to be aware of, and try to minimize, the biases such as publication bias and language bias that can result from restricting searches in different ways.'' It is important to note that not only studies, but also study reports are occasionally used in the reviews, as they may provide useful information. \\
There are different sources that are being used to search for studies. 
\begin{itemize}
\item The Cochrane Central Register of Controlled Trials is a source of reports of controlled trials. ``As of January 2008 (Issue 1, 2008), CENTRAL contains nearly 530,000 citations to reports of trials and other studies potentially eligible for inclusion in Cochrane reviews, of which 310,000 trial reports are from MEDLINE, 50,000 additional trial reports are from EMBASE and the remaining 170,000 are from other sources such as other databases and handsearching.'' It includes citations published in many languages, citations only available in conference proceedings, citations from trials registers and trials results registers.
\item MEDLINE. MEDLINE includes over 16 million references to journal articles. 5,200 journals publishing in 27 languages are indexed for MEDLINE. PubMed gives access to a free version of MEDLINE with up-to-date citations. NLM gateway such as the Health Services Research Project, Meeting Abstracts and TOXLINE Subset for toxicology citations allows for search in both databases together with additional data from the US National Library of Medicine.
\item EMBASE. 4,800 Journals publishing in 30 languages are indexed to EMBASE, which includes more than 11 million records from 1974 onward. EMBASE.com also includes 7 million unique records from MEDLINE (1966 up to date) together with its own records. Additionally, EMBASE Classic allows access to digitized records from 1947 to 1973. EMBASE and MEDLINE each have around 1,800 journals not indexed in the other database.
\item Regional or national and subject specific databases can additionally be consulted and often provide important information. Financial considerations may limit the use of such databases.
\item General search engines such as Google Scholar, Intute and Turning Research into Practice (TRIP) database can be used.
\item Citation Indexes. The database lists articles published in around 6,000 Journals with articles in which they have been cited and is available online as SciSearch. This form of search is known as cited reference searching.
\item Dissertation sources. Dissertations are often listed in MEDLINE or EMBASE but one is advised to also search in specific dissertation sources.
\item Grey Literature Databases. Approximately 10\% of the results in the Cochrane Database stems from conference abstracts and other grey literature. The Institute for Scientific and Technical Information in France provides access to entries of the previously closed System for Information on Grey Literature database of the European Association for Grey Literature Exploitation). Another source is the Healthcare Management Information Consortium (HMIC) database containing records from the Library and Information Services department of the Department of Health (DH) in England and the King's Fund Information and Library Service. The National Technical Information Service (NTIS) gives access to the results of US and non-US government-sponsored research, as well as technical report for most published results. References from newsletters, magazines and technical and annual reports in behavioral science, psychology and health are provided in the PsycEXTRA database which is linked to PsycINFO database.
\end{itemize}


\subsection{Structure and Content}
The dataset consists of \Sexpr{length(unique(data$file.nr))} systematic reviews from the Cochrane Library with \Sexpr{length(unique(data$study.name))} studies and \Sexpr{dim(data)[1]} results. A result compares a clinical or medical intervention or treatments to a control. Each study provides (multiple) results of clinical interventions. \\
In Table \ref{barbiturate.row}, two results from a systematic review about effects of barbiturates are shown as they are given in the dataset. As can be seen, further specifications are provided by the variables in the columns. \\
The comparison variable specifies \textit{what kind} of treatments or interventions are compared, the outcome variable \textit{how} it is compared, and the subgroup variable (not indicated in table) if the result belongs to a certain subgroup. Here, the result is of a binary type, so the counts of events in the barbiturate treatment group and the total number of participants are given in columns ``Events'' and ``Total'' and the number of events in the control group ``Events\_c'' and participants ``Total\_c''. A event is here death at the end of follow up.

<<echo=FALSE, results = 'asis'>>=
print(xtable(barbi1, label = "barbiturate.row", digits = 0,
             caption = "Example of two results as given in the dataset. Events denotes the count of events in the treatment group while Events c the count of events in the group compared to. Further descriptive variables have been ommitted"), 
      include.rownames = F, size = "scriptsize")
@

A complete listing of the variables of a result is given in Table \ref{variable}. They can roughly be separated into variables that \textit{specify the review} in which the result is contained and variables that \textit{specify the result} itself (separated by a horizontal line in Table \ref{variable}):

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{l l}
      \textbf{Variable} & \textbf{Description}\\
      \hline
      \texttt{file.nr} & The number of the file from which the review data has been \\&gathered. This file corresponds to a file available in the. \\& Cochrane library\\
      \texttt{doi} & Digital object identifier. A unique id of the review such that  \\ &the full text of the review can be found on the web.\\
      \texttt{file.index} & Internal index of the file in the Cochrane library.\\
      \texttt{file.version} & Denotes the version of the review, since the reviews are \\ &occasionally updated.\\
      %\multicolumn{2}{c}{textbf{Study level variables}}\\ 
      \hline
      \texttt{study.name} & Name of the study to which the result belongs\\
      \texttt{study.year} & Year in which the study was published\\
      \hline
      \texttt{comparison.name/.nr} & Specification of the interventions compared in the study  \\ &and a unique number for the comparison\\
      \texttt{outcome.name/.nr} & Specification by which outcome the interventions are compared\\ &and a unique number for the outcome\\
      \texttt{subgroup.name/.nr} & Potentially indication of affiliation to subgroups and a \\ &unique number for the subgroup\\
      \texttt{outcome.measure} & Indication of the quantification method of the effect \\ &(of one intervention compared to the other).\\
      \texttt{effect} & Measure of the effect given in the quantity denoted by \\ &\texttt{outcome measure}.\\
      \texttt{se} & Standard error of the measure of the effect,\\
      \texttt{events1/events2} & The counts of patients with an outcome \textit{if}\\ &measurement/outcome is binary or dichotomous \\ &2 (1 for treatment group and 2 for control group).\\
      \texttt{total1/total2} & Number of patients in groups.\\
      \texttt{mean1/mean2} & Mean of patient measurements \textit{if} outcome is continuous.\\
      \texttt{sd1/sd2} & Standard deviation of mean \textit{if} \\ &outcome is continuous.
    \end{tabular}
  \caption{Dataset variable names and descriptions  \label{variable}}

  \end{center}
\end{table}

Results are part of studies that are again part of a (systematic) review. This structure of a review is shown in Figure \ref{review}. 

\begin{figure}
\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=red,fill=red!30]
\tikzstyle{optional}=[dashed,fill=gray!50]
\begin{tikzpicture}
[grow = right, anchor = west, 
  growth parent anchor=east, % added code
  parent anchor=east]
  \node {Review} [edge from parent fork right]
    child { node {Comparison 2}
      child { node {Outcome 2}}
      child { node {Outcome 1}
        child { node {Subgroup 2}}
        child { node {Subgroup 1}
          child  { node {Result 2}}
          child  { node {Result 1}}
          }}
    }
    child [missing] {}		
    child { node {Comparison 1  }};
\end{tikzpicture}
\caption{Structure of a hypothetical review with two different comparisons}
\label{review.structure}
\end{figure}

\vspace{0mm}
The structure of a review will now be outlined based on an example of the dataset. Let us consider the previously mentioned barbiturate and head injury review. The aim was to ``assess the effects of barbiturates in reducing mortality, disability and raised ICP (intra-cranial pressure) in people with acute traumatic brain injury'' as well as to ``quantify any side effects resulting from the use of barbiturates''. \\
%Since there are arguments for and against use of barbiturates, the authors of the review did a comprehensive literature search and collected all available study findings. 
The review comprises five studies in total. Three of them compared barbiturate to placebo, one compared barbiturate to Mannitol and one Pentobarbital to Thiopental. The studies have different outcomes, for example, death or death and severe disability at follow up, but also dropout counts or adverse effects (secondary outcomes). 
We have continuous (e.g. mean body temperature) and binary outcome data (e.g. death/no death). One study split up outcomes for patients with and without haematoma, which would be subgroups. Thus, it is important not to confuse results with studies. A study can contribute multiple results to a systematic review, for example, primary and secondary outcomes and adverse effects. 

<<echo=FALSE, results='asis'>>=
print(xtable(barbi2, label = "barbiturates", caption = "Barbiturate and head injury review. In the columns, study names, comparison and outcome measure of the results are given"), include.rownames = F, size = "footnotesize")
@

Information about missing values in the dataset is given in Table \ref{missing}. For variables as research subject, outcome and subgroup name and event counts there are no missing values. The relative amount of missing values is very low except for study years. For continuous outcomes, the cases have been counted were no treatment effect and standard error is available: neither mean values and standard deviations, nor mean differences and standard error. Also Study years before 1920 and after 2019 are declared as missing, as well as sample sizes below zero.

<<echo=FALSE, results='asis'>>=
print(xtable(missing.table, label = "missing", caption = "Number of missing variables and measurements in the dataset", align = "lr"), include.colnames = F,
      size = "footnotesize", digits = 0)
@

The studies that are included in the reviews and have been published are most often from the years after 1980 (5\% quantile = \Sexpr{publication.year.range[1]}, 95\% quantile = \Sexpr{publication.year.range[6]},). The median of the publication years is \Sexpr{publication.year.range[3]}, the mean \Sexpr{publication.year.range[5]} and the quartiles are \Sexpr{publication.year.range[2]} and \Sexpr{publication.year.range[4]}. Only a handful ($n = 18$) have been published in 2018, none in 2019. \\
%No information is available concerning unpublished results and studies.
The top treatment effect measure (risk ratio, mean difference, hazard ratio etc.) abundances are summarized in Table \ref{outcome.measure.frequencies}. One can conclude of the table that roughly 30 \% of outcomes in the dataset are continuous and the rest being some sort of discrete or binary outcomes, most often binary (> 65\%).

<<echo=FALSE, results='asis'>>=
print(xtable(outcome.measure.frequencies, label = "outcome.measure.frequencies", 
             caption = "Frequencies of outcome measures among results. n denotes the total number 
             of results with the outcome measure and percentage the percentage of the outcome measure,", 
             align = "llrr", digits = 1), include.rownames = F, size = "footnotesize")
@


The sample sizes among results vary to some extent. There are 5\% of treatment group sample sizes that are smaller than \Sexpr{treatment.group.size.range[1]}, the 5\% quantile and 95\% smaller than \Sexpr{treatment.group.size.range[6]}. The first quartile is \Sexpr{treatment.group.size.range[2]}, the median \Sexpr{treatment.group.size.range[3]}, the mean \Sexpr{treatment.group.size.range[5]} and the third quartile \Sexpr{treatment.group.size.range[4]}. The large difference between median and mean is caused by very large groups with over 2,000,000 participants. Analogously, the quantiles of the total sample size are: 5\% quantile = \Sexpr{samplesize.range[1]}, first quartile = \Sexpr{samplesize.range[2]}, median = \Sexpr{samplesize.range[3]}, third quartile = \Sexpr{samplesize.range[4]} and 95\% = \Sexpr{samplesize.range[6]}. The mean is \Sexpr{samplesize.range[5]}. \\
The mean and median number of results per review are \Sexpr{study.range[5]} and \Sexpr{study.range[3]}. There are \Sexpr{comp.range[1]} reviews with five or fewer results, and the quartiles are \Sexpr{comp.range[2]} and \Sexpr{comp.range[4]}. Similarly, the number of reviews with a maximum of two studies included is \Sexpr{study.range[1]}, the mean study number is \Sexpr{study.range[5]}, the median \Sexpr{study.range[3]} and the interquartile range \Sexpr{study.range[2]} and \Sexpr{study.range[4]} and the 95\% quantile \Sexpr{study.range[6]}. The discrepancy between mean and median is due to large reviews with a high number of studies and results, most extreme in \citet{largest.review} which is a systematic review about antibiotic prophylaxis for preventing infection after cesarean section, with 95 studies and 1497 results in total.\\
For results to be suitable for usage in meta-analysis, they have to be identical with respect to comparison and outcome. More specifically, the studies in the dataset that have the same comparison, outcome and subgroup can be pooled in a meta-analysis, since their research subject and experimental setup can be considered sufficiently homogeneous. Importantly, this distinction is also used by the Cochrane Organization itself, i.e. the meta-analyses are identical to the meta-analyses done in the systematic reviews.\\ %Another approach that is not made here is to analyze all subgroups together, which is possible if enough studies are given.
The dataset is divided in meta-analyses with identical experimental setup. The size of a meta-analysis denotes how many results are included in a group.
Table \ref{repr.groups} shows the number of meta-analysis with size $\geq n$ results. Practically, this number of meta analyses can be performed, with each having at least $n$ results.

<<echo=FALSE, results='asis'>>=

print(xtable(cum.repr.trials.subg, label = "repr.groups", caption = "Cumulative number of groups with number of reproduction trials $\\geq$ n", align = "llrr", digits = 0), include.rownames = F, size = "footnotesize")
@

\section{Data Tidying and Processing} \label{sec:Processing}
The original dataset was provided by .. (some words how the dataset was obtained and processed by C.R.). \\
The information in the previous pages are from a tidied and processed version of this dataset. \\

\subsection{Modification of old variables}
In some cases, reasonable assumptions led to small changes in the originally provided variables:
\begin{itemize}
\item \texttt{study.year}: It was assumed that studies that are declared to have been published before 1920 ($n$ = \Sexpr{length(which(data$study.year < 1920))}) are mis-specified, as well as after 2019 ($n$ = \Sexpr{length(which(data$study.year > 2019))}), so these have been set to NA. 
\item \texttt{mean1} and \texttt{mean2}: When both \texttt{mean1} and \texttt{mean2} are equal to zero or NA, \texttt{outcome.measure.new} is equal to \texttt{(Std.) Mean Difference}, but a mean difference is given in \texttt{effect}, \texttt{mean1} is set equal to \texttt{effect} ($n$ = \Sexpr{length(nomeans.ind)}).
\end{itemize}


\subsection{Newly Introduced Variables}
Some new variables are added to the obtained dataset:
\begin{itemize}
\item \texttt{outcome.measure.new}: Outcome measure specifications given in \texttt{outcome.measure} were standardized whenever they were supposed to denote the same outcome measure. An example would be the formally different notations for odds ratios: ``Odds Ratio'', ``odds ratio'', ``OR'', which were all denoted as ``Odds Ratio''.
\item \texttt{outcome.type}: A simplification of \texttt{outcome.measure.new}. The outcome.type ``bin'' indicates if \texttt{outcome.measure.new} is either one of ``Risk Ratio'', ''Odds Ratio'', ``Risk difference'' or ``Peto Odds Ratio''. ``cont'' is equivalent to \texttt{outcome.measure.new} equal to "Std. Mean Difference'' or ``Mean Difference''. ``surv'' equal to ``Hazard Ratio'' and ``rate'' equal to ''Rate Ratio'' or ``Rate Difference''.
\item \texttt{lrr} and \texttt{var.lrr}: log risk ratio and variance of the log risk ratio for outcome.type ``bin''.
\item \texttt{smd} and \texttt{var.smd}: Hedges $g$ and the variance of Hedges $g$ for outcome.type ``cont''. If not computable from \texttt{mean1}, \texttt{mean2}, \texttt{sd1} and \texttt{sd2}, and \texttt{outcome.measure.new} was equal to ``Std. Mean Difference'', it was set equal to \texttt{effect} (and \texttt{var.smd} equal to \texttt{se} squared, $n$ =  \Sexpr{length(inpute.given.ind)}).
\item \texttt{smd.ordl} and \texttt{var.smd.ordl}: Cohen's $d$ and its variance as obtained by transformation of a log odds ratio for outcome.type ``bin''.
\item \texttt{cor.Pearson} and \texttt{var.cor.Pearson}: Pearson correlation coefficient and variance as obtained from the $d$ (for outcome.type ``bin'') or $g$ (for outcome.type ``cont'') to $r$ transformation.
\item \texttt{z} and \texttt{var.z}: Fisher's z score and it's variance obtained from the Pearson correlation $r$ to $z$ transformation.
\item \texttt{pval.single}: $p$-value against the null hypothesis of no treatment effect, derived by a $t$-test for outcome.type ``cont'' or Wald test for outcome.type ``bin''.
\item \texttt{events1c} and \texttt{events2c}: Correction of \texttt{events1} and \texttt{events2} zero event counts or event counts = patient number. When no events occurred, 0.5 was added, and when all patients experienced the event, 0.5 was subtracted. When one of \texttt{events} had zero counts while the other had maximum counts, no adjustment occurred.
\item \texttt{meta.id}: Meta-analysis ID variable to uniquely identify any potential meta-analysis in the dataset. Consistent to what has been discussed before, all results that share a common comparison, outcome and subgroup (optional, subgroups not given in any case) may be combined in a meta-analysis.
% \item \texttt{}:
% \item \texttt{}:
\end{itemize}


\subsection{Eligibility criteria for Publication Bias Test and Adjustment} 
Initially, the analysis is restricted to binary, continuous and survival outcomes. More formally:
\begin{itemize}
\item \textbf{Outcome measures}: The analysis has been restricted on the following outcome measures (from \texttt{outcome.measure.new}): ``Odds Ratio'', ``Risk Ratio'', ``Risk difference'', ``Peto Odds Ratio'', ``Std. Mean Difference'', ``Mean Difference'', ``Hazard Ratio'' 
($n$ = \Sexpr{length(data.ext2$outcome.type[which(data.ext2$outcome.type == "bin" | data.ext2$outcome.type == "cont" | data.ext2$outcome.type == "surv")])} out of a total of \Sexpr{length(data.ext2$outcome.type)} results)
\end{itemize}

The suggestions of criteria for eligibility for publication bias tests of \citet{Ioannidis2007} have largely been followed:
\begin{itemize}
\item \textbf{Sample size}: A meta-analysis is comprised of at least ten studies ($n$ = \Sexpr{m.a.largerten.number} remaining). 
\item \textbf{Heterogeneity}: The $I^2$ statistic of a given meta-analysis is smaller than 0.5, thus, the proportion of between study variance of the overall variance is smaller than 0.5 ($n$ = \Sexpr{m.a.smaller.5.number} remaining).
\item \textbf{Study size}: The ratio between largest variance of an estimate and smallest variance of an estimate is larger than four ($n$ = \Sexpr{m.a.variance4.number} remaining).
\item \textbf{Significance}: At least one treatment effect has a $p$-value below the significance threshold 0.05 ($n$ = \Sexpr{m.a.one.sig.number} remaining)
\end{itemize}

After having excluded meta-analyses with less than ten studies, additional criteria for excluding inconvenient meta-analyses are:
\begin{itemize}
\item \textbf{Sensitivity Analyses}: When the same results are used multiple times for different meta-analyses, only one is retained. More precisely, if a study hat the same \texttt{study.name} and same \texttt{effect}, it was considered a duplicate, and the smaller meta-analysis of the two was excluded. The intention is to exclude sensitivity analyses which are operated on subsets of the available results.
\item \textbf{Zero events}: In the case of binary outcomes, meta-analyses with zero events in any study and any group are excluded ($n$ = \Sexpr{all.zero.events.number} out of meta-analyses with at least ten studies).
\item \textbf{Missing means and sd's}: In the case of continuous outcomes, meta-analyses with means and sd's in any group being equal to zero are excluded ($n$ = \Sexpr{all.zero.means.number} out of meta-analyses with at least ten studies).
\item \textbf{Single patient data}: Meta-analyses that are comprised of single patient data are excluded ($n$ = \Sexpr{m.a.singlepatient.number} out of meta-analyses with at least ten studies)
\end{itemize}

--Make Flowchart--

\subsubsection{Exclusions due to Computational Errors}
In exceptional cases, the applied meta-analysis methods and publication bias tests and adjustment algorithms failed due to various reasons. Here, those cases are listed and if known, the reasons why computation failed are given.\\
\textbf{Binary Outcomes}: Out of the meta-analyses that are of \texttt{outcome.type} bin, and have at least ten studies, two studies hat to be excluded:
\begin{itemize}
\item meta.id = 62301 (file.nr = 1531, comparison.nr = 8, outcome.nr = 6, subgroup.nr = 1):
%A subgroup analysis for women with increased adverse pregnancy outcomes, where the effect of vitamin C supplements is tested on pre-eclampsia: 
Largest study (se = 0.1) has risk ratio 1 and smallest study (se = 1) risk ratio 0.07. Copas publication bias adjustment methods has likelihood optimization issues.
\item meta.id = 94519 (2519, 14, 1, 2): Largest study (se = 0.05) has risk ratio 0.9 and smallest study (se = 0.4) risk ratio 3. Again Copas publication bias adjustment methods has likelihood optimization issues.
\end{itemize}

There were no issues with \texttt{outcome.type} ``cont'' and ``surv''. For the subsequent information, it is important to know that meta-analyses are only repeated with Hedges $g$, Pearson correlation coefficient and Fisher's Z-scores, if the outcome type is not survival and all of the above criteria are met ($n$ = \Sexpr{length(meta.f$n.sig.type[which(meta.f$outcome.type != "surv")])}). \\
\textbf{Pearson Correlation Coefficient}: Three studies had to be excluded when analyzing the Pearson correlation coefficients:
\begin{itemize}
\item meta.id = 157083 (file.nr = 5061, comparison.nr = 1, outcome.nr = 5, subgroup.nr = 2): A meta-analysis with all results from the same study, and equal sample size (5 each group). The Copas selection model algorithm issued an error when optimizing the likelihood.
\item meta.id = 159329 (5183, 3, 13): One very small study with group sizes of 2 and 1 patients and small risk ratio of 0.222 (compared to the largest of 1.05, se = 0.04). Also, the Copas selection model algorithm issued an error when optimizing the likelihood.
\item meta.id = 182298 (6211, 1, 8, -): One very small study with 8 patients in each group and 0 event counts in both. The Copas selection model algorithm issued an error when optimizing the likelihood.
\end{itemize}

\textbf{Fisher's Z score}: The same issues as encountered for Pearson correlation coefficients (meta.id = 157083 and 159329). The variance of the z score $s_z^2$ can be calculated as:  $s_z^2 = \frac{1}{n-3}$, $n$ being the total sample size. Thus, studies that have total sample size $n \geq 3$ are discarded in the meta-analyses ($n$ = \Sexpr{total.seq3.number} studies). \Sexpr{m.a.seq3.seq10.number} meta-analyses have then less than 10 studies left for pooling: 
\begin{itemize}
\item meta.id = 10671: (file.nr = 5061, comparison.nr = 1, outcome.nr = 5, subgroup.nr = 2), 7 studies left.
\item meta.id = 43324: (1019, 1, 3, 2), 9 studies left.
\end{itemize}

\subsubsection{The Publication Bias Test and Adjustment Dataset}
The dataset that was ultimately tested and adjusted for publication bias comprises \Sexpr{dim(metac)[1]} meta-analyses and \Sexpr{dim(meta.data)[1]} results. ..


% \begin{itemize}
% \item meta.id = 136563 (4218, 1, 1, 1): ``Roberts 2010'' (3)
% \item meta.id = 136566 (4218, 1, 3, 1): ``Roberts 2010'' (3)
% \end{itemize}




%which leads to a reduction of the meta-analyses that can be calculated based on the Fisher's z score by $n$ = \Sexpr{}























