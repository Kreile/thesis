% LaTeX file for Chapter 01
<<'preambleA1',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path='figure/cha1_fig', 
    self.contained=FALSE,
    cache=TRUE
)

@


\chapter{Appendix}

<<>>=
sessionInfo()
@



\section{Data Pre-processing}

<<eval=FALSE>>=
#Dataset processing function to get transformed effect sizes, p-values, event 
# counts with increments, etc. :
pb.process3 <- function(data){
  data <- data %>% mutate(meta.id = 
            group_indices(., id, comparison.id, outcome.id, subgroup.id)) %>%
    group_by(meta.id) %>% mutate(study.id2 = row_number()) %>% ungroup()
  
  #Mark duplicate effects between meta-analyses:
  data <- data %>% group_by(meta.id) %>%
    mutate(n = n())  %>% ungroup() %>% group_by(id) %>% 
    mutate(dupl.id = 
         dupl.finder(effects = effect, names = study.name, metas = meta.id), 
           dupl.remove = 
  dupl.max.finder(duplicate.index = dupl.id, study.number = n, metas = meta.id)) %>% 
    ungroup()
  
  data <- data %>% mutate(lrr = NA,
    var.lrr = NA,
    hedgesg = NA,
    var.hedgesg = NA,
    cohensd = NA,
    var.cohensd = NA,
    smd.ordl = NA,
    var.smd.ordl = NA,
    pval.single = NA, 
    cor.pearson = NA,
    var.cor.pearson = NA,
    z = NA,
    var.z = NA,
    events1c = NA,
    events2c = NA,
    sig.single = NA,
    smd.pool = NA,
    se.smd.pool = NA)

  
  cont.ind <- which(data$outcome.flag == "CONT")
  bin.ind <- which(data$outcome.flag == "DICH")
  IV.ind <- which(data$outcome.flag == "IV")
  #----------------------------------------------------------------------------------------------#
  
  #Outcome.flag == "DICH"
  data[bin.ind,] <- escalc(data = data[bin.ind,], ai = events1, n2i = total2, 
                           ci = events2, n1i = total1, 
                           to = "only0",
                           add = 1/2,
                           measure = "RR", append = T, 
                      var.names = c("lrr", "var.lrr")) #Calculate Risk Ratios

  data[bin.ind,] <- escalc(data = data[bin.ind,], ai = events1, n2i = total2, 
                           ci = events2, n1i = total1, 
                           to = "only0",
                           add = 1/2,
                           measure = "OR2DL", append = T, 
  var.names = c("smd.ordl", "var.smd.ordl")) #Calculate SMD (w. logistic transf.)

  #What to do if there are 0/total cells:
  data[bin.ind,] <- data[bin.ind,] %>% 
    mutate(events1c  = case_when(events1 == 0 ~ events1 + 0.5,
                                 events2 == 0 ~ events1 + 0.5,
                                 events1 - total1 == 0 ~ events1 - 0.5,
                                 events2 - total2 == 0 ~ events1 - 0.5,
                                 TRUE ~ events1),
           events2c = case_when(events2 == 0 ~ events2 + 0.5,
                                events1 == 0 ~ events2 + 0.5,
                                events2 - total2 == 0 ~ events2 - 0.5,
                                events1 - total1 == 0 ~ events2 - 0.5,
                                TRUE ~ events2))
  
  #What to do if there is one zero and one total:
  data[bin.ind,] <- data[bin.ind,] %>% 
    mutate(events1c  = case_when(events2 == 0 & events1 - total1 == 0 ~ events1,
                                 events1 == 0 & events2 - total2 == 0 ~ events1,
                                 TRUE ~ events1c),
           events2c = case_when(events2 == 0 & events1 - total1 == 0 ~ events2,
                                events1 == 0 & events2 - total2 == 0 ~ events2,
                                TRUE ~ events2c))
  data[bin.ind, "pval.single"] <- data[bin.ind, ] %>% 
    mutate(pval.single = 2*(1-pnorm(abs(lrr/sqrt(var.lrr))))) %>% select(pval.single)
  #----------------------------------------------------------------------------------------------#
  
  #Outcome.flag == "CONT"
  data[cont.ind,] <- escalc(data = data[cont.ind,], m1i = mean1, m2i = mean2, 
                            sd1i = sd1, sd2i = sd2, n1i = total1, n2i = total2,
                            measure = "SMD" , append = T, 
                var.names = c("hedgesg", "var.hedgesg")) #Calculate Hedge's g
  
  data[cont.ind, ] <- data[cont.ind, ] %>% 
    mutate(cohensd = (mean1 - mean2)/sqrt((((total1 - 1)*sd1^2) + 
                    (total2 - 1)*sd2^2)/(total1 + total2 - 2)),
           var.cohensd = ((total1 + total2)/(total1 * total2)) + 
             (cohensd^2)/(2*(total1 + total2)))

  data[cont.ind, ] <- data[cont.ind, ] %>% 
    mutate(cohensd = case_when(sd1 == 0 ~ NA_real_,
                               sd2 == 0 ~ NA_real_,
                               total2 == 0 ~ NA_real_,
                               total1 == 0 ~ NA_real_,
                               TRUE ~ cohensd))
  
  #p-value for continuous outcomes (Student):
  data[cont.ind, "pval.single"] <- data[cont.ind, ] %>% 
    mutate(t = (mean1 - mean2)/(sqrt((((total1-1)*sd1^2) + (total2-1)*sd2^2)/
                          (total1 + total2 -2))*sqrt((1/total1)+(1/total2))), 
           pval.single = 2*(1-pt(abs(t), df = total1 + total2 - 2))) %>% 
    select(pval.single)
  
  sd1.0 <- which(data$outcome.flag == "CONT" & data$sd1 == 0) 
  sd2.0 <- which(data$outcome.flag == "CONT" & data$sd2 == 0)
  sd.0 <- union(sd1.0, sd2.0)
  data[sd.0, "pval.single"] <- NA #Such that p-value here is not equal to zero
  #----------------------------------------------------------------------------------------------#
  
  #Outcome.flag == "IV"
  data[IV.ind, "pval.single"] <- data[IV.ind, ] %>% 
    mutate(pval.single = 2*(1-pnorm(abs((effect)/se)))) %>% 
    select(pval.single)
  #----------------------------------------------------------------------------------------------#
  
  #Declare smd.ordl, cohensd and SMD of IV flag all as "smd.pool":
  data <- data %>% 
    mutate(smd.pool = case_when(outcome.flag == "DICH" ~ smd.ordl,
                                outcome.flag == "CONT" ~ cohensd,
                                outcome.flag == "IV" & 
                                  outcome.measure.merged == "SMD" ~ effect,
                                TRUE ~ NA_real_),
           se.smd.pool = case_when(outcome.flag == "DICH" ~ sqrt(var.smd.ordl),
                                   outcome.flag == "CONT" ~ sqrt(var.cohensd),
                                   outcome.flag == "IV" & 
                                     outcome.measure.merged == "SMD" ~ se,
                                   TRUE ~ NA_real_))
  #----------------------------------------------------------------------------------------------#
  
  #Transform effect sizes:
  smd.pool.ind <- which(!is.na(data$smd.pool))
  
  #Pearson correlation:
  data[smd.pool.ind, "cor.pearson"]<- data[smd.pool.ind, ] %>% mutate(
    a = ((total1 + total2)^2)/(total1*total2),
    cor.pearson  = smd.pool/sqrt((smd.pool^2) + a),
    var.cor.pearson = ((a^2)*se.smd.pool^2)/(((smd.pool^2)+a)^3)) %>% 
    select(cor.pearson)
  
  data[smd.pool.ind, "var.cor.pearson"]<- data[smd.pool.ind, ] %>% 
    mutate(
    a = ((total1 + total2)^2)/(total1*total2),
    cor.pearson  = smd.pool/sqrt((smd.pool^2) + a),
    var.cor.pearson = ((a^2)*se.smd.pool^2)/(((smd.pool^2)+a)^3)) %>% 
    select(var.cor.pearson)
  
  #Fisher's z-score:
  data[smd.pool.ind, "z"] <- data[smd.pool.ind, ] %>% 
    mutate(z = atan(x = cor.pearson),
           var.z= 1/(total1 + total2 - 3)) %>% select(z)
  data[smd.pool.ind, "var.z"] <- data[smd.pool.ind, ] %>% 
    mutate(z = atan(x = cor.pearson), 
           var.z= 1/(total1 + total2 - 3)) %>% select(var.z)
  
  #----------------------------------------------------------------------------------------------#
  data$sig.single <- ifelse(data$pval.single < 0.05, 1, 0)
  
  return(data)
}


########################################################################################################

#Function to find sensitivity analyses.  The function gives all meta-analyses 
#that are subdivided
#into sensitivity analyses a common number. 
#*to use with "data %>% mutate(.. = dupl.finder(..))"*
dupl.finder <- function(effects, names, metas){
  
  results <- rep(NA, times = length(effects))
  meta.double.marker <- 1
  
  
  for(u in seq_along(effects)){
    
    if(is.na(results[u])){
      
      double.indices <- which(effects[u] == effects & names[u] == names)
      
      if(length(double.indices) > 1){
    #If any meta-analysis has already duplicates, give all the same double marker
        if(any(!is.na(results[double.indices]))){ 
          
          already.marked <- which(!is.na(results[double.indices]))
          meta.double.marker.2 <- unique(results[double.indices[already.marked]])
          #Collect meta.ids with same double markers
          meta.ids.2 <- unique(metas[which(results %in% meta.double.marker.2)]) 
          meta.ids <- metas[double.indices] #Collect metas with the same results
          
          meta.ids.pooled <- union(meta.ids, meta.ids.2)
          meta.indices <- which(metas %in% meta.ids.pooled)
          results[meta.indices] <- meta.double.marker
          
        } else{
          
          meta.ids <- metas[double.indices]
          meta.indices <- which(metas %in% meta.ids)
          results[meta.indices] <- meta.double.marker
          
        }
      } else results[u] <- 0
      
      meta.double.marker <- meta.double.marker + 1
    }}
  return(results)
}

#Function picks the largest meta-analysis within a set of sensitivity analyses,
#and assigns it a "0" *to use with "data %>% mutate(.. = dupl.finder(..))":*
dupl.max.finder <- function(duplicate.index, study.number, metas){
  results <- rep(NA, length(duplicate.index))
  
  for(u in seq_along((duplicate.index))){
    
    duplicate.indices <- which(duplicate.index %in% duplicate.index[u])
    
    if(duplicate.index[u] != 0){
      
      meta.ids <- metas[duplicate.indices]
      
      max.meta.id <- meta.ids[which.max(study.number[duplicate.indices])]
      max.meta.indices <- which(metas %in% max.meta.id)
      if(length(unique(max.meta.id)) < 2){
        results[max.meta.indices] <- 0
      } else print("error")
      
    } else results[duplicate.indices] <- 0
    
  }
  
  results[is.na(results)] <- 1
  
  return(results)
}
@

\section{Analysis}

Data is subdivided into meta-analyses, and after all meta-analyses are excluded that are not suited for analysis, meta-analyses are done and saved.
"data.ext2" is the dataset processed with the previously introduced "pb.process3" function. Functions defined in the global environment are marked with
a "*USER.DEF*". They can be find in the next section.

<<eval = FALSE>>=
#Load data:
# rm(list = ls())
# PATH_HOME = path.expand("~") # user home
# PATH = file.path(PATH_HOME, 'Data/PubBias')
# PATH2 = file.path(PATH_HOME, 'PubBias')
# FILE = 'cochrane_2019-07-04.csv'
# PATH_DATA = file.path(PATH, 'data')
# PATH_CODE = file.path(PATH2, 'code')
# PATH_RESULTS = file.path(PATH2, 'results_new')
# PATH_FIGURES = file.path(PATH_RESULTS, 'figures')

source(file.path(PATH_CODE, 'PubBias_functions.R')) #Load user defined functions
load(file.path(PATH_DATA, "PubBias_2019-07-19.RData")) #Load data as contributed 
#by Simon Schwab.
# load(file.path(PATH_RESULTS, "data_used_for_analysis.RData")) 
data.ext2 <- pb.process3(data) #*USER.DEF*


#--------------------------------------------------------------------------------------------------------------------#
# PRE-ANALYSIS PART - EXCLUDE UNSUITABLE META-ANALYSES:
#--------------------------------------------------------------------------------------------------------------------#

#To skip pre-analysis:
# load(file.path(PATH_RESULTS, "meta_id_vector.RData"))
#--------------------------------------------------------------------------------------------------------------------#

# # ---------- Uncomment to run pre-analysis --------------
# # Get exclusion critetia (I-squared, n. sig. findings, s.e. ratio, dupl.index):
meta.info.bin <- data.ext2 %>% filter(outcome.flag == "DICH") %>%
  group_by(meta.id) %>%
  mutate(n.pre = n()) %>% filter(n.pre >= 10) %>%
  filter(!all(events1 == 0) & !all(events2 == 0)) %>% #No events
  mutate(se.lrr = sqrt(var.lrr)) %>%
  summarize(dupl.remove = unique(dupl.remove),
            id = unique(id),
            outcome.desired = unique(outcome.desired),
            n.sig.single = sum(sig.single, na.rm = T),
            se.min = min(se.lrr, na.rm = T),
            se.max = max(se.lrr, na.rm = T))

meta.info.cont <- data.ext2 %>% filter(outcome.flag == "CONT") %>%
  group_by(meta.id) %>%
  mutate(n.pre = n()) %>% filter(n.pre >= 10) %>%
  filter(!all(mean1 == 0) & !all(mean2 == 0)) %>% #No means
  filter(!all(sd1 == 0) | !all(sd2 == 0)) %>% #No sd's
  summarize(dupl.remove = unique(dupl.remove),
            id = unique(id),
            outcome.desired = unique(outcome.desired),
            n.sig.single = sum(sig.single, na.rm = T),
            se.min = min(se, na.rm = T),
            se.max = max(se, na.rm = T))

meta.info.iv <- data.ext2 %>%
  group_by(meta.id) %>%
  mutate(n.pre = n()) %>% filter(n.pre >= 10) %>%
  filter(outcome.flag == "IV") %>%
  filter(outcome.measure.merged == "Rate Ratio" | 
           outcome.measure.merged == "SMD" |
           outcome.measure.merged == "MD" | 
           outcome.measure.merged == "Hazard Ratio" |
           outcome.measure.merged == "OR" | 
           outcome.measure.merged == "RR") %>% #Remove outcomes w. unclear def.
  summarize(dupl.remove = unique(dupl.remove),
            id = unique(id),
            outcome.desired = unique(outcome.desired),
            n.sig.single = sum(sig.single, na.rm = T),
            se.min = min(se, na.rm = T),
            se.max = max(se, na.rm = T))

meta.info.pre <- rbind(meta.info.bin, meta.info.cont, meta.info.iv) 
#To save to control how many are excluded

meta.info.pre <- meta.info.pre %>%
  filter(id %in% data.review$id[which(data.review$withdrawn == FALSE)]) 
#No withdrawn meta-analyses


meta.info <- meta.info.pre %>% 
  filter(n.sig.single > 0) %>% #At least one significant result
  filter((se.max^2)/(se.min^2) > 4) %>% #variance ratio > 4
  filter(dupl.remove == 0) %>% #no duplicates
  filter(outcome.desired == "efficacy") #Only efficacy outcomes
#--------------------------------------------------------------------------------------------------------------------#

#Meta-analysis to get I2 (random effects meta-analysis):
meta.id.vector.org.ranef <- meta.info$meta.id #Do meta-analysis for each of those

meta.org.ranef.list <- list()
counter <- 0
for(u in meta.id.vector.org.ranef){
  counter <- counter + 1
  temp <- data.ext2 %>% filter(meta.id == u)
  print(c(u, counter))
  meta.org.ranef.list[[counter]] <- meta.fct.ranef.mom(temp)
}

exclusion.estimates <- cbind(
  meta.id = meta.id.vector.org.ranef,
  n = unlist(lapply(meta.org.ranef.list, 
                    FUN = function(meta.analysis){meta.analysis$k})),
  Q = unlist(lapply(meta.org.ranef.list, 
                    FUN = function(meta.analysis){meta.analysis$QE})))


meta.info.pre2 <- merge(meta.info, exclusion.estimates, by = "meta.id")
meta.info.I2 <- meta.info.pre2 %>% 
  rowwise() %>% mutate(I2  = max(0, (Q - n + 1)/Q)) #calculate I2
meta.info <- meta.info.I2 %>% filter(n > 9) %>% 
  filter(I2 < 0.5) #exclude I2 >= 0.5
meta.id.vector <- meta.info$meta.id #Vector of meta-ids that match the criteria.

save(meta.id.vector, file =  file.path(PATH_RESULTS, "meta_id_vector.RData"))
save(meta.info.I2, file =  file.path(PATH_RESULTS, "meta_id_I2.RData"))
#--------------------------------------------------------------------------------------------------------------------#

#Get more extensive information from the original dataset about the meta-analyses:
meta.info.extended <- data.ext2 %>% 
  filter(meta.id %in% meta.id.vector) %>% 
  group_by(meta.id) %>%
  summarize(id = unique(id),
            outcome.flag = unique(outcome.flag),
            comparison.nr = unique(comparison.nr),
            comparison.name = unique(comparison.name),
            outcome.name = unique(outcome.name),
            outcome.nr = unique(outcome.nr),
            subgroup.name = unique(subgroup.name),
            subgroup.nr = unique(subgroup.nr),
            outcome.measure.merged = unique(outcome.measure.merged),
            outcome.measure = unique(outcome.measure),
            outcome.desired = unique(outcome.desired),
            mean.samplesize = mean(total1 + total2, na.rm = T),
            total.samplesize = sum(total1 + total2),
            var.samplesize = var(total1 + total2, na.rm = T),
            min.samplesize = min(min(total1, na.rm = T), min(total2, na.rm = T)),
            total.events = sum(events1 + events2),
            mean.events = mean(events1 + events2),
            mean.publication.year = mean(study.year, na.rm = TRUE),
            first.publication.year = min(study.year, na.rm = T),
            #*USER.DEF* function to detect the expected side of bias
            side = bias.side.fct2(outcome = outcome.flag, outcome.measure.merged, 
                                  lrr = lrr, var.lrr = var.lrr, smd = cohensd, 
                                  var.smd = var.cohensd, effect = effect, se = se), 

            n.sig.single = sum(sig.single, na.rm = T),
            NA.sig.single = sum(is.na(sig.single)),
            se.min = min(se, na.rm = T),
            se.max = max(se, na.rm = T))

######################################################################################
######################################################################################
######################################################################################
# ANALYSIS PART: META-ANALYSES, TESTS AND ADJUSTMENTS: ###############################
######################################################################################
######################################################################################
######################################################################################

#Do all analyses with Fixed effects meta-analysis method and paule mandel tau^2 
#estimator
settings.meta(method.tau = "PM", method = "Inverse") 

#Load previously constructed lists (to skip analysis):
# load(file.path(PATH_RESULTS, "meta_complete_list_bin.RData"))
# load(file.path(PATH_RESULTS, "meta_complete_list_cont.RData"))
# load(file.path(PATH_RESULTS, "meta_complete_list_iv.RData"))
# load(file.path(PATH_RESULTS, "meta_complete_list_zscore.RData"))
# load(file.path(PATH_RESULTS, "meta_complete_list_cohensd.RData"))



#--------------------------------------------------------------------------------------------------------------------#
# BINARY DATA META-ANALYSES: ----------------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------#

# # -------- Uncomment to run analysis ----------
meta.id.vector.bin <- 
  meta.info.extended$meta.id[which(meta.info.extended$outcome.flag == "DICH")]
meta.analyses <- list()
meta.analyses.asd <- list()
meta.analyses.reg <- list()
meta.analyses.copas <- list()
meta.tests.harbord <- list()
meta.tests.peter <- list()
meta.tests.rucker.mm <- list()
meta.tests.rucker.linreg <- list()
meta.tests.schwarzer <- list()
meta.tests.excess <- list()
counter <- 0
for(u in meta.id.vector.bin){
	counter <- counter + 1
	print(c(u, counter))
	meta.analyses[[counter]] <- 
	  metabin(event.e = events1c, n.e = total1, event.c = events2c, n.c = total2,
	          studlab = study.name, sm = "RR",
	          method = "Inverse", data = data.ext2[data.ext2$meta.id == u,])
	
	#Arcsine transformed proportions to use in combination with Rücker's test:
	meta.analyses.asd[[counter]] <- 
	  metabin(event.e = events1c, n.e = total1, event.c = events2c, n.c = total2,
	          studlab = study.name, sm = "ASD", 
	          method = "Inverse", data = data.ext2[data.ext2$meta.id == u,])
  
	#Adjustment for publication bias
	meta.analyses.reg[[counter]] <- limitmeta(meta.analyses[[counter]])
	meta.analyses.copas[[counter]] <- auto.copas(meta.analyses[[counter]], 
	                         sig.level = 0.1) #*USER.DEF* Copas selection model.

	#Publication bias tests.
	meta.tests.excess[[counter]] <- tes.fct2(data = data.ext2[data.ext2$meta.id == u,])
	meta.tests.harbord[[counter]] <- 
	  metabias(meta.analyses[[counter]], method.bias = "score", k.min = 2)
	meta.tests.peter[[counter]] <- 
	  metabias(meta.analyses[[counter]], method.bias = "peters", k.min = 2)
	meta.tests.schwarzer[[counter]] <- 
	  metabias(meta.analyses[[counter]], method.bias = "count", k.min = 2)
	meta.tests.rucker.mm[[counter]] <- 
	  metabias(meta.analyses.asd[[counter]], method.bias = "mm", k.min = 2)
	meta.tests.rucker.linreg[[counter]] <- 
	  metabias(meta.analyses.asd[[counter]], method.bias = "linreg", k.min = 2)
}


# counter.unknown.bin.copas.error <- 0
# for(u in meta.id.vector.bin){
# 	if(length(meta.analyses.copas[[counter]]) < 3){
# 		meta.analyses.copas[[counter]] <- c(NA, NA, NA)
# 		counter.unknown.bin.copas.error <- counter.unknown.bin.copas.error + 1
# 	}
# }
# print(c("unknown.bin.copas.errors = ", counter.unknown.bin.copas.error))
#
# bin.meta.list <- list(data.ext2, meta.id.vector.bin, meta.analyses,
# 											meta.analyses.asd,
# 											meta.analyses.reg,
# 											meta.analyses.copas,
# 											meta.tests.excess,
# 											meta.tests.harbord,
# 											meta.tests.peter,
# 											meta.tests.rucker.mm,
# 											meta.tests.schwarzer,
# 											meta.tests.excess,
# 											meta.tests.rucker.linreg)
# save(bin.meta.list, file =  file.path(PATH_RESULTS, "meta_complete_list_bin.RData"))
# #--------------------------------------------------------------------------------------------------------------------#
# 
# #Load analysis data:
# meta.id.vector.bin <- bin.meta.list[[2]]
# meta.analyses <- bin.meta.list[[3]]
# meta.analyses.reg <- bin.meta.list[[5]]
# meta.analyses.copas <- bin.meta.list[[6]]
# meta.analyses.trimfill <- bin.meta.list[[7]]
# meta.tests.harbord <- bin.meta.list[[8]]
# meta.tests.peter <- bin.meta.list[[9]]
# meta.tests.rucker.mm <- bin.meta.list[[10]]
# meta.tests.schwarzer <- bin.meta.list[[11]]
# meta.tests.excess <- bin.meta.list[[12]]
# meta.tests.rucker.linreg <- bin.meta.list[[13]]


#Extract from lists:
bin.results <- data.frame(
  meta.id = meta.id.vector.bin,
  meta.es.measure = rep(times = length(meta.id.vector.bin), "log risk ratio"),
  
  n.sig.single2 = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){length(which(meta.analysis$pval < 0.05))})),
  
  #Meta-analysis:
  est.fixef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$TE.fixed})),
  est.ranef = unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$TE.random})),
  zval.fixef = unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$zval.fixed})),
  zval.ranef = unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$zval.random})),
  
  pval.fixef = unlist(lapply(meta.analyses, 
                   FUN = function(meta.analysis){meta.analysis$pval.fixed})),
  pval.ranef = unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$pval.random})),
  
  se.est.fixef =  unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$seTE.fixed})),
  se.est.ranef =  unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$seTE.random})),
  
  Q = unlist(lapply(meta.analyses, FUN = function(meta.analysis){meta.analysis$Q})),
  pval.Q = unlist(lapply(meta.analyses, 
                         FUN = function(meta.analysis){meta.analysis$pval.Q})),
  #I2 = unlist(lapply(meta.analyses, FUN = function(meta.analysis){meta.analysis$I2.w})),
  tau = unlist(lapply(meta.analyses, 
                      FUN = function(meta.analysis){meta.analysis$tau})),
  #se.tau = unlist(lapply(meta.analyses, FUN = function(meta.analysis){meta.analysis$se.tau})),
  sparse = unlist(lapply(meta.analyses, 
                         FUN = function(meta.analysis){meta.analysis$sparse})),
  k = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$k})),
  
  #Adjustment:
  method.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$method.adjust})),
  est.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$TE.adjust})),
  se.est.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$seTE.adjust})),
  zval.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$zval.adjust})),
  pval.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  alpha.r = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  beta.r = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  Q.small = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$Q.small})),
  Q.resid = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$Q.resid})),
  G.squared = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$G.squared})),
  
  est.copas = unlist(lapply(meta.analyses.copas, 
                  FUN = function(meta.adjust){meta.adjust[1]})),
  se.est.copas = unlist(lapply(meta.analyses.copas, 
                  FUN = function(meta.adjust){meta.adjust[2]})),
  missing.copas = unlist(lapply(meta.analyses.copas, 
                  FUN = function(meta.adjust){meta.adjust[3]})),
  
  #Tests;
  pval.d.tes.org = unlist(lapply(meta.tests.excess, 
                                 FUN = function(object){object[3]})),
  pval.d.tes = unlist(lapply(meta.tests.excess, 
                             FUN = function(object){object[4]})),
  stat.d.tes = unlist(lapply(meta.tests.excess, 
                             FUN = function(object){object[2]})),
  excess.d = unlist(lapply(meta.tests.excess, 
                           FUN = function(object){object[5]})) - 
    unlist(lapply(meta.tests.excess, 
                  FUN = function(object){object[6]})),
  pval.harbord = unlist(lapply(meta.tests.harbord, 
                               FUN = function(meta.test){meta.test$p.value})),
  stat.harbord = unlist(lapply(meta.tests.harbord, 
                               FUN = function(meta.test){meta.test$statistic})),
  pval.peter = unlist(lapply(meta.tests.peter, 
                             FUN = function(meta.test){meta.test$p.value})),
  stat.peter = unlist(lapply(meta.tests.peter, 
                             FUN = function(meta.test){meta.test$statistic})),
  pval.rucker = unlist(lapply(meta.tests.rucker.mm, 
                              FUN = function(meta.test){meta.test$p.value})),
  stat.rucker = unlist(lapply(meta.tests.rucker.mm, 
                              FUN = function(meta.test){meta.test$statistic})),
  pval.rucker.linreg = unlist(lapply(meta.tests.rucker.linreg, 
                              FUN = function(meta.test){meta.test$p.value})),
  stat.rucker.linreg = unlist(lapply(meta.tests.rucker.linreg, 
                              FUN = function(meta.test){meta.test$statistic})),
  pval.schwarzer = unlist(lapply(meta.tests.schwarzer, 
                              FUN = function(meta.test){meta.test$p.value})),
  stat.schwarzer = unlist(lapply(meta.tests.schwarzer, 
                              FUN = function(meta.test){meta.test$statistic}))
)



#--------------------------------------------------------------------------------------------------------------------#
# CONTINUOUS DATA META-ANALYSES: ------------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------#


# # -------- Uncomment to run analysis ----------
meta.id.vector.cont <- 
  meta.info.extended$meta.id[which(meta.info.extended$outcome.flag == "CONT")]
meta.analyses <- list()
meta.analyses.reg <- list()
meta.analyses.copas <- list()
meta.analyses.trimfill <- list()
meta.tests.excess <- list()
meta.tests.linreg <- list()
meta.tests.begg <- list()
meta.tests.mm <- list()
counter <- 0
for(u in meta.id.vector.cont){
	counter <- counter + 1
	print(c(u, counter))
	outcome.measure.merged <- 
	  as.character(unique(data.ext2[data.ext2$meta.id == u,
	                 "outcome.measure.merged"])$outcome.measure.merged)
	meta.analyses[[counter]] <- 
	  metacont(n.e = total1, mean.e = mean1, sd.e = sd1, n.c = total2,
						mean.c = mean2, sd.c = sd2, sm = outcome.measure.merged, 
						studlab = study.name, data = data.ext2[data.ext2$meta.id == u,])
	meta.analyses.reg[[counter]] <- limitmeta(meta.analyses[[counter]])
	meta.analyses.trimfill[[counter]] <- trimfill(meta.analyses[[counter]])
	meta.analyses.copas[[counter]] <- auto.copas(meta.analyses[[counter]], 
	                                             sig.level = 0.1)

	meta.tests.excess[[counter]] <- 
	  tes.fct2(data = data.ext2[data.ext2$meta.id == u,])
	meta.tests.linreg[[counter]] <- metabias(meta.analyses[[counter]], 
	                                         method.bias = "linreg", k.min = 2)
	meta.tests.begg[[counter]] <- metabias(meta.analyses[[counter]], 
	                                       method.bias = "rank", k.min = 2)
	meta.tests.mm[[counter]] <- metabias(meta.analyses[[counter]], 
	                                     method.bias = "mm", k.min = 2)
# }
# cont.meta.list <- list(data.ext2, meta.id.vector.cont, meta.analyses,
# 											 meta.analyses.reg,
# 											 meta.analyses.copas,
# 											 meta.analyses.trimfill,
# 											 meta.tests.linreg,
# 											 meta.tests.begg,
# 											 meta.tests.mm,
# 											 meta.tests.excess)
# save(cont.meta.list, file =  file.path(PATH_RESULTS, "meta_complete_list_cont.RData"))
#--------------------------------------------------------------------------------------------------------------------#

#Load analysis data:
# meta.id.vector.cont <- cont.meta.list[[2]]
# meta.analyses <- cont.meta.list[[3]]
# meta.analyses.reg <- cont.meta.list[[4]]
# meta.analyses.copas <- cont.meta.list[[5]]
# meta.analyses.trimfill <- cont.meta.list[[6]]
# meta.tests.linreg <- cont.meta.list[[7]]
# meta.tests.begg <- cont.meta.list[[8]]
# meta.tests.mm <- cont.meta.list[[9]]
# meta.tests.excess <- cont.meta.list[[10]]

#Extract from lists:
cont.results <- data.frame(
  meta.id = meta.id.vector.cont,
  meta.es.measure = rep("std. mean difference", times = length(meta.id.vector.cont)),
  
  n.sig.single2 = unlist(lapply(meta.analyses, FUN = function(meta.analysis){length(which(meta.analysis$pval < 0.05))})),
  
  #Meta-Analysis
  est.fixef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$TE.fixed})),
  est.ranef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$TE.random})),
  
  zval.fixef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$zval.fixed})),
  zval.ranef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$zval.random})),
  
  pval.fixef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$pval.fixed})),
  pval.ranef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$pval.random})),
  
  se.est.fixef =  unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$seTE.fixed})),
  se.est.ranef =  unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$seTE.random})),
  
  Q = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$Q})),
  pval.Q = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$pval.Q})),
  tau = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$tau})),
  k = unlist(lapply(meta.analyses, FUN = function(meta.analysis){meta.analysis$k})),
  
  #Adjustment:
  method.reg = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$method.adjust})),
  est.reg = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$TE.adjust})),
  se.est.reg = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$seTE.adjust})),
  zval.reg = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$zval.adjust})),
  pval.reg = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  alpha.r = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  beta.r = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  Q.small = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$Q.small})),
  Q.resid = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$Q.resid})),
  G.squared = unlist(lapply(meta.analyses.reg, 
                      FUN = function(meta.adjust){meta.adjust$G.squared})),
  
  est.copas = unlist(lapply(meta.analyses.copas, 
                      FUN = function(meta.adjust){meta.adjust[1]})),
  se.est.copas = unlist(lapply(meta.analyses.copas, 
                      FUN = function(meta.adjust){meta.adjust[2]})),
  missing.copas = unlist(lapply(meta.analyses.copas, 
                      FUN = function(meta.adjust){meta.adjust[3]})),
  
  #Tests:
  pval.d.tes.org = unlist(lapply(meta.tests.excess, 
                              FUN = function(object){object[3]})),
  pval.d.tes = unlist(lapply(meta.tests.excess, 
                              FUN = function(object){object[4]})),
  stat.d.tes = unlist(lapply(meta.tests.excess, 
                              FUN = function(object){object[2]})),
  excess.d = unlist(lapply(meta.tests.excess, 
                              FUN = function(object){object[5]})) - 
    unlist(lapply(meta.tests.excess, 
                              FUN = function(object){object[6]})),
  pval.egger = unlist(lapply(meta.tests.linreg, 
                             FUN = function(meta.test){meta.test$p.value})),
  stat.egger = unlist(lapply(meta.tests.linreg, 
                             FUN = function(meta.test){meta.test$statistic})),
  pval.begg = unlist(lapply(meta.tests.begg, 
                            FUN = function(meta.test){meta.test$p.value})),
  stat.begg = unlist(lapply(meta.tests.begg, 
                            FUN = function(meta.test){meta.test$statistic})),
  pval.thompson = unlist(lapply(meta.tests.mm, 
                            FUN = function(meta.test){meta.test$p.value})),
  stat.thompson = unlist(lapply(meta.tests.mm, 
                            FUN = function(meta.test){meta.test$statistic}))
)

#--------------------------------------------------------------------------------------------------------------------#
# IV OUTCOME META-ANALYSIS: -----------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------#


# # -------- Uncomment to run analysis ----------
meta.id.vector.iv <- 
  meta.info.extended$meta.id[which(meta.info.extended$outcome.flag == "IV")]
meta.analyses <- list()
meta.analyses.reg <- list()
meta.analyses.copas <- list()
meta.analyses.trimfill <- list()
meta.tests.linreg <- list()
meta.tests.begg <- list()
meta.tests.mm <- list()
meta.tests.excess <- list()
counter <- 0
for(u in meta.id.vector.iv){
	counter <- counter + 1
	meta.analyses[[counter]] <- metagen.iv(data = data.ext2[data.ext2$meta.id == u,])
	print(c(u, counter))
	
	meta.analyses.reg[[counter]] <- limitmeta(meta.analyses[[counter]])
	meta.analyses.trimfill[[counter]] <- trimfill(meta.analyses[[counter]])
	meta.analyses.copas[[counter]] <- auto.copas(meta.analyses[[counter]], 
	                                             sig.level = 0.1)

	meta.tests.excess[[counter]] <- 
	  tes.fct2(data = data.ext2[data.ext2$meta.id == u,])
	meta.tests.linreg[[counter]] <- metabias(meta.analyses[[counter]], 
	                               method.bias = "linreg", k.min = 2)
	meta.tests.begg[[counter]] <- metabias(meta.analyses[[counter]], 
	                               method.bias = "rank", k.min = 2)
	meta.tests.mm[[counter]] <- metabias(meta.analyses[[counter]], 
	                               method.bias = "mm", k.min = 2)
}
# iv.meta.list <- list(data.ext2, meta.id.vector.iv, meta.analyses,
# 											 meta.analyses.reg,
# 											 meta.analyses.copas,
# 											 meta.analyses.trimfill,
# 											 meta.tests.linreg,
# 											 meta.tests.begg,
# 											 meta.tests.mm,
# 											 meta.tests.excess)
# save(iv.meta.list, file =  file.path(PATH_RESULTS, "meta_complete_list_iv.RData"))
# #--------------------------------------------------------------------------------------------------------------------#
# 
# #Load analysis data:
# meta.id.vector.iv <- iv.meta.list[[2]]
# meta.analyses <- iv.meta.list[[3]]
# meta.analyses.reg <- iv.meta.list[[4]]
# meta.analyses.copas <- iv.meta.list[[5]]
# meta.analyses.trimfill <- iv.meta.list[[6]]
# meta.tests.linreg <- iv.meta.list[[7]]
# meta.tests.begg <- iv.meta.list[[8]]
# meta.tests.mm <- iv.meta.list[[9]]
# meta.tests.excess <- iv.meta.list[[10]]

#Extract from lists:
iv.results <- data.frame(
  meta.id = meta.id.vector.iv,
  meta.es.measure = rep(times = length(meta.id.vector.iv), "unknown.effect(IV)"),
  
  n.sig.single2 = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){length(which(meta.analysis$pval < 0.05))})),
  #Meta-Analysis
  est.fixef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$TE.fixed})),
  est.ranef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$TE.random})),
  
  zval.fixef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$zval.fixed})),
  zval.ranef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$zval.random})),
  
  pval.fixef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$pval.fixed})),
  pval.ranef = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$pval.random})),
  
  se.est.fixef =  unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$seTE.fixed})),
  se.est.ranef =  unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$seTE.random})),
  
  Q = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$Q})),
  pval.Q = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$pval.Q})),
  tau = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$tau})),
  k = unlist(lapply(meta.analyses, 
    FUN = function(meta.analysis){meta.analysis$k})),
  
  #Adjustment:
  method.reg = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$method.adjust})),
  est.reg = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$TE.adjust})),
  se.est.reg = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$seTE.adjust})),
  zval.reg = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$zval.adjust})),
  pval.reg = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  alpha.r = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  beta.r = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$pval.adjust})),
  Q.small = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$Q.small})),
  Q.resid = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$Q.resid})),
  G.squared = unlist(lapply(meta.analyses.reg, 
    FUN = function(meta.adjust){meta.adjust$G.squared})),
  
  est.copas = unlist(lapply(meta.analyses.copas, 
                           FUN = function(meta.adjust){meta.adjust[1]})),
  se.est.copas = unlist(lapply(meta.analyses.copas, 
                           FUN = function(meta.adjust){meta.adjust[2]})),
  missing.copas = unlist(lapply(meta.analyses.copas, 
                           FUN = function(meta.adjust){meta.adjust[3]})),
  
  #Tests:
  pval.d.tes.org = unlist(lapply(meta.tests.excess, 
                             FUN = function(object){object[3]})),
  pval.d.tes = unlist(lapply(meta.tests.excess, 
                             FUN = function(object){object[4]})),
  stat.d.tes = unlist(lapply(meta.tests.excess, 
                             FUN = function(object){object[2]})),
  excess.d = unlist(lapply(meta.tests.excess, 
                             FUN = function(object){object[5]})) - 
    unlist(lapply(meta.tests.excess, 
                  FUN = function(object){object[6]})),
  pval.egger = unlist(lapply(meta.tests.linreg, 
                             FUN = function(meta.test){meta.test$p.value})),
  stat.egger = unlist(lapply(meta.tests.linreg, 
                             FUN = function(meta.test){meta.test$statistic})),
  pval.begg = unlist(lapply(meta.tests.begg, 
                             FUN = function(meta.test){meta.test$p.value})),
  stat.begg = unlist(lapply(meta.tests.begg, 
                             FUN = function(meta.test){meta.test$statistic})),
  pval.thompson = unlist(lapply(meta.tests.mm, 
                             FUN = function(meta.test){meta.test$p.value})),
  stat.thompson = unlist(lapply(meta.tests.mm, 
                             FUN = function(meta.test){meta.test$statistic}))
)


#--------------------------------------------------------------------------------------------------------------------#
# Z-SCORE BASED META-ANALYSES: --------------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------#

# # -------- Uncomment to run analysis ----------
meta.id.vector.noiv <- 
  meta.info.extended$meta.id[-which(meta.info.extended$outcome.flag == "IV")]
meta.id.vector.smd <- 
  meta.info.extended$meta.id[which(meta.info.extended$outcome.measure.merged == "SMD")]
meta.id.vector.z <- union(meta.id.vector.smd, meta.id.vector.noiv)
meta.id.vector.z.c <- meta.id.vector.z[-c(which(meta.id.vector.z == 104613),
                                          which(meta.id.vector.z == 104616),
                                          which(meta.id.vector.z == 153452),
                                          which(meta.id.vector.z == 163246),
                      which(meta.id.vector.z == 182958))] #Have zero total1..
tmp.z <- data.ext2 %>% group_by(meta.id) %>% mutate(n = n()) %>% filter(n > 9) %>%
  filter(total1 + total2 > 3) %>% filter(total1 != 0 & total2 != 0)
meta.analyses <- list()
meta.analyses.reg <- list()
meta.analyses.copas <- list()
counter <- 0
for(u in meta.id.vector.z.c){
	counter <- counter + 1
	print(c(u,counter))
	meta.analyses[[counter]] <- metacor(cor = z, n = total1 + total2, 
	                   studlab = study.name, tmp.z[tmp.z$meta.id == u,])
	meta.analyses.reg[[counter]] <- limitmeta(meta.analyses[[counter]])
	meta.analyses.copas[[counter]] <- auto.copas(meta.analyses[[counter]], 
	                                             sig.level = 0.1)
}
# zscore.meta.list <- list(tmp.z, meta.id.vector.z.c, meta.analyses, 
#meta.analyses.reg, meta.analyses.copas)
# save(zscore.meta.list, file =  file.path(PATH_RESULTS, 
#"meta_complete_list_zscore.RData"))
#--------------------------------------------------------------------------------------------------------------------#

#Load analysis data:
meta.id.vector.z.c <- zscore.meta.list[[2]]
meta.analyses <- zscore.meta.list[[3]]
meta.analyses.reg <- zscore.meta.list[[4]]
meta.analyses.copas <- zscore.meta.list[[5]]

#List extraction:
zscore.meta.analysis.estimates <- cbind(
  meta.id = meta.id.vector.z.c,
  est.z.fixef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$TE.fixed})),
  est.z.ranef = unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$TE.random})),
  se.est.z.fixef =  unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$seTE.fixed})),
  se.est.z.ranef =  unlist(lapply(meta.analyses, 
                    FUN = function(meta.analysis){meta.analysis$seTE.random})),
  
  est.z.reg = unlist(lapply(meta.analyses.reg, 
                    FUN = function(meta.adjust){meta.adjust$TE.adjust})),
  se.est.z.reg = unlist(lapply(meta.analyses.reg, 
                    FUN = function(meta.adjust){meta.adjust$seTE.adjust})),
  
  est.z.copas = unlist(lapply(meta.analyses.copas, 
                    FUN = function(meta.adjust){meta.adjust[1]})),
  se.est.z.copas = unlist(lapply(meta.analyses.copas, 
                    FUN = function(meta.adjust){meta.adjust[2]})))


#--------------------------------------------------------------------------------------------------------------------#
# HEDGES G BASED META-ANALYSES: -------------------------------------------------------------------------------------#
#--------------------------------------------------------------------------------------------------------------------#

# # -------- Uncomment to run analysis ----------
meta.id.vector.d <- meta.id.vector.z[-c(which(meta.id.vector.z == 25407))]
meta.analyses <- list()
meta.analyses.reg <- list()
meta.analyses.copas <- list()
counter <- 0
for(u in meta.id.vector.d){
  counter <- counter + 1
  print(c(u,counter))
  meta.analyses[[counter]] <- metagen.bincont2(data.ext2[data.ext2$meta.id == u,])
  meta.analyses.reg[[counter]] <- limitmeta(meta.analyses[[counter]])
  meta.analyses.copas[[counter]] <- auto.copas(meta.analyses[[counter]], 
                                               sig.level = 0.1)
}
# cohensd.meta.list <- list(data.ext2, meta.id.vector.d, meta.analyses, 
#meta.analyses.reg, meta.analyses.copas)
# save(cohensd.meta.list, file =  file.path(PATH_RESULTS, 
#"meta_complete_list_cohensd.RData"))
#--------------------------------------------------------------------------------------------------------------------#

#Load analysis data:
meta.id.vector.d <- cohensd.meta.list[[2]]
meta.analyses <- cohensd.meta.list[[3]]
meta.analyses.reg <- cohensd.meta.list[[4]]
meta.analyses.copas <- cohensd.meta.list[[5]]

#List extraction:
cohensd.meta.analysis.estimates <- cbind(
  meta.id = meta.id.vector.d,
  est.d.fixef = unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$TE.fixed})),
  est.d.ranef = unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$TE.random})),
  se.est.d.fixef =  unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$seTE.fixed})),
  se.est.d.ranef =  unlist(lapply(meta.analyses, 
                  FUN = function(meta.analysis){meta.analysis$seTE.random})),
  
  est.d.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$TE.adjust})),
  se.est.d.reg = unlist(lapply(meta.analyses.reg, 
                  FUN = function(meta.adjust){meta.adjust$seTE.adjust})),
  
  est.d.copas = unlist(lapply(meta.analyses.copas, 
                  FUN = function(meta.adjust){meta.adjust[1]})),
  se.est.d.copas = unlist(lapply(meta.analyses.copas, 
                  FUN = function(meta.adjust){meta.adjust[2]})))


#--------------------------------------------------------------------------------------------------------------------#
# BUILD FINAL DATASET OF RESULTS
#--------------------------------------------------------------------------------------------------------------------#

meta.tp5 <- bind_rows(bin.results, cont.results, iv.results)
meta.tp1 <- merge(meta.info.extended, meta.tp5, 
                  by = c("meta.id")) #Temporary versions
meta.tp4 <- merge(by = "meta.id", x = meta.tp1, 
                  y = zscore.meta.analysis.estimates, all.x = T)
meta.f <- merge(by = "meta.id", x = meta.tp4, 
                y = cohensd.meta.analysis.estimates, all.x = T)

#--------------------------------------------------------------------------------------------------------------------#
# ROUND-UP: DETECT AND REPLACE MISSING VALUES
#--------------------------------------------------------------------------------------------------------------------#

#se.est.copas.na = 1 -> is missing
meta.f$se.est.copas.na <- ifelse(is.na(meta.f$se.est.copas), 1, 0) 
meta.f$se.est.z.copas.na <- ifelse(is.na(meta.f$se.est.z.copas), 1, 0)
meta.f$se.est.d.copas.na <- ifelse(is.na(meta.f$se.est.d.copas), 1, 0)

meta.f$se.est.reg.na <- ifelse(is.na(meta.f$se.est.reg), 1, 0)
meta.f$se.est.z.reg.na <- ifelse(is.na(meta.f$se.est.z.reg), 1, 0)
meta.f$se.est.d.reg.na <- ifelse(is.na(meta.f$se.est.d.reg), 1, 0)

meta.f$est.copas.na <- ifelse(is.na(meta.f$est.copas), 1, 0)
meta.f$est.z.copas.na <- ifelse(is.na(meta.f$est.z.copas), 1, 0)
meta.f$est.d.copas.na <- ifelse(is.na(meta.f$est.d.copas), 1, 0)

meta.f$est.reg.na <- ifelse(is.na(meta.f$est.reg), 1, 0)
meta.f$est.z.reg.na <- ifelse(is.na(meta.f$est.z.reg), 1, 0)
meta.f$est.d.reg.na <- ifelse(is.na(meta.f$est.d.reg), 1, 0)
#--------------------------------------------------------------------------------------------------------------------#

#Inpute random effect estimate for missing copas:
copas.names <- c("est.copas", "se.est.copas", "est.z.copas", "se.est.z.copas", 
                 "est.d.copas", "se.est.d.copas")
ranef.names <- c("est.ranef", "se.est.ranef", "est.z.ranef", "se.est.z.ranef", 
                 "est.d.ranef", "se.est.d.ranef")
missing.names <- paste(copas.names, ".missing", sep = "")
missing <- c()

for(u in 1:length(copas.names)){
  missing.count <- 0
  for(k in 1:dim(meta.f)[1]){
    if(is.na(meta.f[k, copas.names[u]])){
      missing.count <- missing.count + 1
      meta.f[k, copas.names[u]] <- meta.f[k, ranef.names[u]]
    }
  }
  missing[u] <- missing.count
  meta.f[, missing.names[u]] <- missing.count
}
#--------------------------------------------------------------------------------------------------------------------#

#Some useful variables:
meta.f <- meta.f %>% rowwise() %>% 
  mutate(pval1.egger = onesided.p(stat = stat.egger, side = side, n = k, 
                                  test.type = "reg"),
         pval1.thompson = onesided.p(stat = stat.thompson, side = side, n = k, 
                                     test.type = "reg"),
         pval1.begg = onesided.p(stat = stat.begg, side = side, n = k, 
                                 test.type = "rank"),
         
         pval1.harbord = onesided.p(stat = stat.harbord, side = side, n = k, 
                                    test.type = "reg"),
         pval1.rucker = onesided.p(stat = stat.rucker, side = side, n = k, 
                                   test.type = "reg"),
         pval1.rucker.linreg = onesided.p(stat = stat.rucker.linreg, side = side, n = k, 
                                          test.type = "reg"),
         pval1.peter = onesided.p(stat = stat.peter, side = side, n = k, 
                                  test.type = "reg"),
         pval1.schwarzer = onesided.p(stat = stat.schwarzer, side = side, n = k, 
                                      test.type = "rank"),
         pval1.d.tes = pval.d.tes)

#Summarise different tests for binary and continuous variables to one:
meta.f <- meta.f %>% rowwise() %>% 
  mutate(I2  = max(0, (Q - k + 1)/Q),
         var.ratio = (se.max^2)/(se.min^2),
         pval.se = case_when(outcome.flag == "DICH" ~ pval1.rucker.linreg, 
                             TRUE ~ pval1.egger),
         pval.se.het = case_when(outcome.flag == "DICH" ~ pval1.rucker, 
                                 TRUE ~ pval1.thompson))
#significance of pb tests:
sig.level <- 0.1
meta.f <- meta.f %>% rowwise() %>% 
  mutate(egger.test = ifelse(pval1.egger < sig.level, 1, 0),
         thompson.test = ifelse(pval1.thompson < sig.level, 1, 0),
         begg.test = ifelse(pval1.begg < sig.level, 1, 0),
         
         tes.d.test = ifelse(pval1.d.tes < sig.level, 1, 0),
         
         schwarzer.test = ifelse(pval1.schwarzer < sig.level, 1, 0),
         rucker.test = ifelse(pval1.rucker < sig.level, 1, 0),
         rucker.test.linreg = ifelse(pval1.rucker.linreg < sig.level, 1, 0),
         harbord.test = ifelse(pval1.harbord < sig.level, 1, 0),
         peter.test = ifelse(pval1.peter < sig.level, 1, 0))

#calculate test statistics:
meta.f <- meta.f %>% mutate(
  z.fixef = (est.fixef/se.est.fixef)
  z.ranef = (est.ranef/se.est.ranef),
  z.reg =   (est.reg/se.est.reg),
  z.copas = ((est.copas)/se.est.copas))
#--------------------------------------------------------------------------------------------------------------------#

#Separate outcome.types:
meta.bin <- meta.f %>% filter(outcome.flag == "DICH")
meta.cont <- meta.f %>% filter(outcome.flag == "CONT")
meta.iv <- meta.f %>% filter(outcome.flag == "IV")
#--------------------------------------------------------------------------------------------------------------------#

#Save the result datasets:
save(meta.f, file =  file.path(PATH_RESULTS, "meta_analyses_summary_complete.RData"))
save(meta.bin, file =  file.path(PATH_RESULTS, "meta.bin.RData"))
save(meta.cont, file =  file.path(PATH_RESULTS, "meta.cont.RData"))
save(meta.iv, file =  file.path(PATH_RESULTS, "meta.iv.RData"))
save(meta.id.vector, file =  file.path(PATH_RESULTS, "meta_id_vector.RData"))
save(data.ext2, file =  file.path(PATH_RESULTS, "data_used_for_analysis.RData")) #Save data used for analysis




# x <- foreach(i = 1:length(meta.id.vector.bin)) %dopar% 
#   # u <- meta.id.vector.bin[i]
#   # counter <- counter + 1
#   metabin(event.e = events1c, n.e = total1, event.c = events2c, n.c = total2,
#           studlab = study.name, sm = "RR",
#           method = "Inverse", data = data.ext2[data.ext2$meta.id == meta.id.vector.bin[i],])
# 
# cl<-makeCluster(7)
# registerDoParallel(cl)
# 
# foreach(i = 1:length(meta.id.vector.bin)) %dopar%
#   sqrt(i)




########################################################################################################
########################################################################################################
########################################################################################################
########################################################################################################
########################################################################################################
########################################################################################################
########################################################################################################
########################################################################################################
@

