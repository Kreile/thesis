% LaTeX file for Chapter 01
<<'preamble01',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path='figure/ch01_fig', 
    self.contained=FALSE,
    cache=TRUE
)

@


\chapter{Introduction}

Studies get more attention and are more likely to be published, read and cited if they contain significant effects. Studies with no evidence for an effect are less likely to get published. This generates a bias called ``publication bias'', a distorted view of the evidence for an effect. Publication bias has been identified as one of the major concerns in irreproducible research \citep{Bishop.2019}. The issue has been discussed in clinical science by many researchers (\citealp{pb.clinicalscience1}, \citealp{Sterne}, \citealp{Dwan2013}). Consensus is that publication bias exists in clinical science. \\
In medical research, clinical trials study the efficacy of therapies and drugs. The gold standard in such intervention studies are randomized controlled trials (RCTs). Results from RCTs influence the treatment of patients in daily clinical practice. The results from multiple intervention studies can be summarized in a meta-analysis to estimate an overall treatment effect (across all studies) \citep{Cochran}. However, publication bias can bias the overall effect estimates from meta-analyses and eventually lead to ineffective treatments that could lead to patient harm, distortion and financial expenses. \\
There is extensive literature on publication bias in meta-analyses, \eg (\citealp{pb.clinicalscience.2013}, %\citealp{Hopewell02},
\citealp{grey.literature.4}, \citealp{grey.literature.3}, \citealp{grey.literature.2}).
The authors agree on that the exclusion of unpublished results in meta-analyses can lead to overestimation of treatment effects (\eg \citealp{Egger}). Although there are policies that make it mandatory to make all study results publicly accessible \citep{fda}, it is not clear if the situation has improved yet. There are also notable efforts from both journals \citep{Abbasi.2004} and researchers (DORA: San Francisco declaration of research assessment).\\
There are multiple ways to assess the amount of publication bias. For instance, it is possible to follow studies and assess if they are getting published depending on their findings (\citealp{Dwan2013}, \citealp{publication.fate}, \citealp{Lee.2008}). One often finds that positive findings (\ie large effects) are reported and published more often (see also an example in the social sciences: \citet{social.sciences.publication.bias}). Another way is to compare results in study registries with results published in journals (\eg \citealp{pb.clinicalscience.2013}). Again one finds systematic differences between published and unpublished results. \\
A third way is to assess the so-called small study effect in a meta-analysis, that is, smaller studies sometimes showing different, often larger treatment effects than large ones. The rationale is that studies with larger standard errors have to have larger effects in order to be significant. The estimation of small study effects is an efficient way to investigate publication bias in a large number of meta-analyses. Although there are other reasons for small study effects as well, evidence for small study effects can oftentimes be interpreted as evidence for publication bias \citep{Egger}, as it is the most likely cause. \\
% 
% The underlying rationale is that journal editors are guided by two simple rules (\citealp{excess.significance}, \citealp{ioannidis.2019}): 
% \begin{itemize}
% \item Publish new and trend-setting positive findings that lead to many citations, increasing the journal impact factor (JIF). Statistical significance is oftentimes interpreted as confirmation for treatment efficacy.
% \item Publish large trials that are likely to set the standard for a given scientific question, again to increase the JIF.
% \end{itemize}
% 
% Publication bias thus leads to larger effects in studies with larger uncertainities, in order for them to be statistically significant. 
A funnel plot \citep{funnel.plot} allows visual inspection of small study effects by plotting the effects against their standard error. For illustration purposes, one meta-analysis with large funnel plot asymmetry and one with no asymmetry is shown in Figure \ref{small.study.effect.examples}. %\citep{pre.eclampsia}: 
The purpose of a funnel plot is to visualize if there are missing study results on one lower side of the funnel plot. By means of simple linear regression, one can investigate how much evidence there is for asymmetry. 

\begin{figure}
<<echo = FALSE, fig.height = 3, warning=FALSE>>=
PATH_HOME = path.expand("~") # user home
PATH = file.path(PATH_HOME, 'Data/PubBias')
PATH2 = file.path(PATH_HOME, 'PubBias')
FILE = 'cochrane_2019-07-04.csv'
PATH_DATA = file.path(PATH, 'data')
PATH_CODE = file.path(PATH2, 'code')
PATH_RESULTS = file.path(PATH2, 'results_new')
PATH_FIGURES = file.path(PATH_RESULTS, 'figures')
load(file.path(PATH_RESULTS, "data_used_for_analysis.RData"))
load(file.path(PATH_RESULTS, "meta_analyses_summary_complete.RData"))

source(file.path(PATH_CODE, 'PubBias_functions.R'))

ex.se <- meta.f$meta.id[which(meta.f$id == "CD003246" & meta.f$subgroup.nr == 0
                              & meta.f$outcome.nr == 3 & meta.f$comparison.nr == 9)]
ex.nose <- meta.f$meta.id[which(meta.f$id == "CD000213" & meta.f$subgroup.nr == 1
                              & meta.f$outcome.nr == 15 & meta.f$comparison.nr == 1)]
par(mfrow = c(1,2))
funnel(x = meta.id(ex.se), ylim = c(1.60, 0), comb.fixed = F, comb.random = F, pch = 20, las = 1)
funnel(x = meta.id(ex.nose), ylim = c(1.60, 0), comb.fixed = F, comb.random = F, ylab = NULL, pch = 20, las = 1)
@
\caption{Funnel plots of two meta-analyses: On the left, the improvement in depression syndromes after application of tricyclic antidepressants is compared to placebo. The meta-analysis on the right measures the occurrence of intracranial haemoerrhage by CT after application of any anti-thrombolytic agent. All studies are RCT's.}
\label{small.study.effect.examples}
\end{figure}


We see that while the studies in the meta-analysis on the right rather accumulate on the right side, they seem to be more evenly distributed in the right triangle. From this, we would ultimately conclude that some sort of bias or heterogeneity is distorting the estimate of the overall treatment effect.\\
The Cochrane Organisation has specialized on systematic reviews of healthcare interventions. Researchers that write a systematic review collect data across studies, review them and try to provide up-to-date information about specific treatment efficacy \citep{cochrane.handbook}. By systematic literature review, they try to circumvent the issue of publication bias.
Earlier research however suggests that the efforts are only partially successful, and that there still is publication bias within the reviews (\citealp{Egger}, \citealp{Ioannidis2007}, \citealp{kicinsky}, \citealp{vanAert.2019}). In these publications, Cochrane systematic reviews is analysed with methods to detect publication bias, for example small study effect tests or Bayesian hierarchical selection models \citep{kicinsky}. They all find moderate to large evidence for publication bias in the database.\\

\section{Aim of the Study}
None of the research so far has estimated the amount and impact of publication bias on meta-analytical findings thoroughly and with the most suitable methods. Also, the results are ironically often presented in the form of dichotomous hypothesis tests, a practice that is partly responsible for publication bias.\\
The aim of this thesis was to use prevailed methods to detect publication bias, and make use of the full amount of data that the Cochrane Organisation provides. The research questions are: Are effects in meta-analyses \textit{larger} if their standard errors are small, and are there \textit{more} significant effects than expected? How can this affect the combined treatment effects as commonly obtained by meta-analysis? To answer these questions, methods to detect and adjust for publication bias in meta-analysis are applied on the data.\\
At the end, we will not only give an estimate of publication bias in the Cochrane Library but also show to what extent treatment effects are overestimated. The analyses are exploratory, but may generate new hypotheses and stimulate future directions for confirmatory research.



