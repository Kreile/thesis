% LaTeX file for Chapter 02
<<'preamble04',include=FALSE>>=
library(knitr)
opts_chunk$set(
    fig.path='figure/ch04_fig', 
    self.contained=FALSE,
    cache=FALSE
) 
@

\chapter{Methods} \label{ch:methods}
\section{Introduction and Notation}
The interventions are restricted to comparisons of two treatment groups by some measure of melioration or worsening of health. The difference in this measure between the groups is referred to as the treatment effect. Where it is not particularly mentioned, the term treatment effect refers to any effect measure such as log risk ratio, log hazard ratio, log rate ratio, Cohen's $d$ or standardized mean difference, Fisher's z transformed score.\\
Let us consider a meta-analysis with $n$ study treatment effects ($n > 1$, but typically small). A study is indexed by $i$, and it's treatment effect by  $\theta_i$. The observed treatment effect is $\hat{\theta}_i$. The pooled treatment effect of a meta-analysis will be denoted as $\theta_M$, and consequently, the observed pooled treatment effect as $\hat{\theta}_M$. Furthermore, each treatment effect is typically measured with some standard error $\se_i$ and an estimate of $\se_i$ is denoted as $\hat{\se}_i$. The $\hat{}$ sign thus indicates if it is an estimate.\\
For continuous outcomes, let $m_t$ be the mean of the treatment group, $m_c$ the mean of the control group, and equivalently $\textrm{sd}_t$ and $\textrm{sd}_c$ the corresponding standard deviations. 
In the case of binary outcomes, let $e_t$ be the count of events in the treatment arm $e_c$ the events in the control group. $n_t$ and $n_c$ are the total number of participants in the groups ($c$ for control and $t$ for treatment).%The observed counts in a study $i$ are referred to as $e_{t,i}$ and analogously $e_{c,i}$.

\section{Effect Measures and $p$\hspace{0.4mm}-values}
\subsection{Continuous Outcomes}
For given $(m_t, m_c), (\textrm{sd}_t, \textrm{sd}_c)$ and $(n_t, n_c)$, one can compute mean difference as well as a standardized mean difference (here: Cohen's $d$) and a standard error thereof.
The mean difference $\theta$ and its standard error $\se$ can be obtained as

\begin{align}
\theta &= m_t - m_c & \se &= \sqrt{\textrm{sd}_t^2/n_t + \textrm{sd}_c^2/n_t}
\end{align}

Cohen's $d$ and its standard error $\se$ can similarly be obtained by

\begin{align}
\se &= \sqrt{\frac{(n_t - 1)\textrm{sd}_t^2 + (n_c - 1)\textrm{sd}_c^2}{n_t + n_c - 2}} & d &= \frac{m_t - m_c}{\se} \label{eq:hedges.g}
\end{align}

Both estimators take into account that the two groups might have unequal variances. \\ 
A $p$\hspace{0.4mm}-value to test the null hypothesis that the mean between group is equal is commonly obtained with the Students $t$ test. The $t$ statistic is obtained, using $\se$ and $d$ from \eqref{eq:hedges.g}, by

\begin{align}
t &= d/(\se\sqrt{(1/n_t)+(1/n_c)}) \nonumber
\end{align}
and the $p$\hspace{0.4mm}-value can be obtained with the cumulative Student's $t$-distribution $F$ with $n_t + n_c - 2$ degrees of freedom:

\begin{align}
p &= 2(1-F(\abs{t})) \nonumber
\end{align}

The t-test is known to be not very reliable if combined sample size is small ($n_t + n_c < 30$).

\subsection{Binary Outcomes}
Two commonly used effect measures for binary outcome data are risk ratios and odds ratios between treatment and control groups. 
The methods presented here can also be found, for example, in \cite[34]{Intro.meta}.
Let $\theta$ be the natural logarithm of the odds ratio. $\hat{\theta}$ and its variance $\hat{\se}^2$ can be obtained by computing

\begin{align}
\hat{\theta} &= \log(\frac{e_t\cdot(n_c - e_c)}{e_c\cdot(n_t - e_t)}) \nonumber \\
\hat{\se}^2 &= 1/e_t + 1/(n_t - e_t) + 1/e_c + 1/(n_c - e_c) \nonumber
\end{align}

Plugging in the observed counts will give the corresponding estimates. The logarithm of the risk ratio $\theta$ and its variance $\se^2$ is similarly defined as

\begin{align}
\hat{\theta} &= \log(\frac{e_t/n_t}{e_c/n_c}) \label{eq:risk.ratio} \\
\se^2&= 1/e_t - 1/n_t + 1/e_c - 1/e_t \label{eq:risk.ratio.variance}
\end{align}

Asuming binomial distribution of the events and using likelihood theory, one could show that the estimators are maximum likelihood estimators and that one can use the asymptotic normal distribution of the maximum likelihood estimator to calculate a $p$\hspace{0.4mm}-value, \eg \cite[98]{held2014}. The approximation is only good if there are enough events and sample size is large enough.\\
Thus, with $\Phi$ as the cumulative standard normal distribution, we get
\begin{align}
p &= 2\cdot(1-\Phi(|\hat{\theta}/\hat{\se}|), \nonumber
\end{align}
a $p$\hspace{0.4mm}-value for the corresponding estimate, which summarizes the evidence against $\hat{\theta}$ being zero (\ie the true risk/odds ratio being 1). \\
Odds ratios can be transformed to std. mean differences, which will be described in Section \ref{sec:transformation.effectsizes}.

\subsection{Time-to-Event Outcomes}
Usually, time-to-event data of two experimental groups can be compared by rate ratios. The normal approximations of the maximum likelihood estimators also works here when using the log rate ratio.
Time-to-event data with censoring has to be analyzed by special means. One frequently used method to take into account right-censoring is the Cox proportional hazards regression model \citep{Cox}. Because the method itself is not applied in this thesis, but only the resulting estimates of the parameters are used, the reader is referred to the extensive literature covering this topic (\eg \citet{Surv}). \\
The so-called hazard ratio estimated by Cox regression is the ratio of the instantaneous risk of experiencing the event between two groups. Because it is a maximum likelihood estimator, one can again use its Wald test statistic to test for equal hazards. Let $\hat{\theta}$ be an estimate of the log hazard ratio and $\hat{\se}$ an estimate of the standard error of it. As before
\begin{align}
p &= 2\cdot(1-\Phi(|\hat{\theta}/\hat{\se}(\hat{\theta})|) \nonumber
\end{align}
will give a $p$\hspace{0.4mm}-value for the evidence against the null hypothesis.



\section{Fixed and Random Effects Meta-Analysis} \label{sec:meta.analysis}
The fixed effects meta-analysis estimator of the pooled treatment effect is a mean of the single treatment effect estimators, weighted by their standard errors \citep{fixed.effects.rosenthal}. Let $w_i = 1/\se_i^2$ be the weights, and $\theta_M$ be the pooled estimator and $\se_M^2$ its variance. Then 

\begin{align}
\theta_M &= \frac{\sum_{i = 1}^n w_i \theta_i}{\sum_{i = 1}^n w_i} &
\se_M^2 &= \frac{1}{\sum_{i = 1}^n w_i} \label{eq:fixed.effects}
\end{align}

This estimator minimizes the variance between the effects. An estimate $\hat{\theta}_M$ can be obtained by plugging in the observed treatment effects and variances $\hat{\theta}_i$ and $\hat{\se}_i^2$. The underlying idea is that we assume $\theta_i \sim N(\theta_M, \se_i^2)$, $\theta_M$ being the true effect, all $\theta_i$ being distributed around an equal mean. \\
The random effects model \citep{whitehead} assumes instead that 
\begin{align}
\theta_i \sim N(\mu_i, \se_i^2) &&
\mu_i \sim N(\theta_M, \tau^2) \label{eq:random.effects} 
\end{align}

Marginally, we have $\theta_i$ being distributed around a common mean $\theta_M$ with additional variance $\tau^2$:

\begin{align}
\theta_i \given \mu_i \sim N(\theta_M, \se_i^2 + \tau^2) \nonumber %\label{eq:random.effects.marginal}
\end{align}

$\tau^2$ is often referred to as a population variance or between-study variance, whereas $\se_i^2$ can be interpreted as sampling error. The pooled treatment effect estimate $\theta_M$ of the random effects model and its variance is obtained by replacing the weights $w_i$ in equation \eqref{eq:fixed.effects} with $w_i = 1/(\se_i^2 + \tau^2)$.\\
The model is superior to the fixed effects model whenever the standard errors of the treatment effects alone are unlikely to fully account for the entire variability observed between studies. The method assigns larger weights to studies with larger standard errors.\\
The estimation of $\tau^2$ has been subject to some debate in the statistical literature. Oftentimes, the method of moment estimator of \citet{tau.estimator} is used. We use the measure of heterogeneity, $Q$, and divide by $C$ after having subtracted the degrees of freedom $n-1$:

\begin{align}
Q &= \sum_{i = 1}^n w_i(y_i - \theta_M)^2 & C &= \sum_{i = 1}^n w_i - \frac{\sum_{i = 1}^n w_i^2}{\sum_{i = 1}^n w_i} \label{eq:Q.heterogeneity} \\
\tau^2 &= \max\big(0, \frac{Q - (n-1)}{C}\big) \label{eq:Tau.definition}
\end{align}

The estimators have to be replaced by their estimates in order to get an estimate $\hat{\tau}^2$.\\
The Paule-Mandel estimator \citep{paulemandel} is considered to have better properties than the method of moments estimator (\eg \citet{tau.estimator.evaluation}). Since we defined $w_i = 1/(\se_i^2 + \tau^2)$, it also holds that

\begin{align}
w_i \textrm{Var}(\theta_i) &= 1 & \textrm{Var}(\sqrt{w_i}\theta_i) = 1 \nonumber
\end{align}

For any $w_i$, the variance can be estimated and equated to its expected value:

\begin{align}
\se^2(w_i\theta_i) &= \frac{\sum_{i = 1}^n w_i(\theta_i - \theta_M)^2}{n-1} & \frac{\sum_{i = 1}^n w_i(\theta_i - \theta_M)^2}{n-1} = 1 \label{eq:paulemandel}
\end{align}

After estimating $\theta_M$ with equation \eqref{eq:fixed.effects}, the only problem remaining is to estimate $\tau^2$. $\hat{\tau}^2$ can be obtained through an iterative process, using a newly defined function

\begin{align}
F(\tau^2) &= \sum_{i = 1}^n w_i(\theta_i - \theta_M)^2 - (n-1) \nonumber
\end{align}

In view of equation \eqref{eq:paulemandel}, $\tau^2$ must be such that $F(\tau^2) = 0$. Then, we start with a arbitrary $\tau^2$ and repeatedly add a term $\tau_0^2$ to update $\tau^2$ until $F(\tau^2 + \tau_0^2)$ is close to zero (using $\tau^2 + \tau_0^2$ for $\hat{w}_i, \hat{\theta}_M$). Using a truncated Taylor series expansion, one can obtain the partial derivative after $\tau^2$, which is a reasonable choice for $\tau_0^2$. Using $\tau^2 + \tau_0^2$ for $\hat{w}_i, \hat{theta}$, we can update $F(\tau^2)$ and check convergence to zero. \\
The estimation of $\tau^2$ is accompanied by uncertainty. A common procedure is to test if it is there is significant heterogeneity between the studies \cite[109]{Intro.meta}. For this, $Q$ has to be computed as given in \eqref{eq:Q.heterogeneity}. It is assumed that $Q$ follows a central Chi-squared distribution with $n -1$ degrees of freedom under the null hypothesis of equally distributed effect sizes. Thus, the expected value of $Q$ is $n-1$, and the excess dispersion is $Q - n + 1$. The $p$\hspace{0.4mm}-value against the null hypothesis of equally distributed effect sizes is $1 - F(Q)$, using $F$ as the cumulative distribution function of the Chi-squared distribution with d.f. = $n-1$. \\
$\tau^2$ is  is directly linked to the variability in the data. The $I^2$ statistic of excess/total dispersion can be used alternatively to assess the extent of additional variance to the variances of the primary study estimates. It is computed as

\begin{align}
I^2 &= \max\Big(0, 1 - \frac{n-1}{Q}\Big) \nonumber%\label{I2.proportion}
\end{align}

The statistic takes value between zero and one, and is easily interpretable. 0 is equal to 0\% excess dispersion and \eg 0.5 equal to 50\% additional between-study variance of the total variance of the estimates. \\
Importantly, all proposed methods above assume normally distributed effect sizes and proper estimates $\hat{\se}$ of the true standard error. This assumptions are not met for very small sample sizes and very few event counts. Alternatively, the Mantel-Haenszel method for risk and odds ratios (see \eg \citet{mantel.haenszel}) could be used in the latter case. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Linear, Weighted and Linear Mixed Regression Models} \label{sec:regression}
First, the concept of simple linear regression is introduced \citep{fahrmeir2007}. In short, the model assumes a dependent variable $y$ to be a linear function of another explanatory variable $x$, with the residuals being distributed independently and identically and following a normal distribution:

\begin{align}
y &= \beta_0 + \beta_1 x + \epsilon, & \epsilon \sim N(0, \sigma^2) \label{eq:simple.regression}
\end{align}

$\epsilon$ is the residual noise term that becomes necessary when $n$ pairs $(x_i, y_i)$ are given and there is no exact solution. We look for the solution that minimizes the squared residuals, the least-squares solution. Formally,

\begin{align}
\operatorname*{argmin}_{\beta_0, \beta_1}\Big(\sum_{i = 1}^n y_i - \beta_0 - \beta_1 x_i\Big) \label{eq:least.squares}
\end{align}

Let $\mathbf{X}$ be a matrix with the explanatory variables $x$ and $\mathbf{y}$ a corresponding vector for all $y$:

\begin{equation*}
\mathbf{X} = 
\begin{bmatrix}
1 & x_{12} \\
1 & x_{22} \\
1 & x_{32} \\
\vdots & \vdots \\
1 & x_{n2} \\
\end{bmatrix} 
\qquad
\mathbf{y} = 
\begin{bmatrix}
y_1 \\
y_2 \\
y_3 \\
\vdots \\
y_n \\
\end{bmatrix}
\end{equation*}

\vspace{2mm}

Let $\mathbf{\beta} = (\beta_0, \beta_1)^\top$. It can be shown that 

\begin{align}
\hat{\mathbf{\beta}} &= (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y} \label{eq:regression.parameters}
\end{align}

Is an estimator of $\mathbf{\beta}$ that minimizes the squared residuals. Let $\hat{\mathbf{y}} = \mathbf{X}\hat{\mathbf{\beta}}$ and $\hat{\mathbf{r}} = \hat{\mathbf{y}} - \mathbf{y}$. The variance estimates $\hat{\sigma}^2$ and $\hat{\mathbf{s}}_\beta^2$ are

\begin{align}
\hat{\sigma}^2 &= \frac{1}{n-2}\mathbf{r}^\top \hat{\mathbf{r}} & \hat{\mathbf{s}}_\beta^2 &= \hat{\sigma}^2 (\mathbf{X}^\top \mathbf{X})^{-1} \label{eq:regression.variances}
\end{align}

If one plots the values of $y$ and $x$, the estimate $\hat{\beta}_0$ is the intercept and $\hat{\beta}_1$ the slope of the regression line. Furthermore, in the simple linear regression setting, $\hat{\beta}_0$ can also be obtained by:

\begin{align}
% \hat{\beta_1} &= \frac{\sum_{i = 1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n (x_i - \bar{x})^2} &
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \nonumber
\end{align}

$\bar{x}$ and $\bar{y}$ denoting the sample means of the corresponding values $x_1, .., x_n$ and $y_1, ..., y_n$. Thus, $\hat{\beta}_0$ is also called the global mean.
To test whether there is evidence for the intercept $\beta_0$ to be unequal to some value $\beta_{H0}$, a $t$-test can be used. 

\begin{align}
p &= 2(1-F(\abs{(\beta_0 - \beta_{H0})/s_{\beta_0}})) \nonumber
\end{align}

where $F$ is the cumulative $t$ distribution with $n-2$ degrees of freedom. The $p$\hspace{0.4mm}-value will give the evidence against the null hypothesis $\beta_0 = \beta_{H0}$. \\
The concept is extendable to weighted linear regression. Weighted linear regression may be used if the residuals $\mathbf{r}$ have unequal variances, which is equivalent to ascribe different precision to the observed $y$ (heteroscedasticity). The least squares equation \eqref{eq:least.squares} is extended as follows:

\begin{align}
\operatorname*{argmin}_{\beta_0, \beta_1}\Big(\sum_{i = 1}^n w_i(y_i - \beta_0 - \beta_1 x_i)\Big) \nonumber
\end{align}

with the positive weights $w_i$ penalizing large squared residuals for some $i$ more if $w_i$ is larger. \\
Let $\mathbf{W}$ be a $n \times n$ matrix with $\mathbf{W}_{ii} = w_i$, the weights on the diagonal and zeros on the off-diagonals. The estimates in \eqref{eq:regression.parameters} and \eqref{eq:regression.variances} can again be used if $\mathbf{X}$ is exchanged with $\mathbf{X}^\star =  \mathbf{W} \mathbf{X}$ and $\mathbf{y}$ with $\mathbf{y}^\star = \mathbf{W} \mathbf{y}$. \label{weighted.regression} \\
The introduction of group-specific random effects allows to analyze grouped or repeated measurements by linear regression. Let $j$ be the group index, $i$ the index of the single observation from the group $j$ and $x_i$ the $i^\textrm{th}$ row of $\mathbf{X}$, $(1, \mathbf{X}_{i2})$. Then the equation

\begin{align}
\mathbf{y}_i|U_j,\epsilon_{i} =  x_i\beta + U_j + \epsilon_{i} \label{eq:one.random.intercept}
\end{align}

gives the marginal distribution of $\mathbf{y}_i$ depending on $U{_j}$ and $\epsilon_i$. The random effects $U_j \sim N(0, \mathbf{G})$ and the residual error term $\epsilon_i \sim N(0, \tau^{2})$ are independent from each other. Let $\mathbf{y}_j$ be a vector of all observations of group $j$. The expectation $\mathbb{E}(\mathbf{y}_i)$ is still $x_i \beta$, but the covariance between the observations within a group $j$, is modeled as

\begin{align}
\Cov(\mathbf{y}_j) &= \mathbf{D}_j \mathbf{G} \mathbf{D}_j^\top + \tau^2 \mathbf{I}_{n_j} \label{eq:random.intercepts.covariance}
\end{align}

where $\D_j$ is in the case of the random intercept model a $n_j \times 1$ matrix of 1's, $\mathbf{G}$ is a scalar to be estimated and $\mathbf{I}_{n_j}$ is an $n_j \times n_j$ identity matrix. Thus, if $\mathbf{G} \neq 0$, the observations within a group will be uniformly correlated (uniform correlation between each observation). \\
Nested groups can be modelled by extending the design matrix $\mathbf{X}$ with an additional column of 1's and using according indices that specify the nesting structure.\\
An extension of the random intercepts model is the random slopes model, which allows for additional, group-specific slopes with respect to a explanatory variable $x$. It can be implemented by modifying \eqref{eq:one.random.intercept}. Let $\mathbf{U}_j$ be a two-dimensional random vector with a $2 \times 2$ covariance matrix $\mathbf{G}$. Again, we can specify the marginal distribution of a observation $i$ within a group $j$:

\begin{align}
\mathbf{y}_i|U_j,\epsilon_i =  x_i\beta + x_i \mathbf{U}_j + \epsilon_i \label{eq:one.random.intercept.and.slope}
\end{align}

$\mathbf{D}_j$ is a $n_i \times 2$ equal to all rows of observations of $j$ in $\mathbf{X}$. The covariance matrix $\mathbf{V_j}$ for group $j$ is defined as in equation \eqref{eq:random.intercepts.covariance}, using the new $\mathbf{D}_j$. Defining $\mathbf{x}_j$ as the matrix with all observations from group $j$ of $\mathbf{X}$, and equivalently the vector $\mathbf{y}_j$, $\hat{\beta}$ is obtained by computing

\begin{align}
\hat{\beta} &= \Big( \sum_{j = 1}^m \mathbf{x}_j^\top \hat{\mathbf{V}}_j^{-1} \mathbf{x}_j \Big)^{-1} \sum_{j = 1}^m \mathbf{x}_j^\top \hat{\mathbf{V}}_j^{-1} \mathbf{y}_j
\end{align}

with $m$ being the number of groups and $\hat{\mathbf{V}}_j$ being the estimated covariance, obtained by maximizing the log likelihood of the normal distribution, as $\mathbf{y}_j$ is distributed as

\begin{align}
\mathbf{y}_j \sim N(\mathbf{x}_j \beta, \mathbf{V}_j)
\end{align}

The matrices $\sum_{j = 1}^m \mathbf{x}_j^\top \hat{\mathbf{V}}_j^{-1} \mathbf{x}_j$ and $\hat{\mathbf{V}}_j$ are assumed to be positive definite  . The approximate covariance matrix of $\hat{\beta}$ is given by

\begin{align}
\hat{\Cov}(\hat{\beta}) &= \Big( \sum_{j = 1}^m \mathbf{x}_j^\top \hat{\mathbf{V}}_j^{-1} \mathbf{x}_j \Big)^{-1}
\end{align}

Weights can be introduced by replacing $\mathbf{I}_{n_j}$ in \eqref{eq:random.intercepts.covariance} with the previously introduced weight matrix $\mathbf{W}_j$. Hypothesis tests for $\beta = \beta_\textrm{H0}$ can be made using the Wald method. 










\section{Publication Bias Tests}
The tests that will be presented on the following pages are a common way to detect publication bias. A frequently to test and adjust for publication bias, which goes under the name of trim-and-fill \citep{trimfill} is not discussed because of its disadvantageous properties, therefore, it will not be discussed here (see \eg \citet{Moreno.2009}).\\

\subsection{Begg and Mazumdar: Rank Correlation Test} \label{sec:Begg}
\citet{begg.ties} proposed a rank based test to test the null hypothesis of no correlation between effect size and variance.
A standardized effect size $\theta_i^\star$ can be computed as in \eqref{eq:begg.stand.eff}. $\se_i^{2\star}$ is the variance of $\theta_i - \theta_M$ as defined in \eqref{eq:begg.stand.var} and $\theta_M$ is the fixed effects pooled treatment effect (\eqref{eq:fixed.effects}. 

\begin{align}
\theta_i^\star &= (\theta_i - \theta_M)/\se_i^{2\star} \label{eq:begg.stand.eff}  \\
\se_i^{2\star} &= \se_i^2 - 1/\sum_{i = 1}^n\frac{1}{\se_i^2}1 \label{eq:begg.stand.var} 
\end{align}

A rank correlation test based on Kendall's tau is then used. First, the pairs are ordered after their ranks based on $\se^{2\star}$. Then, for each $\se^{2\star}$ rank, the corresponding ranks based on $\theta^{2\star}$ that are larger are counted and summed up to $u$. The number of ranks based on $\theta^{2\star}$ that are in contrary, smaller, are counted and summed up to $l$. Then the normalized test statistic $Z$ is given as

\begin{align}
Z &= (u - l)/\sqrt{n(n-1)(2n + 5)/18} \nonumber
\end{align}

Thus, large number of concordant pairs will reflect in large $\hat{u}$ and small $\hat{l}$ and thus lead to a large $\hat{Z}$. A two-sided $p$\hspace{0.4mm}-value is obtained using the standard normal distribution $\Phi$:
\begin{align}
p &= 2\cdot(1-\Phi(\abs{Z})) \nonumber
\end{align}

A one-sided test for positive correlation is obtained by computing $1-\Phi(Z)$ instead.
The changes that have to be made int the case of ties are small and can be found in \cite[410]{begg.ties}.


\subsection{Egger's Test: Weighted Linear Regression Test} \label{sec:Egger}
Linear regression can be used to test dependency of effect sizes on study sizes. The simplest application was introduced by \citet{Egger}.
Let $\theta/\se$ be the dependent variable $y$ and $1/\se$ the explanatory variable $x$. If plotted, this corresponds to a radial or Galbraith plot \citep{galbraith}. The linear regression equation as introduced before in \eqref{eq:simple.regression} can be written in two ways:

\begin{align}
\theta/s &= \beta_0 + \beta_1/\se + \epsilon, & \epsilon \sim N(0, \sigma^2) \label{eq:radial.plot} 
\end{align}

Equation \eqref{eq:radial.plot} is often provided due to the correspondence to the radial plot. However, it is equivalent to

\begin{align}
\theta &= \beta_0 + \beta_1 \se + \epsilon, & \epsilon \sim N(0, w^{-2}\sigma^2) \label{eq:egger.plot}
\end{align}

with weights $w = 1/\se^2$. Thus testing $\beta_0$ of \eqref{eq:radial.plot} or $\beta_1$ of \eqref{eq:egger.plot} is equivalent. The corresponding $p$\hspace{0.4mm}-value is then used as evidence for a small study effect. Plugging in  $\theta_i/\se_i, 1/\se_i$ as $y_i, x_i$ into equations \eqref{eq:regression.parameters} and \eqref{eq:regression.variances} will give the estimates for $\hat{\beta}_0, \hat{\beta}_1,\hat{\se}_{\beta_0}$ and $\hat{\se}_{\beta_1}$.

% \begin{align}
% \hat{\beta_1} &= \frac{\sum_{i = 1}^n (\varphi_i - \bar{\varphi})(\theta^\star_i - \bar{\theta}^\star)}{\sum_{i = 1}^n (\varphi_i - \bar{\varphi})^2} &
% \hat{\beta}_0 &= \bar{\theta}^\star - \hat{\beta}_1 \bar{\varphi} \nonumber
% \end{align}


\subsection{Thompson and Sharp's Test: Weighted Linear Regression Random Effects Test} \label{sec:Thompson}
A method proposed in \citet{thompson.sharp} allows for between study variance $\tau^2$, as introduced before in section \ref{sec:meta.analysis}. It extends the previously seen linear regression approach with $x = 1/\se$ and $y = \theta/\se$ by introducing new weights. The effect size $\theta_i$ is assumed to be distributed as

\begin{align}
\theta_i \sim N(\beta_0 + \beta_1 \se_i, \se_i^2 + \tau^2) \label{t.sharp.regression}
\end{align}

$\tau^2$ is estimated as in equation \eqref{eq:Tau.definition} (method of moments). %or \eqref{eq:paule.mandel}. 
The weights are set as $w_i = 1/\sqrt{\se_i^2 + \tau^2})$. After adjusting for the weights as described in \ref{weighted.regression}, we can proceed analogous to Egger's test. The $p$\hspace{0.4mm}-value for $\beta_{0} \neq 0$ reflects the evidence for a small study effect.


\subsection{Peters Test: Weighted Linear Regression Test} \label{sec:Peter}
When the outcome is dichotomous, effect sizes and variances of effect size are correlated, which can readily be seen in \eqref{eq:risk.ratio} and \eqref{eq:risk.ratio.variance} (see also \cite[120]{meta.w.R}). A small number of event counts in one or group will inflate the variance and the effect size. Consequently, the tests above will tend to reject the null-hypothesis too often, \ie report false positives.\\ 
Instead of taking the standard error $\se$ as explanatory variable $x$ as in Egger's Test, the inverse of the total sample size is used. Additionally, the variances $\se_i^2$ are used as weights. Thus, the subsequent test procedure is identical to Egger's test. Peters test is a a small modification of Macaskill's test where the explanatory variable is the sample size instead of its inverse. \\



\subsection{Harbord's Test: Score based Test} \label{sec:Harbord}
A rank based alternative to Peters test for binary outcomes is Harbord's test \citep{Harbord}.
It uses a different treatment effect and variance estimate: the score $\varphi$ of the log-likelihood, evaluated at log odds ratio $\theta_\textrm{H0} = 0$ and its inverse Fisher information $s^2$. Formally,

\begin{align}
\varphi &= e_t - (e_t - e_c)(e_t + (n_t - e_t))/(n_t + n_c) \label{harbord.score} \\
 s^2 &= \frac{(e_t + e_c)(e_t + (n_t - e_t))(e_c + (n_c - e_c))((n_t - e_t) + (n_c - e_c))}{(n_t + n_c)^2(n_t + n_c - 1)} \label{harbord.variance}
\end{align}

It can be shown that they are both good approximations of the log odds ratio and its variance if the real $\theta$ is not too far from zero. The standardized estimator $\varphi_i/\se_i^2$ is also known as Peto odds ratio. The obtained scores and variances can be used in Egger's test as treatment effects and variances.


\subsection{Schwarzer's Test: Rank Correlation Test} \label{sec:Schwarzer}
\citet{Schwarzer} developed a test for the correlation between the event counts in the treatment group and the expected event counts $E_t - \mathbb{E}(E_t)$. When the marginals in a two-by-two table and the log odds ratio is fixed, it can be shown that $E_t$ follows a non-central hypergeometric distribution. Using the Mantel-Haenszel log odds ratio and the marginal total parameters, the variance and the expectation of $E_t$ is calculated. The inverse of the variance $\se(E_t)^2$ and the standardized event count

\begin{align}
(e_t - \mathbb{E}(E_t))/\sqrt(\se_i^2)
\end{align}

are then used as before in Begg and Mazumdar's test.

\subsection{R\"ucker's Test: Using the Variance Stabilizing Transformation for Binomial Random Variables} \label{sec:Rucker}
The correlation between variance and effect size of dichotomous outcome measures can be abolished by the variance stabilizing transformation for binomial random variables. We use that the arcsine function is the variance stabilizing transformation for a proportion. Let

\begin{align}
\theta_i &= \arcsin{e_t/n_t} - \arcsin{e_c/n_c} \nonumber &
\se_i^2 &= 1/4n_t + 1/4n_c \nonumber
\end{align}

Then one can optionally apply Begg and Mazumdar's rank correlation test or Thompson and Sharp's test using the newly obtained estimates.


\subsection{Excess Significance Test} \label{sec:excess.significance}
\citet{excess.significance} developed an exploratory test to detect if the proportion of significant findings is larger than expected. 
%Note that significance is here defined as one-sided significance, with the direction of the test being the same for each study. \\
We assume that the effects are equally distributed around a true mean effect $\theta_M$, which can be estimated by fixed effects Meta-Analysis \eqref{eq:fixed.effects}. Let $O$ be the number of significant study results out of $n$ studies and $\alpha$ the significance threshold. Corresponding to the study effect $\theta_i$, we can specify the power $1 - \beta_i$, the probability to be accepting a true result. Let $z_{\alpha,i}$ be the $1-\alpha$ quantile of a normal distribution with standard error $\hat{\se}_i$. The power of study $i$ can be estimated as:

\begin{align}
1 - \hat{\beta}_i &= F(z_\alpha) 
\end{align}

with $F$ being the cumulative normal distribution with mean $\hat{\theta}_M$ and standard deviation $\hat{\se}_i$. \\
If we assume no bias in $\theta_i$ and $\theta_M$, the expected number of significant study results is then just

\begin{align}
E &= \sum_{i = 1}^n (1 - \beta_i) \nonumber
\end{align}

$E$ can then be compared to $O$ by constructing a test statistic $\chi$:

\begin{align}
\chi  &= \bigg( \frac{(O - E)^2}{E} + \frac{(O - E)^2}{n - E}\bigg) \nonumber
\end{align}

and consecutively, calculating a $p$\hspace{0.4mm}-value for the evidence against the null-hypothesis of $O = E$ with a $\chi^2$ distribution with one degree of freedom. Alternatively, one can also use a binomial test, which is encouraged when $n$ and $O$ is small. We will get a one sided $p$\hspace{0.4mm}-value for excess significance, $\P(X \geq O)$, by computing

\begin{align}
p &= \sum_{i = O}^n\Big({n \choose i} p^i (1-p)^{n - i}\Big)
\end{align}

with $p = E/n$ and $X$ being a binomial random variable with probability $p$. 





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\section{Publication Bias Adjustment}
There are different approaches to correct for small study effects and publication bias. They can mainly be distinguished by their underlying methods: regression based approaches aim to regress the effect to a study with infinite precision (\ie very small standard error) or to a summary effect, corrected for publication bias. Selection models are used for a sensitivity analysis, where the selection parameters are assumed to be fixed. 

\subsection{Adjustment by Regression} \label{sec:regression.adjustment}
In \citet{limitmeta.2} and \citet{limitmeta}, a random effects model is proposed to obtain unbiased treatment effect estimates. Similarly to regression based tests for small study effects, we have

\begin{align}
\theta_i & = \beta_0 + \beta_1\sqrt{\se_i^2 + \tau^2} + \epsilon_i\sqrt{v_i + \tau^2}, \label{eq:limitmeta.regression} \\
\epsilon_i \stackrel{\textrm{iid}}{\sim} N(0,1)
\end{align}

The only difference between Thompson and Sharp's variant and this method is that $x = \sqrt{\se^2 + \tau^2}$ is used instead of $x = \sqrt{\se^2}$. $\beta_{1}$ is the bias parameter and can be interpreted as the bias introduced by small study effects, as illustrated in the following equations:

\begin{align}
\mathbb{E}((\theta_i - \beta_0)/\sqrt{\se_i^2}) \rightarrow \beta_1 \textrm{ if } \se_i \rightarrow \infty \nonumber \\ %\label{limitmeta.infinitesample} \\
\mathbb{E}(theta_i) \rightarrow \beta_0 + \beta_1 \tau \textrm{if} \se_i \rightarrow 0 \nonumber
\end{align}

After estimating $\tau^2$, one can estimate $\beta_{0}$ and $\beta_{1}$ as seen before in the simple linear regression framework.There are two possible estimates at hand:
\begin{itemize}
\item $\beta_0$ the treatment effect without any influence of study precision with standard error $\se_{\beta_0}$
\item $\beta_0 + \beta_1 \tau$ the treatment effect of a hypothetical study with infinite precision, corresponding standard error $\se = \se_{\beta_0} + \se_{\beta_1}$
\end{itemize}

Simulations in \citet{limitmeta} suggested that the latter estimate is slightly superior to the former, because it showed a smaller mean-squared error in simulation studies \citet{limitmeta.2}. From the formulas above, it becomes clear that is has a larger standard error. The results of the simulation furthermore emphasize that adjustment is more reliable when effects of publication bias are strong within a meta-analysis. When no publication bias affects the meta-analysis, and event rates are low, the method provided biased estimates and the mean squared error was large. The coverage of the confidence intervals was always larger or equal to meta-analysis. It outperforms or is equal to classical meta-analysis estimates with respect to coverage, mean squared error and bias if there is publication bias, especially if event rates in the control group are small. 



\subsection{Copas Selection Model} \label{sec:copas}

A method proposed in \cite{Copas1,Copas2,Copas3} assumes that study results are selected based on the specific properties of their effect sizes and variances. \\
Let $\theta_i$ be the effect size estimate of study $i$. Then 

\begin{align}
\theta_i &\sim N(\mu_i, \sigma_i^2) &
\mu_i \sim N(\theta, \tau^2) \label{eq:population.model}
\end{align}

which is identical to the random-effects meta-analysis setting. $\theta$ is the population mean effect, $\sigma_i^2$ the within study variance and $\tau^2$ the between study variance. This is termed the \textit{population model}. \\
The \textit{selection model} is defined as follows. Suppose a selection of studies with reported %($\neq$ estimated) 
standard errors $\se$ (possibly different from $\sigma$). Only a proportion of the selection will be published, with the parameter $a$ defining the overall proportion of published studies and $b$ (assumed to be positive) defining how fast this proportion increases with $\se$ becoming smaller. Formally, the probability of selection given a reported standard error $\se$ is defined as

\begin{align}
P(\textrm{select}\given \se) &= \Phi(a + b/\se) \nonumber %\label{copas.selection1}
\end{align}

The equation can be rewritten as 

\begin{align}
z = a + b/\se + \delta \nonumber %\label{copas.selection2}
\end{align}

with $\delta \sim N(0,1)$. $z$ is interpreted as the \textit{propensity for selection}. It is defined that the sign of $z$ must be positive in order for the study to be selected.
$a$ is some kind of global selection rate for each study and $b$ decides about the decline of selection probability with increasing $\se$.\\
So far, we have, for a study $i$

\begin{align}
\theta_i = \mu_i + \sigma_i\epsilon_i \nonumber \\ 
\mu_i \sim N(\theta, \tau^2) \nonumber \\
z_i = a + b/\se_i + \delta_i \nonumber
\end{align}

where $(\epsilon_i, \delta_i)$ are standard normal residuals. The two models are coupled by introducing a correlation $\rho = cor(\theta_i, z_i)$ by defining $(\epsilon_i, \delta_i)$ as bivariate standard normals. It follows that,
%Every given study $i$ in the meta-analysis has $z_i > 0$. 
if $\rho_i$ is unequal to zero and positive and $z_i > 0$, then the estimate of a study $i$ that is selected is likely to have positive $\delta_i$ and thus positive $\epsilon_i$, such that the true mean $\mu$ is likely to be overestimated. \\
Let $u_i = a + b/\se_i$, $\lambda(u_i)$ the Mill's ratio $\phi(u_i)/\Phi(u_i)$ ($\phi$ is the standard normal density function and $\Phi$ the cdf) and $\tilde{\rho_i} = \sigma/\sqrt(\tau^2 + \sigma_i^2) \rho_i$. The probability of a study being selected, given $\se_i$ and $\theta_i$, is

\begin{align}
P(\textrm{select} \given \se_i, \theta_i) = %P(a,b,s,y) = 
\Phi\bigg(\frac{u_i + \tilde{\rho_i}((\theta_i - \mu)/\sqrt(\tau^2 + \sigma_i^2))}{\sqrt{1 - \tilde{\rho_i^2}}}\bigg) \nonumber
\end{align}

Which shows that larger $\se_i$ and $\theta_i$ lead to a larger selection probability. It can also be shown that the expected value 

\begin{align}
\mathbb{E}(\theta_i \given \se_i, \textrm{select}) = \mu + \rho_i\sigma_i\lambda(u_i) \label{eq:copas.expectation}
\end{align}

increases for larger $\sigma$.\\
A likelihood for $\theta_i$, conditional on $z>0$ can be formulated to estimate the parameters of the model. $a$ and $b$ are not estimated because the number of missing studies and their effect sizes is not known. Instead, fixed values for $a$ and $b$ have to be imputed.
The nuisance parameter $\sigma_i$ can be estimated, as

\begin{align}
\textrm{Var}(\theta_i\given \se_i, z_i > 0) = \sigma_i^2 (1 - c_i^2\rho_i^2) \nonumber
\end{align}

with $c^2 = \lambda(u_i)(u_i + \lambda(u_i))$. Thus we can replace $\sigma_i^2$ by $\hat{\sigma}_i^2 = \frac{1}{1-c_i^2\rho_i^2}$. \\ 
With equation \eqref{eq:copas.expectation}, one can obtain fitted values of $\theta_i$ based on $\se_i$ and fixed $a$ and $b$. For two different pairs $(a,b)$, $(a^\star, b^\star)$,

\begin{align}
\mathbb{E}(\theta_i\given z_i > 0, a^\star, b^\star) - \mathbb{E}(\theta_i\given z_i > 0, a, b) \approx c^\star + \rho(\lambda(a^\star) - \lambda(a))\se_i \nonumber
\end{align}

Local departures of two fitted values of $\theta_i$ can be approximated by adding a linear term in $\se_i$ to the expectation of $\theta_i$. Thus, to test a single pair $(a,b)$ (chosen such that $\rho \geq 0$), it is sufficient to test $\beta \neq 0$ in

\begin{align}
\theta_i &= \theta + \beta \se_i + \sigma_i \epsilon_i \nonumber
\end{align}

If $\beta \neq 0$, there is still bias in the fitted values. To test a pair $(a,b)$ against the scenario with no selection, we set $a^\star = \infty$ (or $\rho = 0$) and $b^\star = 0$. A likelihood ratio test will give a test statistic to test against $H0 =$ no selection ($\beta \neq 0$):

\begin{align}
\chi^2 &= 2\cdot(\operatorname*{max1}_{\theta, \tau, \beta}\tilde{L}(\theta, \tau, \beta) - \operatorname*{max}_{\theta, \tau}\tilde{L}(\theta, \tau, 0)) \label{eq:copas.small.study}
\end{align}

with 
\begin{align}
\tilde{L}(\theta, \tau, \beta) = -\frac{1}{2}\sum_{i = 1}^n[\log(\tau^2 + \sigma_i^2) + \frac{(\theta_i - \theta - \beta \se_i)^2}{(\tau^2 + \sigma_i^2)}] \nonumber
\end{align}

$\chi^2$ can be used with a $\chi^2$ distribution with one degree of freedom to obtain a $p$\hspace{0.4mm}-value. Note that the test is very similar to Egger's small study effect test when $\tau^2 = 0$.\\
In practice ne can observe how $\theta$ and it's confidence intervals change dependent on the underlying selection process, and how the choice of the parameters affect the evidence for remaining publication bias (selection). \citet{limitmeta} used the method in a simulation for inference purposes, and have implemented it in the \citet{meta.package}. However, in the simulations, the method was outperformed by the regression adjustment method when publication bias was present. Especially when event rates in the control group were small and publication bias was strong, bias, mean squared error and coverage was substantially worse. Other authors argue that selection models should in general not be used for inference (\eg \citet{selection.assessment}).\\
The procedure in \citet{limitmeta} is the following: A range of values of $(a,b)$ are applied, and the test for residual small study effect as described in equation \eqref{eq:copas.small.study} is applied. If all obtained $p$\hspace{0.4mm}-values from the test are above a threshold 0.1, this is interpreted as no evidence, and no need for adjustment, and the standard, classical random effects meta-analysis is retained. If none of the $p$\hspace{0.4mm}-values is above the threshold, a wider range of values for $(a,b)$ is used. When some $p$\hspace{0.4mm}-values are above, and some below the threshold, the pair $(a,b)$ with the smallest number of missing studies is retained (that is, the pair of $a$ and $b$ that implies the fewest publication bias is chosen).\\
Currently, there is no test to detect miss-specifications in the model itself and the authors themselves have argued that a non-parametric test of the residuals would lack power.



\section{Transformation between Effect Measures} \label{sec:transformation.effectsizes}
Assuming that binary outcomes result from a dichotomization of originally continuous random variables, binary outcome measure can be transformed into continuous outcome measures. Here, the logistic distribution is used to achieve the transformation from a typical binary effect measures to a std. mean difference \cite[47]{Intro.meta}.\\
Let $\theta$ be a log odds ratio and $\se$ it's standard error. The std. mean difference $d$ and it's variance $\se_d^2$ can be obtained as

\begin{align}
d &= \theta \frac{\sqrt{3}}{\pi} & \se_d^2 =  \se^2\frac{\sqrt{3}}{\pi} \nonumber
\end{align}

The factor $\frac{\pi}{\sqrt{3}} = 1.81$ is the standard deviation of the logistic distribution $L(\mu, \eta)$ with scale parameter $\eta = 1$, so we just divide the log odds ratio and it's variance through the standard deviation. The approximation works only well if $e_t$ and $e_c$ are not very small, especially in the case of $s_d^2$. \\
The Pearson's correlation coefficient can be attained by the formulas (\citet{olkin1985dtor}, \cite[48]{Intro.meta})

\begin{align}
r &= \frac{d}{\sqrt{d^2 + a}} & a = (n_c + n_t)^2 / n_c n_t \nonumber
\end{align}

where $a$ is a correction factor if $n_t \neq n_c$. The variance of $r$, $\se_r^2$ is computed by

\begin{align}
s_r^2 &= \frac{a^2 s_d^2}{(d^2 + a)^3} \nonumber
\end{align}

Finally, we can get to a fisher's z-scaled correlation $z$ and it's variance $\se_z^2$ by using
\begin{align}
% z &= 0.5 \ln\big(\frac{1 + r}{1 - r}\big) & \nonumber
z &= \arctan(r) & \nonumber
s_z^2 &= \frac{1}{n-3}
\end{align}















%SIMPLE LINEAR REGRESSION
% \begin{align}
% \hat{\mathbf{\beta}} &= (\mathbf{X}^\top  \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y} \label{eq:regression.parameters}
% \end{align}

% There is a closed form solution for $\hat{\beta_0}, \hat{\beta}_1$ that minimize the sum of squares:
% 
% \begin{align}
% \hat{\beta_1} &= \frac{\sum_{i = 1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n (x_i - \bar{x})^2} & 
% \hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \label{eq:regression.estimator}
% \end{align}
% 
% $\bar{x}, \bar{y}$ denotes the sample mean of the corresponding values $x_1, .., x_n$ and $y_1, ..., y_n$. $\hat{\beta}_0$ is the intercept and $\hat{\beta}_1$ the slope of the fitted line. Let $\hat{y}_i = \beta_0 + \beta_1 x_i$ and $e_i = y_i - \hat{y}_i$. The variances $\se^2_\beta$
% 
% 
% 
% To test whether the intercept or the slope is close to a certain value, a $t$-test can be used. Simply taking the absolute value of $\beta_0/s_\beta_0$,
% \begin{align}
% p &= 2(1-F(|\beta_0/s_\beta_0|)) \nonumber
% \end{align}
% 
% where $F$ is the cumulative $t$ distribution with $n-2$ degrees of freedom. The $p$\hspace{0.4mm}-value will give the evidence against the null-hypothesis $\beta_0 = 0$. The procedure for $\beta_1$ is equivalent. \\
% To extend the model to weighted simple linear regression is straightforward. Let $w_i$ be the corresponding weight that will be attributed to the pair $x_i, y_i$. The least squares minimization problem can be restated
% 
% \begin{align}
% \operatorname*{argmin}_{\beta_0, \beta_1}(\sum_{i = 1}^n w_i(y_i - \beta_0 - \beta_1 x_i)) \nonumber
% \end{align}
% 
% And the corresponding estimators are thus
% 
% \begin{align}
% \hat{\beta_1} &= \frac{\sum_{i = 1}^n w_i(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n w_i(x_i - \bar{x})^2} & 
% \hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \label{eq:regression.estimator}
% \end{align}
% 



% LIMITMETa
% \vspace{0mm}
% To diminuish the random variation within studies, but keep the variation between studies, we change \ref{limitmeta.regression} to a scenario where each study has $M$-fold increased precision:
% 
% \begin{align}
% y_{M,i} &= \beta_{0}^\star + \beta_{1}^\star(\sqrt{v_{i}/M + \tau^2}) + \epsilon_{i}(\sqrt{v_{i}/M + \tau^2}) \label{limitmeta.regression}
% \end{align}
% 
% Letting $M \rightarrow \infty$, we obtain:
% 
% \begin{align}
% y_{\infty,i} &= \beta_{0}^\star + \tau(\beta_{1}^\star + \epsilon_{i}),  \epsilon_{i} \stackrel{\textrm{iid}}{\sim} N(0,1) \label{limitmeta.regression.infinity}
% \end{align}
% 
% Note that:
% 
% \begin{align}
% y_{\infty,i} &= \beta_{0}^\star + \tau\beta_{1}^\star = \beta_{0}
% \end{align}
% 
% $\beta_{0}$ is termed the limit meta analysis expectation. Now, the random errors from \ref{limitmeta.regression} are rewritten as:
% 
% \begin{align}
% \epsilon_{i} &= \frac{y_{i} - \beta_{0}^\star}{\sqrt{v_{i} + \tau^2}} - \beta_{1}^\star
% \end{align}
% 
% Assuming $\epsilon_{i}$ to be fixed, we can plug it into \ref{limitmeta.regression.infinity} and get 
% 
% \begin{align}
% y_{\infty,i} &= \beta_{0}^\star + \sqrt{\frac{\tau^2}{v_{i} + \tau^2}}(y_{i} - \beta_{0}^\star)
% \end{align}
% 
% By estimating $\tau^2, v_{i}$ and  $\beta_{0}^\star$, we can use the formula to obtain a new study means, adjusted for small study effects and shrunken to a common mean. 









% \section{Basic notation}
% The notation used here will be used throughout the chapter and exceptions will be noted. Let $i$ be the number of a study of a meta analysis with $n$ being the total number of studies. $y_{i}$ is then the effect size estimate (usually log odds ratio or mean difference) and $v_{i}$ the variance of the estimate of study $i$. $w_{i}$ is used for weights which are defined when necessary, and $\Delta$ usually denotes the summarized or pooled effect estimate of the meta-analysis, and $\eta$ the variance thereof.
% 
% \vspace{0mm}
% In the case of binary outcomes, let $e_{t}$ be the number of events and $n_{t}$ be the total number of patients in the treatment arm and $n_{c}$ and $e_{c}$ analogously for the control arm in a two-armed study $i$. 
% 
% 
% \section{Transformation between effect sizes}
% Binary and continuous outcome measures can both be transformed into correlations and fishers z-scaled correlations in order to be compared. Let $\theta$ be a log odds ratio. A standardized mean difference $d$ (also known as Cohen's $d$) is calculated by multiplying $\theta$ with $\sqrt{3}/\pi$. The variance of the standardized mean difference is attained as $v_d = v_\theta \sqrt{3}/\pi$.\\
% We get from a standardized mean difference $d$ to a correlation $r$ by using 
% \begin{align}
% r &= \frac{d}{\sqrt{d^2 + a}} \nonumber
% \end{align}
% where $a$ is a correction factor if $n_t \neq n_c, a = (n_c + n_t)^2 / n_c n_t$. The variance of $r$ is computed by using 
% \begin{align}
% v_r &= v_d
% \end{align}
% 
% Finally, we can get to a fisher's z-scaled correlation $z$ and it's variance $v_z$ by using
% \begin{align}
% z &= 0.5 \ln(\frac{1 + r}{1 - r}) \nonumber
% v_z &= \frac{1}{n-3}
% \end{align}
% 
% 
% 
% \section{Heterogeneity}
% In addition to sampling error, there can be additional, ``real'' variation between estimates of different studies, indicating real differences between the studies. This is called between study variation in contrast to within study variation (noise). 
% 
% 
% \vspace{0mm}
% The $Q$ statistic is a weighted sum of squares that quantifies the deviation from the weighted mean of study effect estimates. Let $w_i$ be the inverse of the variance and $\Delta$ be a summarized effect estimate of your choice as for example a variance-weighted mean \ref{weighted.mean}. Then $Q$ can be calculated as in \ref{Q.heterogeneity}
% 
% \begin{align}
% \Delta &= \frac{\sum_{i = 1}^n w_{i}y_{i}}{\sum_{i = 1}^n w_{i}} \label{weighted.mean} \\
% Q &= \sum_{i = 1}^n w_{i}(y_{i} - \Delta)^2 \label{Q.heterogeneity}
% \end{align}
% 
% Because $Q$ is a standardized measure, it does not depend on the effect size, but only on the study number $n$. Under the assumption of equal effect sizes of all studies, the expected value of $Q$ is $n-1$, so the excess dispersion is just $Q - n + 1$.To test the assumption of equal effect sizes one uses that $Q$ follows a central Chi-squared distribution with $n -1$ degrees of freedom under the null hypothesis of equal effect sizes. $1 - F(Q)$ will provide the $p$\hspace{0.4mm}-value for the significance test with $F$ being the cumulative distribution function of the Chi-squared distribution with the corresponding degrees of freedom.
% 
% \vspace{0mm}
% Since $Q$ is a standardized metric, it gives no impression of the real dispersion of the effect sizes. For this purpose, $\tau^2$, the variance of true effects, can be calculated. $\tau^2$ is on the same scale as the effect size and reflects the absolute amount of dispersion. In practice, $\tau^2$ can be smaller than zero, then it is set to zero.
% 
% \begin{align}
% C &= \sum_{i = 1}^n w_{i} - \frac{\sum_{i = 1}^n w_{i}^2}{\sum_{i = 1}^n w_{i}} \label{C.definition} \\
% \tau^2 &= \max(0, \frac{Q - d}{C}) \label{Tau.definition}
% \end{align}
% 
% The estimation method for $\tau^2$ is known as DerSimonian and Laird method, but others, such as restricted maximum likelihood can be used. Note that their estimate can differ substantially and consequently also the estimate of the pooled effect size estimate.
% 
% \vspace{0mm}
% To estimate the proportion of real variance between effect estimates of the observed variance, the $I^2$ can be used. The calculation is given in \ref{I2.proportion}
% 
% \begin{align}
% I^2 &= (Q - n + 1)/Q \label{I2.proportion}
% \end{align}
% 
% There are ways to compute confidence intervals for $I^2$ and $\tau^2$ that are not shown (see \cite[122]{metaanalysis}).
% 
% \section{Meta Analysis}
% There are numerous methods to pool the estimates of multiple studies into one estimate, and two will be introduced here; fixed and random effects meta-analysis.
% First the fixed effect meta-analysis will be explained. Note that both methods can be used for continuous or dichotomous outcomes. For more details about the methods, see chapter 11 and 12 in \citet{metaanalysis}
% 
% 
% \vspace{0mm}
% Let $w_i = 1/v_{i}$ be the inverse of the variance of the estimate from study $i$. The pooled estimate $\Delta_{f}$ of the fixed effects model is then the weighted average with the weights given by the inverses of the variances, $w_{i}$, given in \ref{weighted.mean}. The variance $\eta_{f}$ is the reciprocal of the sum of the weights as shown in \ref{reciproce.variance}.
% 
% \begin{align}
% \Delta_{f} &= \frac{\sum_{i = 1}^n w_{i}y_{i}}{\sum_{i = 1}^n w_{i}} \label{weighted.mean} \\
% \eta_{f} &= \frac{1}{\sum_{i = 1}^n w_{i}} \label{reciproce.variance}
% \end{align}
% 
% The computation of random effects meta-analysis is more complicated. Random effects meta-analysis will give smaller studies with larger variance more weight in the pooled estimate. Shortly, the idea is that the estimates are allowed to vary randomly around the true estimate $\Delta$, and additionally, the estimates are subject to noise or sampling error themselves. 
% 
% \vspace{0mm}
% The variance of a study estimate $y_{i}$ of study $i$, $v_{i}^\star$ is defined as in \ref{ranef.study.variance}, with $w_{i}^\star$ being the inverse of $v_{i}^\star$. It is used to calculate a new weighted mean to obtain a pooled estimate $\Delta_{r}$ as in \ref{ranef.weighted.mean}. The variance of $\Delta_{r}$, $\eta_{r}$ is then the sum of the reciprocal variances (\ref{ranef.reciproce.variance}).
% 
% \begin{align}
% v_{i}^\star &= v_{i} + \tau^2 \label{ranef.study.variance} \\
% \Delta_{r} &= \frac{\sum_{i = 1}^n w_{i}^\star y_{i}}{\sum_{i = 1}^n w_{i}^\star} \label{ranef.weighted.mean} \\
% \eta_{r} &= \frac{1}{\sum_{i = 1}^n w_{i}^\star} \label{ranef.reciproce.variance}
% \end{align}
% 
% A $p$\hspace{0.4mm}-value under the Null-hypothesis of $\Delta = 0$ can be obtained by calculating the $Z$-value (\ref{Zvalue}) and using the distribution function of a standard normal as shown in (\ref{p.value.calculation}), $\Phi$ being the distribution function of a standard normal distribution. 
% 
% \begin{align}
% Z &= \frac{\Delta}{\sqrt{\nu}} \label{Zvalue} \\
% p &= 2(1 - \Phi(|{Z}|) \label{p.value.calculation}
% \end{align}
% 
% \section{Small Study Effects Tests}
% One crucial assumption in meta analysis is that the availability and publication of studies does not depend on their effect and the variance of the effect. If this is not given, one often speaks of publication bias. In fact, there can also be other reasons for this (see discussion section). A more appropriate term for the phenomenon is small study effect. If small study effects are present in a meta-analysis, the classical approaches to merge single study results in to an overall intervention effect fails to provide an appropriate estimate of the treatment effect. 
% 
% \subsection{Continuous Outcome Tests}
% % Essentially, there are two kinds of tests for reporting bias, non-parametrical or rank-based tests or regression based tests. 
% % First, tests for continuous outcome studies are described, and special modifications of those for binary outcomes will be introduced later.
% 
% \subsubsection{Begg and Mazumdar: Rank Correlation Test}
% \citet{begg.ties} proposed a rank based test to test the null hypothesis of no correlation between effect size and variance.
% A standardized effect size $y_{i}^\star$ can be computed as in \ref{begg.stand.eff}. $v_{i}^\star$ is the variance of $y_{i} - \Delta_{f}$ as defined in \ref{begg.stand.var}. $\Delta_{f}$ is the pooled estimate for fixed effect estimate defined in \ref{weighted.mean}. 
% 
% \begin{align}
% y_{i}^\star &= (y_{i} - \Delta_{f})/v_{i}^\star \label{begg.stand.eff} \\
% v_{i}^\star &= v_{i} - 1/\sum_{i = 1}^n v_{i}^-1 \label{begg.stand.var} 
% \end{align}
% 
% A rank correlation test based on Kendall's tau is then used. The pairs $(y_{i}^\star, v_{i}^\star)$ that are ranked in the same order are enumerated. Let $u$ be the number of pairs ranked in the same order, and $l$ the number of pairs ranked in the opposite order (\eg larger standardized effect size and smaller variance). Then the normalized test statistic $Z$ is given in \ref{begg.teststat}. 
% 
% \begin{align}
% Z &= (u - l)/\sqrt{n(n-1)(2n + 5)/18} \label{begg.teststat}
% \end{align}
% 
% The changes in the case of ties are negligible \cite[410]{begg.ties}.
% 
% \subsubsection{Egger's Test: Linear Regression Test}
% Alternatively, one can use Eggers test \citep{Egger} that is based on linear regression. Let $y_{i}^\star = y_{i}/\sqrt{v_{i}}$ and $x_{i} = 1/\sqrt{v_{i}}$. 
% Using $y_{i}^\star$ as dependent, and  $x_{i}$ as explanatory variable in linear regression, one obtains an intercept $\beta_{0}$ and a slope. 
% 
% \vspace{0mm}
% If $\beta_{0} \ne 0$, the null hypothesis of no small study effect may be contested, using that $\beta_{0} \sim t_{n-1}$, $n-1$ being the degrees of freedom of the $t$-distribution. The $p$\hspace{0.4mm}-value for $\beta_{0} = 0$ (no reporting bias) is then given by \ref{egger.pvalue}.
% 
% \begin{align}
% p &= 2*(1 - t_{n-1}(\beta_{0}/se(\beta_{0}))) \label{egger.pvalue}
% \end{align}
% 
% \subsubsection{Thompson and Sharp's Test: Weighted Linear Regression Random Effects Test} \label{Thompson}
% A method proposed in \citet{thompson.sharp} allows for between study heterogeneity. Let $\tau^2$ be equal to \ref{Tau.definition}. The effect size estimates are then assumed to be distributed as in \ref{t.sharp.regression}. 
% 
% \begin{align}
% y_{i} \sim N(\beta_{0} + \beta_{1}x_{i}, v_{i} + \tau^2) \label{t.sharp.regression}
% \end{align}
% 
% Then, a weighted regression is carried out with weights $1/v_{i}^\star$ based on the inverse of the variance as in \ref{ranef.study.variance}. Analogous to Egger's test, $\beta_{0}$ is then tested with respect to the null hypothesis $\beta_{0} = 0$.
% 
% \subsection{Dichotomous Outcomes Tests}
% 
% The issue with dichotomous outcomes is that effect size and variance of effect size are not independent. Consequently, the tests above will tend to reject the null-hypothesis too often, \ie that they are not conservative enough. A number of solutions to this problem are existing in the literature.
% 
% 
% \subsubsection{Peters Test: Weighted Linear Regression Test}
% A modification of the weighted linear regression test that takes into account effect size and variance interdependence for dichotomous outcomes is proposed in \citet{Peters}.
% 
% \vspace{0mm}
% Let $y_i$ be the log-odds ratio estimate \ref{log.odds.ratio} and $v_{i}$ its variance \ref{variance.log.odds.ratio}
% 
% \begin{align}
% y_{i} &= \log(e_{t}*(n_{c} - e_{c})/e_{c}*(n_{t} - e_{t})) \label{log.odds.ratio}\\
% v_{i} &= 1/(e_{t}+(n_{t} - e_{t}) + 1/(e_{c}+(n_{c} - e_{c}) \label{variance.log.odds.ratio}
% \end{align}
% 
% and $x_{i}$ be the total sample size $n_{t} + n_{c}$. Instead of taking the variance as explanatory or independent variable in regression as in Egger's Test, the inverse of the total sample size $x_{i}$ is used, and the variance $v_{i}$ is used as a weight. The subsequent test procedure is then identical to Egger's test. 
% 
% \vspace{0mm}
% Peters test is a a small modification of Macaskill's test where the explanatory variable is the sample size instead of its inverse.
% 
% 
% \subsubsection{Harbord's Test: Score based Test}
% A rank based alternative to Peters test for binary outcomes is the Harbord's test \citep{Harbord}. The score $r_{i}$ (the first derivative of the log-likelihood of a proportion with treatment effect equal 0) and its variance $v_{i}$ can be computed as shown in \ref{harbord.score} and \ref{harbord.variance}.
% 
% \begin{align}
% r_{i} &= e_{t} - (e_{t} - e_{c})(e_{t} + (n_{t} - e_{t}))/(n_{t} + n_{c}) \label{harbord.score} \\
% v_{i} &= \frac{(e_{t} + e_{c})(e_{t} + (n_{t} - e_{t}))(e_{c} + (n_{c} - e_{c}))((n_{t} - e_{t}) + (n_{c} - e_{c}))}{(n_{t} + n_{c})^2(n_{t} + n_{c} - 1)} \label{harbord.variance}
% \end{align}
% 
% Similarly to Egger's or Peters Test, now a weighted linear regression can be performed on $r_{i}/v_{i}$ with the standard error $1/\sqrt{v_{i}}$ as explanatory variable and $1/v_{i}$ as a weight. Note that $r_{i}/v_{i}$ is also known as peto odds ratio. 
% 
% \subsubsection{Schwarzer's Test: Rank Correlation Test}
% \citet{Schwarzer} developed a test for the correlation between $e_{t} - \mathbb{E}(E_{t})$ and the variance of $E_{t}$, $E_{t}$ being a random variable from the non-central hypergeometric distribution with fixed log odds ratio. $\mathbb{E}(E_{t})$ and variance of $E_{t}$ are then estimated based on $e_{t}$.
% 
% \vspace{0mm}
% The standardized cell count deviation $(e_{t} - \mathbb{E}(E_{t}))/\sqrt(v_{i})$ and the inverse of $v_{i}$ is then used in the way as before in Begg and Mazumdar's test.
% 
% \subsubsection{R\"ucker's Test: Using the Variance Stabilizing Transformation for Binomial Random Variables}
% The correlation between variance and effect size of dichotomous outcome measures can be abolished by the variance stabilizing transformation for binomial random variables. Let 
% 
% \begin{align}
% y_{i} = \arcsin{e_{t}/n_{t}} - \arcsin{e_{c}/n_{c}} \\
% v_{i} = 1/4n_{t} + +/4n_{c}
% \end{align}
% 
% Then one can for example apply Begg and Mazumdar's rank correlation test or Thompson and Sharp's test using the newly obtained variances. 
% 
% 
% \section{Small Study Effect Adjustment}
% \subsection{Trim and Fill}
% One method to account for reporting bias in meta-analysis is to apply the Trim and Fill adjustment method \citep{trimfill}. It is a nonparametric test based on a funnel plot, on which the effect size estimates of studies are plotted against their standard error. 
% %If reporting bias is present, the estimate will shift in average towards higher or lower efffect sizes compared to the estimates of larger studies
% 
% \vspace{0mm}
% The algorithm for the method tries to estimate the number of studies $k$ that are not available due to reporting bias (different estimators are available for $k$). First, $\Delta$ is estimated using a fixed or random effects model. Then, the $k$ effect size estimates with the smallest standard errors are trimmed, and $\Delta$ is estimated again. The procedure is repeated until $k$ is 0 and the funnel plot is symmetric. The total number of missing studies is then mirrored with respect to the final effect size estimate $\Delta$, and $\Delta$ and its standard error is then computed to obtain an unbiased estimate.
% 
% \subsection{Copas Selection Model}
% 
% A method proposed in \cite{Copas1,Copas2,Copas3} assumes that there is a population of studies of which only a part has been published dependent on the variance and size of their estimated effects. Studies with small variance and large effect sizes are more likely to be published than studies with large variance and small effect sizes. Note that small effect size means here a treatment effect close to the control effect.
% 
% Let $y_i$ be the effect size estimate of study $i$. Then 
% 
% \begin{align}
% y_{i} \sim N(\mu_{i}, \sigma_{i}^2) \\
% \mu_{i} \sim N(\mu, \tau^2)
% \end{align}
% 
% corresponding to a standard random effects meta-analysis. $\mu$ is the overall mean effect, $\sigma_{i}^2$ the within study variance and $\tau^2$ the between study variance. This is the \textit{population model}.
% 
% \vspace{0mm}
% The \textit{selection model} is defined as follows. Suppose a selection of studies with reported standard errors $s$ (likely different from $\sigma$). Only a proportion 
% 
% \begin{align}
% P(\textrm{select}|s) &= \Phi(a + b/s) \label{copas.selection1}
% \end{align}
% 
% of the selection will be published, with a defining the overall proportion of published studies and b (assumed to be positive) defining how fast this proportion increases with $s$ becoming smaller. \ref{copas.selection1} can be rewritten as 
% 
% \begin{align}
% z = a + b/s + \delta \label{copas.selection2}
% \end{align}
% 
% with $\delta \sim N(0,1)$. The study with standard error $s$ is only selected if $z$ is positive. Therefore, the larger $z$, the more likely the study is selected.
% Combining population and selection model for study $i$, we have 
% 
% \begin{align}
% y_{i} = \mu_{i} + \sigma_{i}\epsilon_{i} \\
% \mu_{i} \sim N(\mu, \tau^2) \\
% z_{i} = a + b/s_{i} + \delta_{i}
% \end{align}
% 
% where $(\epsilon_{i}, \delta_{i})$ are standard normal residuals and jointly normal with correlation $\rho = cor(y_{i}, z_{i})$. Every given study $i$ in the meta-analysis has $z_{i} > 0$. If $\rho$ is large and positive and $z_{i} > 0$, then the estimate of a study $i$ that is selected is likely to have positive $\epsilon_{i}$ and $\delta_{i}$. Thus, the true mean $\mu$ is likely to be overestimated. 
% 
% \vspace{0mm}
% Let $u = a + b/s$, $\lambda(u) = \phi(u)/\Phi(u)$ ($\phi$ is the standard normal density function) and $\tilde{\rho} = \sigma/\sqrt(\tau^2 + \sigma^2) \rho$. The probability of a study being selected is
% 
% \begin{align}
% P(\textrm{select}|s, y) = P(a,b,s,y) = \Phi(\frac{u + \tilde{\rho}((y - \mu)/\sqrt(\tau^2 + \sigma^2))}{\sqrt{1 - \tilde{\rho^2}}})
% \end{align}
% 
% It can also be shown that the expected value 
% 
% \begin{align}
% \mathbb{E}(y|s, select) = \mu + \rho\sigma\lambda(u) \label{copas.expectation}
% \end{align}
% 
% which shows that the expected value for a study is larger for larger $\sigma$. 
% 
% \vspace{0mm}
% One can compute a likelihood function based on the distribution of $y$ conditional on $z > 0$. The likelihood can be maximized for any given pair $a,b$ (can not be estimated since the number of missing studies is not known), and a maximum likelihood estimate $\hat{\mu}$ for the true mean $\mu$ can be obtained. One can then perform a sensitivity analysis. First, one looks how $\hat{\mu}$ changes for different values of $a,b$. One can then compare the fitted values in \ref{copas.expectation} with the real values. To test the fit of the model (while keeping all other parts unchanged), the model can be extended in the following way :
% 
% \begin{align}
% y_{i} &= \mu_{i} + \beta s_{i} + \sigma_{i}\epsilon_{i}
% \end{align}
% 
% If we accept $\beta = 0$, then we accept that the selection model has satisfactorily explained any relationship between $y$ and $s$. Only if the value is large enough, typically $p > 0.05$, one concludes that the selection model has explained the observed data. The $p$\hspace{0.4mm}-value is obtained by a likelihood ratio test comparing the maximum of the likelihood with the $\beta$ term added and without it, and by a likelihood ratio test.
% 
% \vspace{0mm}
% To find out if the null-hypothesis of, say, $\mu = 0$ can be rejected, another likelihood ratio test can be performed, this time with imputing $\mu = 0$ and comparing the two maximum likelihoods.
% 
% \vspace{0mm}
% In practice, only a range of values for $a,b$ are reasonable. For those values, the quantities above can be calculated and illustrated. Values for $\mu$ that have $p$\hspace{0.4mm}-values over a predefined significance threshold can be used for inference of the effect size. 
% 
% \subsection{Adjustment by Regression}
% There are multiple ways to adjust for small study effects by regression. The general idea is to extrapolate the effect size of a study with a variance of zero based on the given effects and variances. 
% 
% \citet{limitmeta} use a random effects model together with shrinkage procedure to obtain an unbiased estimate. Similarly to what has been seen in Copas selection model, we let $y_{i}$ depend on the intercept $\beta_{0}$ and on its standard error $\sqrt{v_{i}}$ as in \ref{limitmeta.regression}.
% 
% \begin{align}
% y_{i}& = \beta_{0} + \beta_{1}(\sqrt{v_{i} + \tau^2}) + \epsilon_{i}(\sqrt{v_{i} + \tau^2}), \epsilon_{i} \stackrel{\textrm{iid}}{\sim} N(0,1)  \label{limitmeta.regression}
% \end{align}
% 
% $\beta_{1}$ represents the bias introduced by small study effects, as can be seen when looking at \ref{limitmeta.infinitesample}
% 
% \begin{align}
% \mathbb{E}((y_{i} - \beta_{0})/\sqrt{v_{i}}) \rightarrow \beta_{1} \textrm{ if } \sqrt{v_{i}} \rightarrow \infty \label{limitmeta.infinitesample} \\
% \mathbb{E}(y_{i}) \rightarrow \beta_{0} + \beta_{1}\tau \textrm{if} \sqrt{v_{i}} \rightarrow 0 
% \end{align}
% 
% After estimating $\tau^2$, one can estimate $\beta_{0}$ and $\beta_{1}$ as seen before \eg in Thompson and Sharp's Test with weights also equal to Thompson and Sharp's Test (see \ref{Thompson}).
% 
% \vspace{0mm}
% To diminuish the random variation within studies, but keep the variation between studies, we change \ref{limitmeta.regression} to a scenario where each study has $M$-fold increased precision:
% 
% \begin{align}
% y_{M,i} &= \beta_{0}^\star + \beta_{1}^\star(\sqrt{v_{i}/M + \tau^2}) + \epsilon_{i}(\sqrt{v_{i}/M + \tau^2}) \label{limitmeta.regression}
% \end{align}
% 
% Letting $M \rightarrow \infty$, we obtain:
% 
% \begin{align}
% y_{\infty,i} &= \beta_{0}^\star + \tau(\beta_{1}^\star + \epsilon_{i}),  \epsilon_{i} \stackrel{\textrm{iid}}{\sim} N(0,1) \label{limitmeta.regression.infinity}
% \end{align}
% 
% Note that:
% 
% \begin{align}
% y_{\infty,i} &= \beta_{0}^\star + \tau\beta_{1}^\star = \beta_{0}
% \end{align}
% 
% $\beta_{0}$ is termed the limit meta analysis expectation. Now, the random errors from \ref{limitmeta.regression} are rewritten as:
% 
% \begin{align}
% \epsilon_{i} &= \frac{y_{i} - \beta_{0}^\star}{\sqrt{v_{i} + \tau^2}} - \beta_{1}^\star
% \end{align}
% 
% Assuming $\epsilon_{i}$ to be fixed, we can plug it into \ref{limitmeta.regression.infinity} and get 
% 
% \begin{align}
% y_{\infty,i} &= \beta_{0}^\star + \sqrt{\frac{\tau^2}{v_{i} + \tau^2}}(y_{i} - \beta_{0}^\star)
% \end{align}
% 
% By estimating $\tau^2, v_{i}$ and  $\beta_{0}^\star$, we can use the formula to obtain a new study means, adjusted for small study effects and shrunken to a common mean. 







% \begin{align} \label{cox reg}
% P(Y < y|\mathbf{x}) = 1 - exp(-exp(h(y) - (\mathbf{x})^\top\beta)
% \end{align}
% 
% See \cite{hothorn} for further information. It specifies the instantaneous risk of an event at time t to be
% 
% \begin{align}
% \lambda_{0}(t)exp((\mathbf{x})^\top\beta) \nonumber
% \end{align}
% 
% The model is regarded as a semi parametric model since it includes the covariates in a linear fashion but leaves the baseline hazard $\lambda_{0}(t)$ unspecified. The factor $exp((\mathbf{x})^\top\beta)$ has the interpretation of a hazard ratio between the reference with $\mathbf{x} = 0$. The formal definition of the hazard is
% 
% \begin{align}
% h(t) = \lim_{h \to 0} \frac{P(t < T < t + h| T > t)}{h}
% \end{align}
% 
% 
% \begin{align} \label{generalized linear model}
% \mathbf{Y}{_{ij}}|U{_i},\epsilon{_{ij}} = (1,x{_i}^\top)\beta + U{_i} + \epsilon{_{ij}}
% \end{align}